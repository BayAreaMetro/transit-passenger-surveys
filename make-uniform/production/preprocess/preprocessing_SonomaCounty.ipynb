{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'runid', 'interview_start_time', 'interview_end_time', 'day_of_week', 'date', 'type_of_day', 'strata', 'route', 'dir', 'orig_purp', 'dest_purp', 'sch_status', 'school_name', 'college_name', 'access_mode', 'egress_mode', 'unnamed:_17', 'unnamed:_18', 'unnamed:_19', 'orig_lat', 'orig_lon', 'first_board_lat', 'first_board_lon', 'last_alight_lat', 'last_alight_lon', 'endlat', 'endlon', 'xfers_before', '1_system_before', '1_route_before', '1_before_lat_start', '1_before_long_start', '1_before_lat_end', '1_before_long_end', '2_system_before', '2_route_before', '2_before_lat_start', '2_before_long_start', '2_before_lat_end', '2_before_long_end', 'routeboard_lat', 'routeboard_long', 'routealight_lat', 'routealight_long', 'xfers_after', '1_after_system', '1_route_after_system', '1_after_lat_start', '1_after_long_start', '1_after_lat_end', '1_after_long_end', '2_after_system', '2_route_after_system', '2_after_lat_start', '2_after_long_start', '2_after_lat_end', '2_after_long_end', '3_after_system', '3_route_after_system', '3_after_lat_start', '3_after_long_start', '3_after_lat_end', '3_after_long_end', 'fare', 'farecat', 'cars', 'hh', 'hhwork', 'yearborn', 'age', 'hisp', 'race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_hisp', 'race_other', 'household_income', 'language_at_home_binary', 'language_at_home_detail', 'eng_proficient', 'livebay', 'homelat', 'homelon', 'work_status', 'worklat', 'worklon', 'at_work_after_dest_purp', 'at_work_prior_to_orig_purp', 'school_lat', 'school_lon', 'at_school_after_dest_purp', 'at_school_prior_to_orig_purp', 'depart_hour', 'return_hour', 'gender', 'mode', 'wcode', 'weight', 'tweight', 'first_route_before_survey_board', 'second_route_before_survey_board', 'first_route_after_survey_alight', 'second_route_after_survey_alight', 'third_route_after_survey_alight', 'survey_time']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>runid</th>\n",
       "      <th>interview_start_time</th>\n",
       "      <th>interview_end_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>type_of_day</th>\n",
       "      <th>strata</th>\n",
       "      <th>route</th>\n",
       "      <th>dir</th>\n",
       "      <th>...</th>\n",
       "      <th>mode</th>\n",
       "      <th>wcode</th>\n",
       "      <th>weight</th>\n",
       "      <th>tweight</th>\n",
       "      <th>first_route_before_survey_board</th>\n",
       "      <th>second_route_before_survey_board</th>\n",
       "      <th>first_route_after_survey_alight</th>\n",
       "      <th>second_route_after_survey_alight</th>\n",
       "      <th>third_route_after_survey_alight</th>\n",
       "      <th>survey_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>135</td>\n",
       "      <td>9:23 AM</td>\n",
       "      <td>9:39 AM</td>\n",
       "      <td>THUR</td>\n",
       "      <td>4/5/2018</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>AM PEAK</td>\n",
       "      <td>44</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>...</td>\n",
       "      <td>INTERVIEWER_TABLET</td>\n",
       "      <td>30</td>\n",
       "      <td>30.525000</td>\n",
       "      <td>152.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:23 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808</td>\n",
       "      <td>25</td>\n",
       "      <td>4:28 PM</td>\n",
       "      <td>4:38 PM</td>\n",
       "      <td>TUE</td>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>PM PEAK</td>\n",
       "      <td>48</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>...</td>\n",
       "      <td>INTERVIEWER_TABLET</td>\n",
       "      <td>60</td>\n",
       "      <td>36.305882</td>\n",
       "      <td>181.529412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4:28 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>338</td>\n",
       "      <td>75</td>\n",
       "      <td>12:03 PM</td>\n",
       "      <td>12:20 PM</td>\n",
       "      <td>TUE</td>\n",
       "      <td>4/3/2018</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>MIDDAY</td>\n",
       "      <td>60</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>...</td>\n",
       "      <td>INTERVIEWER_TABLET</td>\n",
       "      <td>30</td>\n",
       "      <td>30.525000</td>\n",
       "      <td>152.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:03 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>75</td>\n",
       "      <td>11:28 AM</td>\n",
       "      <td>11:38 AM</td>\n",
       "      <td>TUE</td>\n",
       "      <td>4/3/2018</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>MIDDAY</td>\n",
       "      <td>60</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>...</td>\n",
       "      <td>INTERVIEWER_TABLET</td>\n",
       "      <td>30</td>\n",
       "      <td>30.525000</td>\n",
       "      <td>152.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:28 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>326</td>\n",
       "      <td>60</td>\n",
       "      <td>9:26 AM</td>\n",
       "      <td>3:37 PM</td>\n",
       "      <td>THUR</td>\n",
       "      <td>3/29/2018</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>AM PEAK</td>\n",
       "      <td>12</td>\n",
       "      <td>LOOP</td>\n",
       "      <td>...</td>\n",
       "      <td>INTERVIEWER_MIX</td>\n",
       "      <td>28</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:26 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id runid interview_start_time interview_end_time day_of_week       date  \\\n",
       "0  350   135              9:23 AM            9:39 AM        THUR   4/5/2018   \n",
       "1  808    25              4:28 PM            4:38 PM         TUE  3/27/2018   \n",
       "2  338    75             12:03 PM           12:20 PM         TUE   4/3/2018   \n",
       "3  335    75             11:28 AM           11:38 AM         TUE   4/3/2018   \n",
       "4  326    60              9:26 AM            3:37 PM        THUR  3/29/2018   \n",
       "\n",
       "  type_of_day   strata route    dir  ...                mode wcode     weight  \\\n",
       "0     WEEKDAY  AM PEAK    44  SOUTH  ...  INTERVIEWER_TABLET    30  30.525000   \n",
       "1     WEEKDAY  PM PEAK    48  NORTH  ...  INTERVIEWER_TABLET    60  36.305882   \n",
       "2     WEEKDAY   MIDDAY    60  SOUTH  ...  INTERVIEWER_TABLET    30  30.525000   \n",
       "3     WEEKDAY   MIDDAY    60  SOUTH  ...  INTERVIEWER_TABLET    30  30.525000   \n",
       "4     WEEKDAY  AM PEAK    12   LOOP  ...     INTERVIEWER_MIX    28  46.300000   \n",
       "\n",
       "      tweight first_route_before_survey_board  \\\n",
       "0  152.625000                             NaN   \n",
       "1  181.529412                             NaN   \n",
       "2  152.625000                             NaN   \n",
       "3  152.625000                             NaN   \n",
       "4  231.500000                             NaN   \n",
       "\n",
       "  second_route_before_survey_board first_route_after_survey_alight  \\\n",
       "0                              NaN                             NaN   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                              NaN                             NaN   \n",
       "4                              NaN                             NaN   \n",
       "\n",
       "   second_route_after_survey_alight  third_route_after_survey_alight  \\\n",
       "0                               NaN                              NaN   \n",
       "1                               NaN                              NaN   \n",
       "2                               NaN                              NaN   \n",
       "3                               NaN                              NaN   \n",
       "4                               NaN                              NaN   \n",
       "\n",
       "   survey_time  \n",
       "0      9:23 AM  \n",
       "1      4:28 PM  \n",
       "2     12:03 PM  \n",
       "3     11:28 AM  \n",
       "4      9:26 AM  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Sonoma County\\2018\\As CSV\\sc transit_data file_final_spring 2018 NO POUND NO SINGLE QUOTE.csv')\n",
    "cols = [x.strip().replace(' ','_').lower() for x in list(df_raw)]\n",
    "df = df_raw.copy()\n",
    "df.columns = cols\n",
    "\n",
    "df['first_route_before_survey_board'] = df['1_system_before'] + '___' + df['1_route_before'].astype(str)\n",
    "df['second_route_before_survey_board'] = df['2_system_before'] + '___' + df['2_route_before'].astype(str)\n",
    "df['first_route_after_survey_alight'] = df['1_after_system'] + '___' + df['1_route_after_system'].astype(str)\n",
    "df['second_route_after_survey_alight'] = df['2_after_system'] + '___' + df['2_route_after_system'].astype(str)\n",
    "df['third_route_after_survey_alight'] = df['3_after_system'] + '___' + df['3_route_after_system'].astype(str)\n",
    "\n",
    "df['survey_time'] = df['interview_start_time']\n",
    "df.rename(columns = {'ccgid': 'id'}, inplace=True)\n",
    "\n",
    "for i in ['race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_hisp']:\n",
    "    df[i] = df[i].fillna(0)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "\n",
    "print(list(df))\n",
    "display(df.head())\n",
    "\n",
    "df.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Sonoma County\\2018\\As CSV\\sc transit_data file_final_spring 2018_addRoutesCols NO POUND NO SINGLE QUOTE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "routes = pd.DataFrame(columns = ['route'])\n",
    "for i in ['first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "          'first_route_after_survey_alight', 'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    route_unique = df[[i]]\n",
    "    route_unique.columns = ['route']\n",
    "    routes = pd.concat([routes, route_unique])\n",
    "\n",
    "routes_clean = routes.loc[routes.route.notnull()]\n",
    "routes_clean.drop_duplicates(inplace=True)\n",
    "print(routes_clean.shape)\n",
    "routes_clean.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Sonoma County\\2018\\As CSV\\all_routes_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic_Variable that should not exit:\n",
      "['race_dmy_hisp' 'work_lat' 'work_lon']\n",
      "\n",
      "ccgid\n",
      "id\n",
      "runid\n",
      "dir\n",
      "school_name\n",
      "college_name\n",
      "unnamed:_17\n",
      "unnamed:_18\n",
      "unnamed:_19\n",
      "xfers_before\n",
      "1_system_before\n",
      "1_route_before\n",
      "1_before_lat_start\n",
      "1_before_long_start\n",
      "1_before_lat_end\n",
      "1_before_long_end\n",
      "2_system_before\n",
      "2_route_before\n",
      "2_before_lat_start\n",
      "2_before_long_start\n",
      "2_before_lat_end\n",
      "2_before_long_end\n",
      "xfers_after\n",
      "1_after_system\n",
      "1_route_after_system\n",
      "1_after_lat_start\n",
      "1_after_long_start\n",
      "1_after_lat_end\n",
      "1_after_long_end\n",
      "2_after_system\n",
      "2_route_after_system\n",
      "2_after_lat_start\n",
      "2_after_long_start\n",
      "2_after_lat_end\n",
      "2_after_long_end\n",
      "3_after_system\n",
      "3_route_after_system\n",
      "3_after_lat_start\n",
      "3_after_long_start\n",
      "3_after_lat_end\n",
      "3_after_long_end\n",
      "age\n",
      "livebay\n"
     ]
    }
   ],
   "source": [
    "# bring in standard dictionary to check field consistency\n",
    "\n",
    "# dictionary for Sonoma survey\n",
    "var = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Sonoma County\\2018\\As CSV\\variables_dictionary.csv',\n",
    "                  encoding = \"ISO-8859-1\", engine='python')\n",
    "# standard dictionary\n",
    "var_standard = pd.read_csv(r'C:\\Users\\ywang\\Documents\\GitHub\\onboard-surveys\\make-uniform\\production\\Dictionary for Standard Database.csv')\n",
    "var_standard.columns = [x+'_s' for x in list(var_standard)]\n",
    "\n",
    "# merge\n",
    "var_merge = var.merge(var_standard, left_on='Generic_Variable', right_on='Generic_Variable_s', how='outer')\n",
    "\n",
    "# check if 'Generic_Variable' in Sonoma dictionary matches the standard 'Generic_Variable'. chk1 should be empty\n",
    "chk1 = var_merge.loc[(var_merge.Generic_Variable.notnull()) & (var_merge.Generic_Variable_s.isnull())]\n",
    "print('Generic_Variable that should not exit:')\n",
    "print(chk1.Generic_Variable.unique())\n",
    "print()\n",
    "\n",
    "# check if columns names in survey data matches 'Survey_Variable' in Sonoma dictionary.\n",
    "# the following loops should not include variables that are needed for standardization\n",
    "\n",
    "for i in var.loc[var.Generic_Variable.notnull()]['Survey_Variable']:\n",
    "    if i not in list(df):\n",
    "        print(i)\n",
    "        \n",
    "for i in list(df):\n",
    "    if i not in list(var.Survey_Variable):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access_mode\n",
      "at_school_after_dest_purp\n",
      "[nan]\n",
      "at_school_prior_to_orig_purp\n",
      "[nan]\n",
      "at_work_after_dest_purp\n",
      "[nan]\n",
      "at_work_prior_to_orig_purp\n",
      "[nan]\n",
      "day_of_week\n",
      "depart_hour\n",
      "[nan]\n",
      "dest_purp\n",
      "egress_mode\n",
      "eng_proficient\n",
      "[nan]\n",
      "farecat\n",
      "fare\n",
      "gender\n",
      "hisp\n",
      "household_income\n",
      "language_at_home_binary\n",
      "language_at_home_detail\n",
      "[nan]\n",
      "orig_purp\n",
      "hh\n",
      "race_dmy_asn\n",
      "race_dmy_blk\n",
      "race_dmy_hisp\n",
      "race_dmy_hwi\n",
      "race_dmy_ind\n",
      "race_dmy_wht\n",
      "return_hour\n",
      "[nan]\n",
      "sch_status\n",
      "[nan]\n",
      "strata\n",
      "mode\n",
      "type_of_day\n",
      "cars\n",
      "work_status\n",
      "[nan]\n",
      "hhwork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# check if all the values in the survey data are included in Sonoma dictionary\n",
    "# look at non-categorical variables; \"diff\" should be empty or only contains nan\n",
    "\n",
    "var_clean = var[['operator', 'Survey_year', 'Survey_Variable', 'Survey_Response', \n",
    "                 'Generic_Variable', 'Generic_Response']].drop_duplicates()\n",
    "var_clean = var_clean.loc[var_clean.Generic_Variable.notnull()]\n",
    "\n",
    "for i in var_clean.loc[var_clean.Survey_Response != 'NONCATEGORICAL']['Survey_Variable'].unique():\n",
    "    print(i)\n",
    "    df_sub = df[['id', i]]\n",
    "    var_sub = var_clean.loc[var_clean.Survey_Variable == i]\n",
    "\n",
    "    if i in ['race_dmy_asn', 'race_dmy_blk', 'race_dmy_hisp', 'race_dmy_hwi', 'race_dmy_ind', 'race_dmy_wht']:\n",
    "        var_sub.Survey_Response = var_sub.Survey_Response.apply(lambda x: int(x))\n",
    "    \n",
    "    compare = df_sub.merge(var_sub, left_on=i, right_on='Survey_Response', how='left')\n",
    "    diff = compare.loc[compare.Generic_Response.isnull()]\n",
    "    if diff.shape[0] > 0:\n",
    "        print(diff[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_string' 'access_mode' 'at_school_after_dest_purp'\n",
      " 'at_school_prior_to_orig_purp' 'at_work_after_dest_purp'\n",
      " 'at_work_prior_to_orig_purp' 'year_born_four_digit' 'ID' 'date_string'\n",
      " 'day_of_week' 'depart_hour' 'dest_lat' 'dest_lon' 'dest_purp'\n",
      " 'egress_mode' 'eng_proficient' 'fare_category' 'fare_medium'\n",
      " 'first_board_lat ' 'first_board_lon' 'first_route_after_survey_alight'\n",
      " 'first_route_before_survey_board' 'gender' 'hispanic' 'home_lat'\n",
      " 'home_lon' 'household_income' 'interview_end_time' 'interview_start_time'\n",
      " 'language_at_home_binary' 'language_at_home_detail' 'last_alight_lat '\n",
      " 'last_alight_lon' 'orig_lat' 'orig_lon' 'orig_purp' 'persons'\n",
      " 'race_dmy_asn' 'race_dmy_blk' 'race_dmy_hisp' 'race_dmy_hwi'\n",
      " 'race_dmy_ind' 'race_dmy_wht' 'race_other_string' 'return_hour' 'route'\n",
      " 'survey_alight_lat' 'survey_alight_lon' 'survey_board_lat'\n",
      " 'survey_board_lon' 'school_lat' 'school_lon' 'student_status'\n",
      " 'second_route_after_survey_alight' 'second_route_before_survey_board'\n",
      " 'strata' 'survey_type' 'third_route_after_survey_alight' 'tweight'\n",
      " 'weekpart' 'vehicles' 'wcode' 'weight' 'work_lat' 'work_lon'\n",
      " 'work_status' 'workers']\n"
     ]
    }
   ],
   "source": [
    "# finally, check all necessary fields are included, and export\n",
    "print(var_clean.Generic_Variable.unique())\n",
    "var_clean.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Sonoma County\\2018\\As CSV\\vars_for_standard_dictionary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
