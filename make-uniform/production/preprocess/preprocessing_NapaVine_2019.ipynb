{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Napa Vine\\2019\\Napa Vine-FINAL Data-Client_01212021.xlsx',\n",
    "                       sheet_name = 'Main Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sys_RespNum', 'CCGID', 'interview_start_time', 'interview_end_time', 'day_of_week', 'date', 'DTYPE', 'RUNID', 'Route', 'Dir', 'Strata', 'wcode', 'weight', 'tweight', 'Lang', 'From', 'To', 'FromSchool', 'ToSchool', 'FromUni', 'ToUni', 'Start_lat', 'Start_lon', 'End_lat', 'End_lon', 'ToBusMode1', 'ToBusMode2', 'ToBusMode3', 'ToBusMode4', 'GetFirstBus', 'totalbusBEFORE', 'Route_Before_1', 'Route_Before_2', 'Route_Before_3', 'Route_Before_4', 'System_Before_1', 'System_Before_2', 'System_Before_3', 'System_Before_4', 'FromBusMode1', 'FromBusMode2', 'FromBusMode3', 'FromBusMode4', 'FromLastBus', 'totalbusAFTER', 'Route_After_1', 'Route_After_2', 'Route_After_3', 'Route_After_4', 'System_After_1', 'System_After_2', 'System_After_3', 'System_After_4', 'fare', 'farecat', 'Alternatives', 'UseVineMoreFrequency', 'UseVineMoreDestination', 'UseVineMoreEarlier', 'UseVineMoreLater', 'cars', 'hh', 'hhwork', 'birthyear', 'Age', 'hisp', 'ETH1', 'ETH2', 'ETH3', 'ETH4', 'income', 'langhh', 'engspk', 'livebay', 'home_lat', 'home_lon', 'sch', 'School_Name', 'school_lat', 'school_lon', 'work', 'WorkLat', 'WorkLong', 'workafter', 'workbefore', 'schafter', 'schbefore', 'hometime_c1', 'hometime_c2', 'gender', 'com', 'Mode']\n",
      "(338, 92)\n",
      "The data has 338 records, 338 unique CCGID\n",
      "If the data has duplicates records: False\n"
     ]
    }
   ],
   "source": [
    "print(list(df_raw))\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# check duplicates\n",
    "print('The data has {} records, {} unique CCGID'.format(df.shape[0], len(df.CCGID.unique())))\n",
    "print('If the data has duplicates records: {}'.format(not(df[df.duplicated()].shape[0] == 0)))\n",
    "\n",
    "df.rename(columns= {'CCGID': 'ID'}, inplace=True)\n",
    "\n",
    "# use interview_start_time as time_string\n",
    "df['survey_time'] = df['interview_start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code transfer system and create columns for 'system + route' which will be used for canonical_route mapping\n",
    "\n",
    "system_dict = {1: 'BART',\n",
    "               2: 'Napa Vine',\n",
    "               3: 'County Connection',\n",
    "               4: 'FAST (Fairfield-Suisun Transit)',\n",
    "               5: 'SolTrans (Solano County Transit)',\n",
    "               6: 'Sonoma County Transit',\n",
    "               7: 'Tri Delta Transit',\n",
    "               8: 'Vacaville City Coach',\n",
    "               9: 'AC Transit',\n",
    "               10: 'Caltrain',\n",
    "               11: 'Golden Gate Transit',\n",
    "               12: 'Golden Gate Ferry',\n",
    "               13: 'SamTrans',\n",
    "               14: 'San Francisco Bay Ferry',\n",
    "               15: 'San Francisco Muni',\n",
    "               16: 'VTA',\n",
    "               17: 'WestCat',\n",
    "               18: 'WHEELS',\n",
    "               19: 'Other (type in next to route)',\n",
    "               20: 'Lake Transit',\n",
    "               21: 'Capitol Corridor'}\n",
    "\n",
    "for i in ['System_Before_1', 'System_Before_2', 'System_Before_3', 'System_Before_4',\n",
    "          'System_After_1', 'System_After_2', 'System_After_3', 'System_After_4']:\n",
    "    #print(i)\n",
    "    #print(df[i])\n",
    "    df[i] = df[i].fillna(0)\n",
    "    df[i].replace(to_replace = ' ', value = 0, inplace=True)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(system_dict)\n",
    "    #print(df[i+'_temp'])\n",
    "\n",
    "df['first_route_before_survey_board'] = df['System_Before_1_temp'] + '___' + df['Route_Before_1'].astype(str)\n",
    "df['second_route_before_survey_board'] = df['System_Before_2_temp'] + '___' + df['Route_Before_2'].astype(str)\n",
    "df['third_route_before_survey_board'] = df['System_Before_3_temp'] + '___' + df['Route_Before_3'].astype(str)\n",
    "df['first_route_after_survey_alight'] = df['System_After_1_temp'] + '___' + df['Route_After_1'].astype(str)\n",
    "df['second_route_after_survey_alight'] = df['System_After_2_temp'] + '___' + df['Route_After_2'].astype(str)\n",
    "df['third_route_after_survey_alight'] = df['System_After_3_temp'] + '___' + df['Route_After_3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['29_NORTH', '2_LOOP', '3_LOOP', '29_SOUTH', '10_SOUTH', '1_LOOP',\n",
       "       '10_NORTH', '4_LOOP', '11_NORTH', '8_SOUTH', '21_EAST', '5_LOOP',\n",
       "       '8_NORTH', '21_WEST', '11_SOUTH', '7_LOOP', '6_LOOP'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new field to represent complete survey route info (route + direction)\n",
    "df['route_dir'] = df.Route.astype(str) + '_' + df.Dir\n",
    "df.route_dir.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['American Indian/Alaska Native_NA_NA_NA', 'Hispanic_NA_NA_NA', 'White/Caucasian_NA_NA_NA', 'Black/African American_NA_NA_NA', 'White/Caucasian_Hispanic_NA_NA', 'Asian_NA_NA_NA', 'Mixed_NA_NA_NA', 'American Indian/Alaska Native_Hispanic_NA_NA', 'Hispanic_American Indian/Alaska Native_NA_NA', 'American Indian/Alaska Native_White/Caucasian_Hispanic_NA', 'American Indian/Alaska Native_Black/African American_White/Caucasian_Asian', 'Mixed_Hispanic_NA_NA', 'Black/African American_White/Caucasian_NA_NA', 'Hispanic_White/Caucasian_NA_NA', 'White/Caucasian_Hispanic_American Indian/Alaska Native_NA', 'Native Hawaiian/Pacific Islander_NA_NA_NA', 'Black/African American_White/Caucasian_Hispanic_NA', 'Native Hawaiian/Pacific Islander_Black/African American_Asian_NA', 'American Indian/Alaska Native_White/Caucasian_NA_NA', 'Refused_NA_NA_NA', 'Asian_Hispanic_NA_NA', 'Black/African American_Hispanic_NA_NA', 'Persian/Arab/North African/Middle Eastern_NA_NA_NA', 'Native Hawaiian/Pacific Islander_White/Caucasian_NA_NA', 'American Indian/Alaska Native_Black/African American_Asian_NA']\n"
     ]
    }
   ],
   "source": [
    "race_dict = {1: 'American Indian/Alaska Native',\n",
    "             2: 'Native Hawaiian/Pacific Islander',\n",
    "             3: 'Black/African American',\n",
    "             4: 'White/Caucasian',\n",
    "             5: 'Asian',\n",
    "             6: 'Other',\n",
    "             7: 'Hispanic',\n",
    "             8: 'Mixed',\n",
    "             9: 'Persian/Arab/North African/Middle Eastern',\n",
    "             0: 'Refused',\n",
    "             10: 'NA'}\n",
    "\n",
    "for i in ['ETH1', 'ETH2', 'ETH3', 'ETH4']:\n",
    "    df[i] = df[i].fillna(10)\n",
    "    df[i].replace(to_replace = ' ', value = 10, inplace=True)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(race_dict)\n",
    "    \n",
    "df['ETH_concat'] = df['ETH1_temp'] + '_' + df['ETH2_temp'] + '_' + df['ETH3_temp'] + '_' + df['ETH4_temp']\n",
    "print(list(df['ETH_concat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hisp</th>\n",
       "      <th>hisp_from_ETH</th>\n",
       "      <th>ETH1</th>\n",
       "      <th>ETH2</th>\n",
       "      <th>ETH3</th>\n",
       "      <th>ETH4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>101.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID hisp hisp_from_ETH  ETH1  ETH2  ETH3  ETH4\n",
       "78  101.0    1          hisp     4     7     1    10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hisp</th>\n",
       "      <th>hisp_from_ETH</th>\n",
       "      <th>ETH1</th>\n",
       "      <th>ETH2</th>\n",
       "      <th>ETH3</th>\n",
       "      <th>ETH4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9010.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>9012.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>9028.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>9029.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID hisp hisp_from_ETH  ETH1  ETH2  ETH3  ETH4\n",
       "0       9.0    2      non-hisp     1    10    10    10\n",
       "4      13.0    2      non-hisp     4    10    10    10\n",
       "193  9010.0    2      non-hisp     4    10    10    10\n",
       "194  9011.0    2      non-hisp     4    10    10    10\n",
       "195  9012.0    2      non-hisp     0    10    10    10\n",
       "197  9020.0    2      non-hisp     4    10    10    10\n",
       "203  9028.0    2      non-hisp     0    10    10    10\n",
       "204  9029.0    2      non-hisp     0    10    10    10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['hisp_from_ETH'] = 'non-hisp'\n",
    "df.loc[df.ETH_concat.str.contains('Hispanic',na=False), 'hisp_from_ETH'] = 'hisp'\n",
    "\n",
    "# check consistency between 'hisp' derived from ETH and the original 'hisp' variable and make corrections\n",
    "\n",
    "# records where ETH indicates 'hispanic' but 'hisp' is 1 (not hispanic)\n",
    "display(df.loc[(df.hisp_from_ETH == 'hisp') & (df.hisp != 2)][['ID','hisp','hisp_from_ETH',\n",
    "                                                                 'ETH1', 'ETH2', 'ETH3', 'ETH4']])\n",
    "# make hisp=2 for records where hisp_from_ETH == 'hisp'\n",
    "df.loc[df.hisp_from_ETH == 'hisp', 'hisp'] = 2\n",
    "\n",
    "# records where ETH doesn't indicate 'hispanic' but 'hisp' is 2 (is hispanic)\n",
    "# for these, keep the '2' value because the surveyed may leave 'ETH-hispanic' out when they feel\n",
    "# they have already provided the information in 'hisp'\n",
    "display(df.loc[(df.hisp_from_ETH != 'hisp') & (df.hisp == 2)][['ID','hisp','hisp_from_ETH',\n",
    "                                                                 'ETH1', 'ETH2', 'ETH3', 'ETH4']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create race_dmy_xx\n",
    "\n",
    "df['race_dmy_ind'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('American Indian/Alaska Native',na=False), 'race_dmy_ind'] = 1\n",
    "\n",
    "df['race_dmy_hwi'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('Native Hawaiian/Pacific Islander',na=False), 'race_dmy_hwi'] = 1\n",
    "\n",
    "df['race_dmy_blk'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('Black/African American',na=False), 'race_dmy_blk'] = 1\n",
    "\n",
    "df['race_dmy_wht'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('White/Caucasian',na=False), 'race_dmy_wht'] = 1\n",
    "\n",
    "df['race_dmy_asn'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('Asian',na=False), 'race_dmy_asn'] = 1\n",
    "\n",
    "df['race_dmy_mdl_estn'] = 0\n",
    "df.loc[df.ETH_concat.str.contains('Persian/Arab/North African/Middle Eastern',na=False), 'race_dmy_mdl_estn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop interim columns and export\n",
    "df.drop(columns = ['System_Before_1_temp', 'System_Before_2_temp', 'System_Before_3_temp',\n",
    "                   'System_Before_4_temp', 'System_After_1_temp', 'System_After_2_temp',\n",
    "                   'System_After_3_temp', 'System_After_4_temp', 'ETH1_temp', 'ETH2_temp',\n",
    "                   'ETH3_temp', 'ETH4_temp', 'ETH_concat', 'hisp_from_ETH'], inplace=True)\n",
    "\n",
    "df.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Napa Vine\\2019\\Napa Vine_FINAL Data_addCols_NO POUND OR SINGLE QUOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic_Variable that shouldn not exit:\n",
      "[]\n",
      "\n",
      "sys_RespNum\n",
      "RUNID\n",
      "Route\n",
      "com\n"
     ]
    }
   ],
   "source": [
    "# bring in standard dictionary to check field consistency\n",
    "\n",
    "# dictionary for Napa Vine survey\n",
    "var = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Napa Vine\\2019\\variable_dictionary.csv',\n",
    "                  encoding = \"ISO-8859-1\", engine='python')\n",
    "\n",
    "# standard dictionary\n",
    "var_standard = pd.read_csv(r'C:\\Users\\ywang\\Documents\\GitHub\\onboard-surveys\\make-uniform\\production\\Dictionary for Standard Database.csv')\n",
    "var_standard.columns = [x+'_s' for x in list(var_standard)]\n",
    "\n",
    "# merge\n",
    "var_merge = var.merge(var_standard, left_on='Generic_Variable', right_on='Generic_Variable_s', how='outer')\n",
    "\n",
    "# check if 'Generic_Variable' in Napa Vine dictionary matches the standard 'Generic_Variable'. chk1 should be empty\n",
    "chk1 = var_merge.loc[(var_merge.Generic_Variable.notnull()) & (var_merge.Generic_Variable_s.isnull())]\n",
    "print('Generic_Variable that shouldn not exit:')\n",
    "print(chk1.Generic_Variable.unique())\n",
    "print()\n",
    "\n",
    "# check if columns names in survey data matches 'Survey_Variable' in Napa Vine dictionary.\n",
    "# the following loops should not include variables that are needed for standardization\n",
    "\n",
    "for i in var.loc[var.Generic_Variable.notnull()]['Survey_Variable']:\n",
    "    if i not in list(df):\n",
    "        print(i)\n",
    "        \n",
    "for i in list(df):\n",
    "    if i not in list(var.Survey_Variable):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route_dir\n",
      "From\n",
      "To\n",
      "GetFirstBus\n",
      "[nan]\n",
      "totalbusBEFORE\n",
      "[nan]\n",
      "FromLastBus\n",
      "[nan]\n",
      "totalbusAFTER\n",
      "[nan]\n",
      "fare\n",
      "farecat\n",
      "cars\n",
      "hh\n",
      "hhwork\n",
      "hisp\n",
      "income\n",
      "langhh\n",
      "engspk\n",
      "[nan]\n",
      "sch\n",
      "work\n",
      "workafter\n",
      "[nan]\n",
      "workbefore\n",
      "[nan]\n",
      "schafter\n",
      "[nan]\n",
      "schbefore\n",
      "[nan]\n",
      "hometime_c1\n",
      "[nan]\n",
      "hometime_c2\n",
      "[nan]\n",
      "gender\n",
      "race_dmy_ind\n",
      "race_dmy_hwi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_dmy_blk\n",
      "race_dmy_wht\n",
      "race_dmy_asn\n",
      "race_dmy_mdl_estn\n"
     ]
    }
   ],
   "source": [
    "# check if all the values in the survey data are included in Napa Vine dictionary\n",
    "# look at non-categorical variables; \"diff\" should be empty or only contains nan\n",
    "\n",
    "var_clean = var[['operator', 'Survey_year', 'Survey_Variable', 'Survey_Response', \n",
    "                 'Generic_Variable', 'Generic_Response']].drop_duplicates()\n",
    "var_clean = var_clean.loc[var_clean.Generic_Variable.notnull()]\n",
    "\n",
    "for i in var_clean.loc[var_clean.Survey_Response != 'NONCATEGORICAL']['Survey_Variable'].unique():\n",
    "    print(i)\n",
    "    df_sub = df[['ID', i]]\n",
    "    var_sub = var_clean.loc[var_clean.Survey_Variable == i]\n",
    "    \n",
    "    if i in ['Route', 'From', 'To', 'GetFirstBus', 'totalbusBEFORE', 'FromLastBus', 'totalbusAFTER', 'fare', 'farecat',\n",
    "             'income', 'langhh', 'engspk', 'sch', 'work', 'workafter', 'workbefore',\n",
    "             'schafter', 'schbefore', 'hometime_c1', 'hometime_c2', 'gender',\n",
    "             'race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_mdl_estn']:\n",
    "        var_sub.Survey_Response = var_sub.Survey_Response.apply(lambda x: int(x))\n",
    "\n",
    "    if i in ['hh', 'cars', 'hhwork', 'hisp']:\n",
    "        df_sub[i] = df_sub[i].apply(lambda x: str(x))\n",
    "\n",
    "    compare = df_sub.merge(var_sub, left_on=i, right_on='Survey_Response', how='left')\n",
    "    diff = compare.loc[compare.Generic_Response.isnull()]\n",
    "    if diff.shape[0] > 0:\n",
    "        print(diff[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID' 'interview_start_time' 'interview_end_time' 'time_string'\n",
      " 'date_string' 'route' 'weight' 'tweight' 'orig_purp' 'dest_purp'\n",
      " 'orig_lat' 'orig_lon' 'dest_lat' 'dest_lon' 'access_mode'\n",
      " 'number_transfers_orig_board' 'egress_mode'\n",
      " 'number_transfers_alight_dest' 'first_route_before_survey_board'\n",
      " 'second_route_before_survey_board' 'third_route_before_survey_board'\n",
      " 'first_route_after_survey_alight' 'second_route_after_survey_alight'\n",
      " 'third_route_after_survey_alight' 'fare_medium' 'fare_category'\n",
      " 'vehicles' 'persons' 'workers' 'year_born_four_digit' 'hispanic'\n",
      " 'household_income' 'language_at_home_detail' 'eng_proficient' 'home_lat'\n",
      " 'home_lon' 'student_status' 'school_lat' 'school_lon' 'work_status'\n",
      " 'workplace_lat' 'workplace_lon' 'at_work_after_dest_purp'\n",
      " 'at_work_prior_to_orig_purp' 'at_school_after_dest_purp'\n",
      " 'at_school_prior_to_orig_purp' 'depart_hour' 'return_hour' 'gender'\n",
      " 'race_dmy_ind' 'race_dmy_hwi' 'race_dmy_blk' 'race_dmy_wht'\n",
      " 'race_dmy_asn' 'race_dmy_mdl_estn']\n"
     ]
    }
   ],
   "source": [
    "# finally, check all necessary fields are included, and export\n",
    "print(var_clean.Generic_Variable.unique())\n",
    "var_clean.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Napa Vine\\2019\\vars_for_standard_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# create raw transfer routes file\n",
    "routes = pd.DataFrame(columns = ['survey_name'])\n",
    "for i in ['first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "          'third_route_before_survey_board', 'first_route_after_survey_alight', \n",
    "          'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    route_unique = df[[i]]\n",
    "    route_unique.columns = ['survey_name']\n",
    "    routes = pd.concat([routes, route_unique])\n",
    "\n",
    "routes_clean = routes.loc[routes.survey_name.notnull()]\n",
    "routes_clean.drop_duplicates(inplace=True)\n",
    "routes_clean['survey'] = 'Napa Vine'\n",
    "routes_clean['survey_year'] = 2019\n",
    "\n",
    "print(routes_clean.shape)\n",
    "routes_clean[['survey','survey_year','survey_name']].to_csv(r'C:\\Users\\ywang\\Documents\\R\\OnboardSurvey_2020Oct_yq\\Data and Reports\\Napa Vine\\2019\\all_routes_raw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
