{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [modify survey data](#modify_survey_data)\n",
    "    * [read raw data](#read_raw_data)\n",
    "    * [build before_transfers and 'access_mode' from raw access mode fields](#build_access_mode)\n",
    "    * [build after_transfers and 'egress_mode' from raw access mode fields](#build_egress_mode)\n",
    "    * [deal with 'hispanic' and 'ethnicity/race'](#race)\n",
    "    * [deal with trip purpose](#trip_purp)\n",
    "    * [code home lat/lon based on zipcode](#home_lat_lon)\n",
    "    * [code board/alight station lat/lon](#station_lat_lon)\n",
    "    * [update 'weight'](#weight)\n",
    "    * [impute year_born from 'age group'](#age)\n",
    "    * [export survey data](#survey_export)\n",
    "\n",
    "* [build standard dictionary](#standard_dict)\n",
    "    * [read raw variable dictionary 'Field Guide'](#raw_dict)\n",
    "    * [add rows to the dictionary for the new fields added to the survey data](#add_row)\n",
    "    * [add default fields in the standard dictionary](#add_fields)\n",
    "    * [check consistency between values in survey data and in the dictionary](#check)\n",
    "    * [export raw standard dictionary](#export_dict)\n",
    "    \n",
    "* [build canonical route crosswalk](#canonical_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify survey data <a class=\"anchor\" id=\"modify_survey_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read raw data  <a class=\"anchor\" id=\"read_raw_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2406 records, with 2406 unique CCGID\n",
      "['RESPNUM', 'CCGID', 'TRAIN', 'INTDAY', 'INTDATE', 'PERIOD', 'LANGUAGE', 'Q1A', 'BOARD', 'Q1B', 'ALIGHT', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6', 'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6', 'Q3', 'Q4', 'Q5_1', 'Q5_2', 'Q5_3', 'Q5_4', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q7', 'Q8_1', 'Q8_2', 'Q8_3', 'Q8_4', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13_1', 'Q13_2', 'Q13_3', 'Q13_4', 'Q15_1', 'Q15_2', 'Q15_3', 'Q15_4', 'Q16_1', 'Q16_2', 'Q16_3', 'Q16_4', 'Q17', 'Q18', 'Q19', 'Unnamed: 57', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4', 'Q21', 'Q22', 'CITY', 'CITY_CODE', 'COUNTY', 'COUNTY_CODE ', 'STATE', 'STATE_CODE ', 'COUNTRY', 'WEIGHT']\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\CAPCO19 Data-For MTC.xlsx',\n",
    "                       sheet_name='Data')\n",
    "print('read {} records, with {} unique CCGID'.format(df_raw.shape[0], len(df_raw.CCGID.unique())))\n",
    "\n",
    "df = df_raw.copy()\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build before_transfers and 'access_mode' from raw access mode fields Q2A_1-Q2A_6 <a class=\"anchor\" id=\"build_access_mode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>Q2A_1</th>\n",
       "      <th>Q2A_2</th>\n",
       "      <th>Q2A_3</th>\n",
       "      <th>Q2A_4</th>\n",
       "      <th>Q2A_5</th>\n",
       "      <th>Q2A_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11+H13:H32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CCGID  Q2A_1  Q2A_2       Q2A_3  Q2A_4  Q2A_5  Q2A_6\n",
       "62     63      4    NaN  11+H13:H32    NaN    NaN    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "row dictionary of Q2A_1-Q2A_6 / Q2B_1-Q2B_6:\n",
    "\n",
    "   {1: 'Dropped off/Picked up', \n",
    "    2: 'Drove alone', \n",
    "    3: 'Carpool', \n",
    "    4: 'Taxi/Uber/Lyft', \n",
    "    5: 'BART', \n",
    "    6: 'Caltrain', \n",
    "    7: 'Light rail (VTA, Sacramento RT)', \n",
    "    8: 'Amtrak thruway bus', \n",
    "    9: 'Amtrak long distance train', \n",
    "    10: 'Bus transit', \n",
    "    11: 'Walked', \n",
    "    12: 'Bike', \n",
    "    13: 'Electric Scooter/Scooter', \n",
    "    14: 'Other (Specify)' \n",
    "    }\n",
    "\"\"\"\n",
    "## create fields\n",
    "\n",
    "for colname in ['access_mode', 'egress_mode',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board', 'third_route_before_survey_board',\n",
    "                'first_route_after_survey_alight', 'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    df[colname] = np.nan\n",
    "    \n",
    "# first, error in CCGID 63 Q2A_3, update to nan\n",
    "display(df.loc[df.CCGID == 63][['CCGID', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6']])\n",
    "df.loc[df.CCGID == 63, 'Q2A_3'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_1 find 1923 rows, 79.9% of total\n",
      "idx_2 find 303 rows, 12.6% of total\n",
      "idx_3 find 18 rows, 0.7% of total\n",
      "idx_4 find 4 rows, 0.2% of total\n",
      "idx_5 find 87 rows, 3.6% of total\n",
      "idx_6 find 27 rows, 1.1% of total\n",
      "idx_7 find 1 rows, 0.0% of total\n",
      "idx_8 find 11 rows, 0.5% of total\n",
      "idx_9 find 3 rows, 0.1% of total\n",
      "idx_10 find 0 rows, 0.0% of total\n",
      "idx_11 find 1 rows, 0.0% of total\n",
      "idx_12 find 25 rows, 1.0% of total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>Q2A_1</th>\n",
       "      <th>Q2A_2</th>\n",
       "      <th>Q2A_3</th>\n",
       "      <th>Q2A_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>969</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1122</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2039</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CCGID  Q2A_1  Q2A_2 Q2A_3  Q2A_4\n",
       "967     969      8    4.0     9   10.0\n",
       "1120   1122     10    1.0     4   12.0\n",
       "2037   2039     10   11.0     7    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. for responses with Q2A_1 only and Q2A_1 is not public transit, set Q2A_1 as access mode, and no before-transfer\n",
    "idx_1 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (     # Q2A_1 not public transit\n",
    "    df['Q2A_1'].notnull() &\n",
    "    df['Q2A_2'].isnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_1 find {} rows, {:.1%} of total'.format(idx_1.sum(), idx_1.sum()/df.shape[0]))\n",
    "df.loc[idx_1, 'access_mode'] = df['Q2A_1']\n",
    "\n",
    "# 2. for responses with Q2A_1 only and Q2A_1 is public transit, set access mode as Missing, and Q2A_1 as before-transfer\n",
    "idx_2 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "    df['Q2A_1'].notnull() &\n",
    "    df['Q2A_2'].isnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_2 find {} rows, {:.1%} of total'.format(idx_2.sum(), idx_2.sum()/df.shape[0]))\n",
    "df.loc[idx_2, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_2, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "# 3. for responses with Q2A_1 and Q2A_2 only, and Q2A_1 is public transit, Q2A_2 is not public transit, \n",
    "# set access mode as Missing, and Q2A_1 as before-transfer\n",
    "idx_3 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "         (df['Q2A_2'] < 5) | (df['Q2A_2'] > 10)) & (    # Q2A_2 not public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_3 find {} rows, {:.1%} of total'.format(idx_3.sum(), idx_3.sum()/df.shape[0]))\n",
    "df.loc[idx_3, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_3, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "# 4. for responses with Q2A_1 and Q2A_2 only, and both are public transit \n",
    "# set access mode as Missing, and Q2A_1, Q2A_2 as before-transfers\n",
    "idx_4 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "         (df['Q2A_2'] > 4) & (df['Q2A_2'] < 11)) & (    # Q2A_2 public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_4 find {} rows, {:.1%} of total'.format(idx_4.sum(), idx_4.sum()/df.shape[0]))\n",
    "df.loc[idx_4, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_4, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "df.loc[idx_4, 'second_route_before_survey_board'] = df['Q2A_2']\n",
    "\n",
    "# 5. for responses with Q2A_1 and Q2A_2 only, and both are not public transit\n",
    "# set access mode as Q2A_1, and no before-transfer\n",
    "idx_5 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (    # Q2A_1 not public transit\n",
    "         (df['Q2A_2'] < 5) | (df['Q2A_2'] > 10)) & (    # Q2A_2 not public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_5 find {} rows, {:.1%} of total'.format(idx_5.sum(), idx_5.sum()/df.shape[0]))\n",
    "df.loc[idx_5, 'access_mode'] =  df['Q2A_1']\n",
    "\n",
    "# 6. for responses with Q2A_1 and Q2A_2 only, and Q2A_1 is not public transit, Q2A_2 is public transit,\n",
    "# set access mode as Q2A_1, Q2A_2 is before-transfer\n",
    "idx_6 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (    # Q2A_1 not public transit\n",
    "         (df['Q2A_2'] > 4) & (df['Q2A_2'] < 11)) & (    # Q2A_2 public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].isnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_6 find {} rows, {:.1%} of total'.format(idx_6.sum(), idx_6.sum()/df.shape[0]))\n",
    "df.loc[idx_6, 'access_mode'] =  df['Q2A_1']\n",
    "df.loc[idx_6, 'first_route_before_survey_board'] = df['Q2A_2']\n",
    "\n",
    "# 7. for responses with Q2A_1, Q2A_2, and Q2A_3 only, and all three are public transit,\n",
    "# set access mode as Missing, and Q2A_1, Q2A_2, Q2A_3 as before-transfers\n",
    "idx_7 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "         (df['Q2A_2'] > 4) & (df['Q2A_2'] < 11)) & (    # Q2A_2 public transit\n",
    "         (df['Q2A_3'] > 4) & (df['Q2A_3'] < 11)) & (    # Q2A_3 public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].notnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_7 find {} rows, {:.1%} of total'.format(idx_7.sum(), idx_7.sum()/df.shape[0]))\n",
    "df.loc[idx_7, 'access_mode'] =  'Missing'\n",
    "df.loc[idx_7, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "df.loc[idx_7, 'second_route_before_survey_board'] = df['Q2A_2']\n",
    "df.loc[idx_7, 'third_route_before_survey_board'] = df['Q2A_3']\n",
    "\n",
    "# 8. for responses with Q2A_1, Q2A_2, and Q2A_3 only, and all three are not public transit,\n",
    "# set access mode as Q2A_1, and no before-transfer\n",
    "idx_8 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (    # Q2A_1 not public transit\n",
    "         (df['Q2A_2'] < 5) | (df['Q2A_2'] > 10)) & (    # Q2A_2 not public transit\n",
    "         (df['Q2A_3'] < 5) | (df['Q2A_3'] > 10)) & (    # Q2A_3 not public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].notnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_8 find {} rows, {:.1%} of total'.format(idx_8.sum(), idx_8.sum()/df.shape[0]))\n",
    "df.loc[idx_8, 'access_mode'] =  df['Q2A_1']\n",
    "\n",
    "# 9. for responses with Q2A_1, Q2A_2, and Q2A_3 only, and Q2A_1 is public transit, Q2A_2 and Q2A_3 not public transit,\n",
    "# set access mode as Missing, and Q2A_1 as before-transfer\n",
    "idx_9 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "         (df['Q2A_2'] < 5) | (df['Q2A_2'] > 10)) & (    # Q2A_2 not public transit\n",
    "         (df['Q2A_3'] < 5) | (df['Q2A_3'] > 10)) & (    # Q2A_3 not public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].notnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_9 find {} rows, {:.1%} of total'.format(idx_9.sum(), idx_9.sum()/df.shape[0]))\n",
    "df.loc[idx_9, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_9, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "# 10. for responses with Q2A_1, Q2A_2, and Q2A_3 only, and Q2A_1, Q2A_2 are public transit, Q2A_3 not public transit,\n",
    "# set access mode as Missing, and Q2A_1, Q2A_2 as before-transfers\n",
    "idx_10 = ((df['Q2A_1'] > 4) & (df['Q2A_1'] < 11)) & (    # Q2A_1 public transit\n",
    "          (df['Q2A_2'] > 4) & (df['Q2A_2'] < 11)) & (    # Q2A_2 public transit\n",
    "          (df['Q2A_3'] < 5) | (df['Q2A_3'] > 10)) & (    # Q2A_3 not public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].notnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_10 find {} rows, {:.1%} of total'.format(idx_10.sum(), idx_10.sum()/df.shape[0]))\n",
    "df.loc[idx_10, 'access_mode'] =  'Missing'\n",
    "df.loc[idx_10, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "df.loc[idx_10, 'second_route_before_survey_board'] = df['Q2A_2']\n",
    "\n",
    "# 11. for responses with Q2A_1, Q2A_2, and Q2A_3 only, and Q2A_1 is not public transit, Q2A_2/Q2A_3 are public transit,\n",
    "# set access mode as Q2A_1, and Q2A_2, Q2A_3 as before-transfers\n",
    "idx_11 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (    # Q2A_1 not public transit\n",
    "          (df['Q2A_2'] > 4) & (df['Q2A_2'] < 11)) & (    # Q2A_2 public transit\n",
    "          (df['Q2A_3'] > 4) & (df['Q2A_3'] < 11)) & (    # Q2A_3 public transit\n",
    "    df['Q2A_1'].notnull() & \n",
    "    df['Q2A_2'].notnull() & \n",
    "    df['Q2A_3'].notnull() & \n",
    "    df['Q2A_4'].isnull() & \n",
    "    df['Q2A_5'].isnull() & \n",
    "    df['Q2A_6'].isnull())\n",
    "\n",
    "print('idx_11 find {} rows, {:.1%} of total'.format(idx_11.sum(), idx_11.sum()/df.shape[0]))\n",
    "df.loc[idx_11, 'access_mode'] = df['Q2A_1']\n",
    "df.loc[idx_11, 'first_route_before_survey_board'] = df['Q2A_2']\n",
    "df.loc[idx_11, 'second_route_before_survey_board'] = df['Q2A_3']\n",
    "\n",
    "# for the rest (access_mode still is nan), if Q2A_1 is not public transit, set access mode as Q2A_1, and no before-transfer\n",
    "idx_12 = ((df['Q2A_1'] < 5) | (df['Q2A_1'] > 10)) & (    # Q2A_1 not public transit\n",
    "          df.access_mode.isnull())\n",
    "\n",
    "print('idx_12 find {} rows, {:.1%} of total'.format(idx_12.sum(), idx_12.sum()/df.shape[0]))\n",
    "\n",
    "df.loc[idx_12, 'access_mode'] = df['Q2A_1']\n",
    "# df.loc[idx_12][['CCGID', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6']].dropna(how='all', axis=1).drop_duplicates()\n",
    "\n",
    "# examine the remaining access_mode.isnull()\n",
    "display(df.loc[df.access_mode.isnull()][['CCGID', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6']].dropna(how='all', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows is missing access_mode\n"
     ]
    }
   ],
   "source": [
    "# for CCGID 969 (Q2A_1 'Amtrak long-distance bus', Q2A_2 'taxi/uber/lyft', Q2A_3 'Amtrak train', Q2A_4 'bus', \n",
    "# set Q2A_1 as before-transfer, and access_mode as Missing\n",
    "df.loc[df.CCGID==969, 'access_mode'] = 'Missing'\n",
    "df.loc[df.CCGID==969, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "# for CCGID 1122 (Q2A_1 'bus', Q2A_2 'drop off/pick up', Q2A_3 'taxi/uber/lyft', Q2A_4 'bike', \n",
    "# set Q2A_1 as before-transfer, and access_mode as Missing\n",
    "df.loc[df.CCGID==1122, 'access_mode'] = 'Missing'\n",
    "df.loc[df.CCGID==1122, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "# for CCGID 2039 (Q2A_1 'bus', Q2A_2 'walk', Q2A_3 'light rail' \n",
    "# set Q2A_1, Q2A_3 as before-transfers, and access_mode as Missing\n",
    "df.loc[df.CCGID==2039, 'access_mode'] = 'Missing'\n",
    "df.loc[df.CCGID==2039, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "df.loc[df.CCGID==2039, 'second_route_before_survey_board'] = df['Q2A_3']\n",
    "\n",
    "# check there is no row with access_mode.isnull()\n",
    "print('{} rows is missing access_mode'.format(df.access_mode.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build after_transfers and 'egress_mode' from raw access mode fields Q2B_1-Q2B_6  <a class=\"anchor\" id=\"build_egress_mode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_1 find 1886 rows, 78.4% of total\n",
      "idx_2 find 329 rows, 13.7% of total\n",
      "idx_3 find 48 rows, 2.0% of total\n",
      "idx_4 find 6 rows, 0.2% of total\n",
      "idx_5 find 64 rows, 2.7% of total\n",
      "idx_6 find 28 rows, 1.2% of total\n",
      "idx_7 find 1 rows, 0.0% of total\n",
      "idx_8 find 12 rows, 0.5% of total\n",
      "idx_9 find 5 rows, 0.2% of total\n",
      "idx_10 find 3 rows, 0.1% of total\n",
      "idx_11 find 0 rows, 0.0% of total\n",
      "idx_12 find 20 rows, 0.8% of total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>Q2B_1</th>\n",
       "      <th>Q2B_2</th>\n",
       "      <th>Q2B_3</th>\n",
       "      <th>Q2B_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>443</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>468</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>572</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1659</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CCGID  Q2B_1  Q2B_2  Q2B_3  Q2B_4\n",
       "441     443      5    7.0   11.0    2.0\n",
       "466     468      7   11.0   10.0    NaN\n",
       "570     572     10   11.0   12.0   13.0\n",
       "1657   1659      6    1.0   10.0    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. for responses with Q2B_1 only and Q2B_1 is not public transit, set Q2B_1 as egress mode, and no after-transfer\n",
    "idx_1 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (     # Q2B_1 not public transit\n",
    "    df['Q2B_1'].notnull() &\n",
    "    df['Q2B_2'].isnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_1 find {} rows, {:.1%} of total'.format(idx_1.sum(), idx_1.sum()/df.shape[0]))\n",
    "df.loc[idx_1, 'egress_mode'] = df['Q2B_1']\n",
    "\n",
    "# 2. for responses with Q2B_1 only and Q2B_1 is public transit, set egress mode as Missing, and Q2B_1 as after-transfer\n",
    "idx_2 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "    df['Q2B_1'].notnull() &\n",
    "    df['Q2B_2'].isnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_2 find {} rows, {:.1%} of total'.format(idx_2.sum(), idx_2.sum()/df.shape[0]))\n",
    "df.loc[idx_2, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_2, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "# 3. for responses with Q2B_1 and Q2B_2 only, and Q2B_1 is public transit, Q2B_2 is not public transit, \n",
    "# set egress mode as Q2B_2, and Q2B_1 as after-transfer\n",
    "idx_3 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "         (df['Q2B_2'] < 5) | (df['Q2B_2'] > 10)) & (    # Q2B_2 not public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_3 find {} rows, {:.1%} of total'.format(idx_3.sum(), idx_3.sum()/df.shape[0]))\n",
    "df.loc[idx_3, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[idx_3, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "# 4. for responses with Q2B_1 and Q2B_2 only, and both are public transit \n",
    "# set egress mode as Missing, and Q2B_1, Q2B_2 as after-transfers\n",
    "idx_4 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "         (df['Q2B_2'] > 4) & (df['Q2B_2'] < 11)) & (    # Q2B_2 public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_4 find {} rows, {:.1%} of total'.format(idx_4.sum(), idx_4.sum()/df.shape[0]))\n",
    "df.loc[idx_4, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_4, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[idx_4, 'second_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "# 5. for responses with Q2B_1 and Q2B_2 only, and both are not public transit\n",
    "# set egress mode as Q2B_1, and no after-transfer\n",
    "idx_5 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (    # Q2B_1 not public transit\n",
    "         (df['Q2B_2'] < 5) | (df['Q2B_2'] > 10)) & (    # Q2B_2 not public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_5 find {} rows, {:.1%} of total'.format(idx_5.sum(), idx_5.sum()/df.shape[0]))\n",
    "df.loc[idx_5, 'egress_mode'] =  df['Q2B_1']\n",
    "\n",
    "# 6. for responses with Q2B_1 and Q2B_2 only, and Q2B_1 is not public transit, Q2B_2 is public transit,\n",
    "# set egress mode as Missing, Q2B_2 is after-transfer\n",
    "idx_6 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (    # Q2B_1 not public transit\n",
    "         (df['Q2B_2'] > 4) & (df['Q2B_2'] < 11)) & (    # Q2B_2 public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].isnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_6 find {} rows, {:.1%} of total'.format(idx_6.sum(), idx_6.sum()/df.shape[0]))\n",
    "df.loc[idx_6, 'egress_mode'] =  'Missing'\n",
    "df.loc[idx_6, 'first_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "# 7. for responses with Q2B_1, Q2B_2, and Q2B_3 only, and all three are public transit,\n",
    "# set egress mode as Missing, and Q2B_1, Q2B_2, Q2B_3 as after-transfers\n",
    "idx_7 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "         (df['Q2B_2'] > 4) & (df['Q2B_2'] < 11)) & (    # Q2B_2 public transit\n",
    "         (df['Q2B_3'] > 4) & (df['Q2B_3'] < 11)) & (    # Q2B_3 public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].notnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_7 find {} rows, {:.1%} of total'.format(idx_7.sum(), idx_7.sum()/df.shape[0]))\n",
    "df.loc[idx_7, 'egress_mode'] =  'Missing'\n",
    "df.loc[idx_7, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[idx_7, 'second_route_after_survey_alight'] = df['Q2B_2']\n",
    "df.loc[idx_7, 'third_route_after_survey_alight'] = df['Q2B_3']\n",
    "\n",
    "# 8. for responses with Q2B_1, Q2B_2, and Q2B_3 only, and all three are not public transit,\n",
    "# set egress mode as Q2B_1, and no after-transfer\n",
    "idx_8 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (    # Q2B_1 not public transit\n",
    "         (df['Q2B_2'] < 5) | (df['Q2B_2'] > 10)) & (    # Q2B_2 not public transit\n",
    "         (df['Q2B_3'] < 5) | (df['Q2B_3'] > 10)) & (    # Q2B_3 not public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].notnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_8 find {} rows, {:.1%} of total'.format(idx_8.sum(), idx_8.sum()/df.shape[0]))\n",
    "df.loc[idx_8, 'egress_mode'] = df['Q2B_1']\n",
    "\n",
    "# 9. for responses with Q2B_1, Q2B_2, and Q2B_3 only, and Q2B_1 is public transit, Q2B_2 and Q2B_3 not public transit,\n",
    "# set egress mode as Q2B_2, and Q2B_1 as after-transfer\n",
    "idx_9 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "         (df['Q2B_2'] < 5) | (df['Q2B_2'] > 10)) & (    # Q2B_2 not public transit\n",
    "         (df['Q2B_3'] < 5) | (df['Q2B_3'] > 10)) & (    # Q2B_3 not public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].notnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_9 find {} rows, {:.1%} of total'.format(idx_9.sum(), idx_9.sum()/df.shape[0]))\n",
    "df.loc[idx_9, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[idx_9, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "# 10. for responses with Q2B_1, Q2B_2, and Q2B_3 only, and Q2B_1, Q2B_2 are public transit, Q2B_3 not public transit,\n",
    "# set egress mode as Q2B_3, and Q2B_1, Q2B_2 as after-transfers\n",
    "idx_10 = ((df['Q2B_1'] > 4) & (df['Q2B_1'] < 11)) & (    # Q2B_1 public transit\n",
    "          (df['Q2B_2'] > 4) & (df['Q2B_2'] < 11)) & (    # Q2B_2 public transit\n",
    "          (df['Q2B_3'] < 5) | (df['Q2B_3'] > 10)) & (    # Q2B_3 not public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].notnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_10 find {} rows, {:.1%} of total'.format(idx_10.sum(), idx_10.sum()/df.shape[0]))\n",
    "df.loc[idx_10, 'egress_mode'] = df['Q2B_3']\n",
    "df.loc[idx_10, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[idx_10, 'second_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "# 11. for responses with Q2B_1, Q2B_2, and Q2B_3 only, and Q2B_1 is not public transit, Q2B_2/Q2B_3 are public transit,\n",
    "# set egress mode as Q2B_1, and no after-transfer\n",
    "idx_11 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (    # Q2B_1 not public transit\n",
    "          (df['Q2B_2'] > 4) & (df['Q2B_2'] < 11)) & (    # Q2B_2 public transit\n",
    "          (df['Q2B_3'] > 4) & (df['Q2B_3'] < 11)) & (    # Q2B_3 public transit\n",
    "    df['Q2B_1'].notnull() & \n",
    "    df['Q2B_2'].notnull() & \n",
    "    df['Q2B_3'].notnull() & \n",
    "    df['Q2B_4'].isnull() & \n",
    "    df['Q2B_5'].isnull() & \n",
    "    df['Q2B_6'].isnull())\n",
    "\n",
    "print('idx_11 find {} rows, {:.1%} of total'.format(idx_11.sum(), idx_11.sum()/df.shape[0]))\n",
    "df.loc[idx_11, 'egress_mode'] = df['Q2B_1']\n",
    "\n",
    "# for the rest (egress_mode still is nan), if Q2B_1 is not public transit, set egress mode as Q2B_1, and no after-transfer\n",
    "idx_12 = ((df['Q2B_1'] < 5) | (df['Q2B_1'] > 10)) & (    # Q2B_1 not public transit\n",
    "          df.egress_mode.isnull())\n",
    "\n",
    "print('idx_12 find {} rows, {:.1%} of total'.format(idx_12.sum(), idx_12.sum()/df.shape[0]))\n",
    "\n",
    "df.loc[idx_12, 'egress_mode'] = df['Q2B_1']\n",
    "# df.loc[idx_12][['CCGID', 'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']].dropna(how='all', axis=1).drop_duplicates()\n",
    "\n",
    "# examine the remaining egress_mode.isnull()\n",
    "display(df.loc[df.egress_mode.isnull()][['CCGID', 'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']].dropna(how='all', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows is missing egress_mode\n"
     ]
    }
   ],
   "source": [
    "# for CCGID 443 (Q2B_1 'BART', Q2B_2 'Light rail', Q2B_3 'walk', Q2B_4 'drove-alone')\n",
    "# set Q2B_1, Q2B_2 as after-transfer, and egress_mode as Q2B_3\n",
    "df.loc[df.CCGID==443, 'egress_mode'] = df['Q2B_3']\n",
    "df.loc[df.CCGID==443, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[df.CCGID==443, 'second_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "# for CCGID 468 (Q2B_1 'light rail', Q2B_2 'walk', Q2B_3 'bus')\n",
    "# set Q2B_1 and Q2B_3 as after-transfer, and egress_mode as Missing\n",
    "df.loc[df.CCGID==468, 'egress_mode'] = 'Missing'\n",
    "df.loc[df.CCGID==468, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[df.CCGID==468, 'second_route_after_survey_alight'] = df['Q2B_3']\n",
    "\n",
    "# for CCGID 572 (Q2B_1 'bus', Q2B_2 'walk', Q2B_3 'bike', Q2B_4 'scooter') \n",
    "# set Q2B_1 as after-transfer, and egress_mode as Q2B_2\n",
    "df.loc[df.CCGID==572, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[df.CCGID==572, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "# for CCGID 1659 (Q2B_1 'Caltrain', Q2B_2 'drop off/pick up', Q2B_3 'bus')\n",
    "# set Q2B_1 as after-transfer, and egress_mode as Q2B_2\n",
    "df.loc[df.CCGID==1659, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[df.CCGID==1659, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "# check there is no row with egress_mode.isnull()\n",
    "print('{} rows is missing egress_mode'.format(df.egress_mode.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with 'hispanic' and 'ethnicity/race'  <a class=\"anchor\" id=\"race\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hispanic/Latino_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Middle Eastern_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_Middle Eastern_Middle Eastern_Middle Eastern', 'Black/African American_Middle Eastern_Middle Eastern_Middle Eastern', 'Other_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Hispanic/Latino_Middle Eastern_Middle Eastern', 'Mixed_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_Middle Eastern_Middle Eastern', 'White_Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern', 'NA_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_Asian/Pacific Islander_Middle Eastern', 'American Indian/Alaskan Native_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_American Indian/Alaskan Native_Middle Eastern', 'Asian/Pacific Islander_Hispanic/Latino_Middle Eastern_Middle Eastern', 'White_Black/African American_Asian/Pacific Islander_Hispanic/Latino', 'Black/African American_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern', 'White_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Black/African American_Other_Middle Eastern_Middle Eastern', 'White_Asian/Pacific Islander_Hispanic/Latino_American Indian/Alaskan Native', 'White_Black/African American_Hispanic/Latino_American Indian/Alaskan Native', 'White_American Indian/Alaskan Native_Middle Eastern_Middle Eastern', 'White_East Indian/Pakistani_Middle Eastern_Middle Eastern', 'Middle Eastern_Middle Eastern_Middle Eastern_Middle Eastern', 'East Indian/Pakistani_Middle Eastern_Middle Eastern_Middle Eastern', 'Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern_Middle Eastern', 'White_Black/African American_Hispanic/Latino_Middle Eastern', 'Hispanic/Latino_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_White_Middle Eastern_Middle Eastern', 'Black/African American_Hispanic/Latino_Middle Eastern_Middle Eastern', 'White_Asian/Pacific Islander_American Indian/Alaskan Native_Middle Eastern']\n"
     ]
    }
   ],
   "source": [
    "race_dict = {1: 'White',\n",
    "             2: 'Black/African American',\n",
    "             3: 'Asian/Pacific Islander',\n",
    "             4: 'Hispanic/Latino',\n",
    "             5: 'American Indian/Alaskan Native',\n",
    "             6: 'Other',\n",
    "             7: 'Other',\n",
    "             8: 'Other',\n",
    "             9: 'Mixed',\n",
    "             10: 'Middle Eastern',\n",
    "             11: 'East Indian/Pakistani',\n",
    "             0: 'NA'}\n",
    "\n",
    "for i in ['Q20_1', 'Q20_2', 'Q20_3', 'Q20_4']:\n",
    "    df[i] = df[i].fillna(10)\n",
    "    df[i].replace(to_replace = ' ', value = 10, inplace=True)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(race_dict)\n",
    "    \n",
    "df['race_concat'] = df['Q20_1_temp'] + '_' + df['Q20_2_temp'] + '_' + df['Q20_3_temp'] + '_' + df['Q20_4_temp']\n",
    "print(list(df['race_concat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     2142\n",
       "YES     264\n",
       "Name: hispanic, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'hispanic' field\n",
    "df['hispanic'] = 'NO'\n",
    "df.loc[df.race_concat.str.contains('Hispanic',na=False), 'hispanic'] = 'YES'\n",
    "df.hispanic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create race_dmy_xx\n",
    "\n",
    "df['race_dmy_ind'] = 0\n",
    "df.loc[df.race_concat.str.contains('American Indian/Alaskan Native',na=False), 'race_dmy_ind'] = 1\n",
    "\n",
    "df['race_dmy_hwi'] = 0\n",
    "df.loc[df.race_concat.str.contains('Native Hawaiian/Pacific Islander',na=False), 'race_dmy_hwi'] = 1\n",
    "\n",
    "df['race_dmy_blk'] = 0\n",
    "df.loc[df.race_concat.str.contains('Black/African American',na=False), 'race_dmy_blk'] = 1\n",
    "\n",
    "df['race_dmy_wht'] = 0\n",
    "df.loc[df.race_concat.str.contains('White',na=False), 'race_dmy_wht'] = 1\n",
    "\n",
    "df['race_dmy_asn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Asian',na=False) | df.race_concat.str.contains('East Indian/Pakistani',na=False), 'race_dmy_asn'] = 1\n",
    "\n",
    "df['race_dmy_mdl_estn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Middle Eastern',na=False), 'race_dmy_mdl_estn'] = 1\n",
    "\n",
    "# drop temp fields\n",
    "df.drop(columns = ['Q20_1_temp', 'Q20_2_temp', 'Q20_3_temp', 'Q20_4_temp', 'race_concat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with trip purpose <a class=\"anchor\" id=\"trip_purp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_3</th>\n",
       "      <th>Q8_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Moving/traveling between homes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Church/volunteering/political</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Personal / Family business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Personal / Family business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Airport trip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Going Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Moving/traveling between homes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Vacation</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Q8_1                            Q8_2  \\\n",
       "0               Visit family/friends                             NaN   \n",
       "1                 Leisure/Recreation                             NaN   \n",
       "2              Travel to/from school                             NaN   \n",
       "3                 Leisure/Recreation            Visit family/friends   \n",
       "4                                NaN                             NaN   \n",
       "6                           Vacation                             NaN   \n",
       "8                              Other                             NaN   \n",
       "14              Commute to/from work                             NaN   \n",
       "23                   Business travel                             NaN   \n",
       "34              Visit family/friends                        Vacation   \n",
       "52                Leisure/Recreation  Moving/traveling between homes   \n",
       "79              Commute to/from work           Travel to/from school   \n",
       "84     Church/volunteering/political                             NaN   \n",
       "85                   Business travel            Visit family/friends   \n",
       "95                Leisure/Recreation            Visit family/friends   \n",
       "96        Personal / Family business                             NaN   \n",
       "131             Commute to/from work              Leisure/Recreation   \n",
       "188                  Business travel              Leisure/Recreation   \n",
       "215            Travel to/from school              Leisure/Recreation   \n",
       "278             Visit family/friends      Personal / Family business   \n",
       "316             Commute to/from work            Visit family/friends   \n",
       "428                  Business travel              Leisure/Recreation   \n",
       "480             Commute to/from work                 Business travel   \n",
       "561                  Business travel              Leisure/Recreation   \n",
       "813             Commute to/from work                 Business travel   \n",
       "844                     Airport trip                             NaN   \n",
       "905                       Going Home                             NaN   \n",
       "910               Leisure/Recreation                        Vacation   \n",
       "929             Commute to/from work           Travel to/from school   \n",
       "941               Leisure/Recreation            Commute to/from work   \n",
       "1087           Travel to/from school              Leisure/Recreation   \n",
       "1133            Commute to/from work                 Business travel   \n",
       "1209  Moving/traveling between homes                             NaN   \n",
       "1473            Commute to/from work                 Business travel   \n",
       "1792           Travel to/from school            Visit family/friends   \n",
       "1971                        Vacation              Leisure/Recreation   \n",
       "1992              Leisure/Recreation                           Other   \n",
       "2011                 Business travel              Leisure/Recreation   \n",
       "2275                 Business travel                        Vacation   \n",
       "\n",
       "                       Q8_3                  Q8_4  \n",
       "0                       NaN                   NaN  \n",
       "1                       NaN                   NaN  \n",
       "2                       NaN                   NaN  \n",
       "3                       NaN                   NaN  \n",
       "4                       NaN                   NaN  \n",
       "6                       NaN                   NaN  \n",
       "8                       NaN                   NaN  \n",
       "14                      NaN                   NaN  \n",
       "23                      NaN                   NaN  \n",
       "34                      NaN                   NaN  \n",
       "52                      NaN                   NaN  \n",
       "79                      NaN                   NaN  \n",
       "84                      NaN                   NaN  \n",
       "85                      NaN                   NaN  \n",
       "95                 Vacation                   NaN  \n",
       "96                      NaN                   NaN  \n",
       "131                     NaN                   NaN  \n",
       "188                Vacation                   NaN  \n",
       "215                     NaN                   NaN  \n",
       "278                     NaN                   NaN  \n",
       "316                     NaN                   NaN  \n",
       "428                     NaN                   NaN  \n",
       "480                     NaN                   NaN  \n",
       "561    Visit family/friends              Vacation  \n",
       "813      Leisure/Recreation  Visit family/friends  \n",
       "844                     NaN                   NaN  \n",
       "905                     NaN                   NaN  \n",
       "910                     NaN                   NaN  \n",
       "929                Vacation                   NaN  \n",
       "941                     NaN                   NaN  \n",
       "1087   Visit family/friends                   NaN  \n",
       "1133  Travel to/from school    Leisure/Recreation  \n",
       "1209                    NaN                   NaN  \n",
       "1473   Visit family/friends              Vacation  \n",
       "1792                    NaN                   NaN  \n",
       "1971                    NaN                   NaN  \n",
       "1992                    NaN                   NaN  \n",
       "2011   Visit family/friends                   NaN  \n",
       "2275                    NaN                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trip_purp_dict = {\n",
    "    '1': 'Commute to/from work', \n",
    "    '2': 'Business travel', \n",
    "    '3': 'Travel to/from school', \n",
    "    '4': 'Leisure/Recreation', \n",
    "    '5': 'Visit family/friends', \n",
    "    '6': 'Vacation', \n",
    "    '7': 'Other', \n",
    "    '8': 'Personal / Family business', \n",
    "    '9': 'Travel to or from school', \n",
    "    '10': 'Other (specify)', \n",
    "    '11': 'School/ Group Trip', \n",
    "    '12': 'Church/volunteering/political', \n",
    "    '13': 'Just to enjoy the train/Outing to ride train', \n",
    "    '14': 'Moving/traveling between homes', \n",
    "    '15': 'Going Home', \n",
    "    '16': 'Airport trip'}\n",
    "\n",
    "for colname in ['Q8_1','Q8_2','Q8_3','Q8_4']:\n",
    "    df[colname].fillna(0, inplace=True)\n",
    "    df[colname] = df[colname].apply(lambda x: str(int(x)))\n",
    "    df[colname] = df[colname].map(trip_purp_dict)\n",
    "\n",
    "# print out all possible combinations in the data\n",
    "display(df[['Q8_1','Q8_2','Q8_3','Q8_4']].dropna(how='all', axis=1).drop_duplicates())\n",
    "\n",
    "\n",
    "# take Q8_1 as trip_purp\n",
    "df['trip_purp'] = df['Q8_1']\n",
    "df.loc[df.trip_purp.isnull(), 'trip_purp'] = 'missing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code home lat/lon based on zipcode <a class=\"anchor\" id=\"home_lat_lon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 records are missing home lat/lon, accounting for 26.1% of all\n"
     ]
    }
   ],
   "source": [
    "# read zipcode spatial data\n",
    "zip_shp = gpd.read_file(r'M:\\Data\\GIS layers\\zip_code_sr\\zip_code_sr.shp')\n",
    "\n",
    "# get lat/lon\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = zip_shp['geometry'].centroid\n",
    "x,y = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "\n",
    "zip_shp['lat'] = y\n",
    "zip_shp['lon'] = x\n",
    "\n",
    "zip_shp['postcode'] = zip_shp['postcode'].apply(lambda x: int(x))\n",
    "\n",
    "# merge into the survey data\n",
    "df = df.merge(zip_shp[['postcode', 'lat', 'lon']], left_on='Q22', right_on='postcode', how='left')\n",
    "\n",
    "no_latlon = df.loc[df.lat.isnull() | df.lon.isnull()].shape[0]\n",
    "print('{} records are missing home lat/lon, accounting for {:.1%} of all'.format(no_latlon, no_latlon/df.shape[0]))\n",
    "\n",
    "# rename\n",
    "df.rename(columns = {'lat': 'home_lat',\n",
    "                     'lon': 'home_lon'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code board/alight station lat/lon <a class=\"anchor\" id=\"station_lat_lon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6    78\n",
       "7    55\n",
       "Name: Q1A, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11    268\n",
       "12     81\n",
       "Name: Q1A, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18    83\n",
       "19    19\n",
       "Name: Q1A, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6    100\n",
       "7     61\n",
       "Name: Q1B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11    156\n",
       "12     61\n",
       "Name: Q1B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18    128\n",
       "19     35\n",
       "Name: Q1B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read x/y data\n",
    "station_xy = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\passenger_rail_stations.csv',\n",
    "                         usecols = ['routename', 'station_na', 'x', 'y'])\n",
    "\n",
    "station_xy_cc  = station_xy.loc[station_xy.routename == 'Capitol Corridor']\n",
    "\n",
    "# rename 'Santa Clara' to 'Santa Clara Great America' and add one row for 'Santa Clara University'\n",
    "station_xy_cc.loc[station_xy_cc.station_na == 'Santa Clara', 'station_na'] = 'Santa Clara Great America'\n",
    "\n",
    "add_station = {'routename': 'Capitol Corridor', 'station_na': 'Santa Clara University', 'x': -121.9396494, 'y': 37.3517273} \n",
    "station_xy_cc = station_xy_cc.append(add_station, ignore_index = True)\n",
    "\n",
    "\n",
    "# Boarding Station - for survey responses with value 21 Fairfield (Unspecified), 22 Oakland (Unspecified), 23 Santa Clara (Unspecified)\n",
    "# need to re-assign to the station with more boardings within the same city\n",
    "\n",
    "# Fairfield stations (6 and 7)\n",
    "display(df.loc[(df.Q1A == 6) | (df.Q1A == 7)].Q1A.value_counts()) # 6 Suisun-fairfield has more\n",
    "\n",
    "# Oakland stations (11 and 12)\n",
    "display(df.loc[(df.Q1A == 11) | (df.Q1A == 12)].Q1A.value_counts()) # 11 Jack London Square has more\n",
    "\n",
    "# Santa Clara stations (18 and 19)\n",
    "display(df.loc[(df.Q1A == 18) | (df.Q1A == 19)].Q1A.value_counts()) # 18 Santa Clara Great America has more\n",
    "\n",
    "\n",
    "# Similarly for Alighting Station\n",
    "\n",
    "# Fairfield stations (6 and 7)\n",
    "display(df.loc[(df.Q1B == 6) | (df.Q1B == 7)].Q1B.value_counts()) # 6 Suisun-fairfield has more\n",
    "\n",
    "# Oakland stations (11 and 12)\n",
    "display(df.loc[(df.Q1B == 11) | (df.Q1B == 12)].Q1B.value_counts()) # 11 Jack London Square has more\n",
    "\n",
    "# Santa Clara stations (18 and 19)\n",
    "display(df.loc[(df.Q1B == 18) | (df.Q1B == 19)].Q1B.value_counts()) # 18 Santa Clara Great America has more\n",
    "\n",
    "\n",
    "# build dictionary\n",
    "cc_station_dict = {'2': 'Berkeley',\n",
    "                   '5': 'Emeryville',\n",
    "                   '6': 'Suisun-fairfield',\n",
    "                   '7': 'Fairfield/Vacaville Station',\n",
    "                   '8': 'Fremont',\n",
    "                   '9': 'Hayward',\n",
    "                   '10': 'Martinez',\n",
    "                   '11': 'Jack London Square',\n",
    "                   '12': 'Oakland Coliseum',\n",
    "                   '13': 'Richmond',\n",
    "                   '17': 'San Jose',\n",
    "                   '18': 'Santa Clara Great America',\n",
    "                   '19': 'Santa Clara University',\n",
    "                   '21': 'Suisun-fairfield',\n",
    "                   '22': 'Jack London Square',\n",
    "                   '23': 'Santa Clara Great America'}\n",
    "\n",
    "# merge station names into the survey data\n",
    "for colname in ['Q1A', 'Q1B']:\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].apply(lambda x: str(x))\n",
    "    df[colname] = df[colname].map(cc_station_dict)\n",
    "    \n",
    "# merge lat/lon into the survey data\n",
    "df_board = df[['CCGID', 'Q1A']].merge(station_xy_cc, left_on='Q1A', right_on='station_na', how='left')\n",
    "df_board = df_board[['CCGID', 'x', 'y']].rename(columns = {'x': 'survey_board_lon',\n",
    "                                                        'y': 'survey_board_lat'})\n",
    "\n",
    "df_alight = df[['CCGID', 'Q1B']].merge(station_xy_cc, left_on='Q1B', right_on='station_na', how='left')\n",
    "df_alight = df_alight[['CCGID', 'x', 'y']].rename(columns = {'x': 'survey_alight_lon',\n",
    "                                                          'y': 'survey_alight_lat'})\n",
    "\n",
    "df = df.merge(df_board, on='CCGID', how='inner').merge(df_alight, on='CCGID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update 'weight' <a class=\"anchor\" id=\"weight\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2406 rows of updated weights: \n",
      "   ID  weight\n",
      "0   1     0.0\n",
      "1   2     0.0\n",
      "2   3     0.0\n",
      "3   4     0.0\n",
      "4   5     0.0\n",
      "total weights: 5762.203065134101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPNUM</th>\n",
       "      <th>CCGID</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>INTDAY</th>\n",
       "      <th>INTDATE</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>Q1A</th>\n",
       "      <th>BOARD</th>\n",
       "      <th>Q1B</th>\n",
       "      <th>...</th>\n",
       "      <th>race_dmy_mdl_estn</th>\n",
       "      <th>trip_purp</th>\n",
       "      <th>postcode</th>\n",
       "      <th>home_lat</th>\n",
       "      <th>home_lon</th>\n",
       "      <th>survey_board_lon</th>\n",
       "      <th>survey_board_lat</th>\n",
       "      <th>survey_alight_lon</th>\n",
       "      <th>survey_alight_lat</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1909</td>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Jack London Square</td>\n",
       "      <td>OAKLAND-JLS</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.271986</td>\n",
       "      <td>37.793520</td>\n",
       "      <td>-121.903040</td>\n",
       "      <td>37.329070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1910</td>\n",
       "      <td>2</td>\n",
       "      <td>737</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>95630.0</td>\n",
       "      <td>38.666915</td>\n",
       "      <td>-121.142106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.291300</td>\n",
       "      <td>37.840547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1911</td>\n",
       "      <td>3</td>\n",
       "      <td>737</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.300943</td>\n",
       "      <td>37.867277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912</td>\n",
       "      <td>4</td>\n",
       "      <td>737</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>94080.0</td>\n",
       "      <td>37.655380</td>\n",
       "      <td>-122.422126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.291300</td>\n",
       "      <td>37.840547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1913</td>\n",
       "      <td>5</td>\n",
       "      <td>737</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>94553.0</td>\n",
       "      <td>37.981739</td>\n",
       "      <td>-122.165406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.137097</td>\n",
       "      <td>38.019510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>1055</td>\n",
       "      <td>2405</td>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>EMERYVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>94123.0</td>\n",
       "      <td>37.800750</td>\n",
       "      <td>-122.436363</td>\n",
       "      <td>-122.291300</td>\n",
       "      <td>37.840547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>1057</td>\n",
       "      <td>2406</td>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>95816.0</td>\n",
       "      <td>38.575553</td>\n",
       "      <td>-121.465409</td>\n",
       "      <td>-122.300943</td>\n",
       "      <td>37.867277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>1060</td>\n",
       "      <td>2407</td>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>MARTINEZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.137097</td>\n",
       "      <td>38.019510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>1063</td>\n",
       "      <td>2408</td>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>EMERYVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>95817.0</td>\n",
       "      <td>38.550905</td>\n",
       "      <td>-121.456226</td>\n",
       "      <td>-122.291300</td>\n",
       "      <td>37.840547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>1066</td>\n",
       "      <td>2409</td>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>EMERYVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>94123.0</td>\n",
       "      <td>37.800750</td>\n",
       "      <td>-122.436363</td>\n",
       "      <td>-122.291300</td>\n",
       "      <td>37.840547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2406 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RESPNUM  CCGID  TRAIN  INTDAY    INTDATE  PERIOD  LANGUAGE  \\\n",
       "0        1909      1    737       3 2019-06-22       2         2   \n",
       "1        1910      2    737       3 2019-06-22       2         1   \n",
       "2        1911      3    737       3 2019-06-22       2         1   \n",
       "3        1912      4    737       3 2019-06-22       2         1   \n",
       "4        1913      5    737       3 2019-06-22       2         1   \n",
       "...       ...    ...    ...     ...        ...     ...       ...   \n",
       "2401     1055   2405    734       7 2019-06-29       2         1   \n",
       "2402     1057   2406    734       7 2019-06-29       2         1   \n",
       "2403     1060   2407    734       7 2019-06-29       2         1   \n",
       "2404     1063   2408    734       7 2019-06-29       2         1   \n",
       "2405     1066   2409    734       7 2019-06-29       2         1   \n",
       "\n",
       "                     Q1A         BOARD         Q1B  ... race_dmy_mdl_estn  \\\n",
       "0     Jack London Square  OAKLAND-JLS     San Jose  ...                 1   \n",
       "1                    NaN   SACRAMENTO   Emeryville  ...                 1   \n",
       "2                    NaN   SACRAMENTO     Berkeley  ...                 1   \n",
       "3                    NaN         DAVIS  Emeryville  ...                 1   \n",
       "4                    NaN         DAVIS    Martinez  ...                 1   \n",
       "...                  ...           ...         ...  ...               ...   \n",
       "2401          Emeryville   EMERYVILLE          NaN  ...                 1   \n",
       "2402            Berkeley      BERKELEY         NaN  ...                 1   \n",
       "2403            Martinez     MARTINEZ          NaN  ...                 1   \n",
       "2404          Emeryville   EMERYVILLE          NaN  ...                 1   \n",
       "2405          Emeryville   EMERYVILLE          NaN  ...                 1   \n",
       "\n",
       "                  trip_purp  postcode   home_lat    home_lon  \\\n",
       "0      Visit family/friends       NaN        NaN         NaN   \n",
       "1        Leisure/Recreation   95630.0  38.666915 -121.142106   \n",
       "2     Travel to/from school       NaN        NaN         NaN   \n",
       "3        Leisure/Recreation   94080.0  37.655380 -122.422126   \n",
       "4                   missing   94553.0  37.981739 -122.165406   \n",
       "...                     ...       ...        ...         ...   \n",
       "2401   Visit family/friends   94123.0  37.800750 -122.436363   \n",
       "2402   Commute to/from work   95816.0  38.575553 -121.465409   \n",
       "2403               Vacation       NaN        NaN         NaN   \n",
       "2404   Visit family/friends   95817.0  38.550905 -121.456226   \n",
       "2405        Business travel   94123.0  37.800750 -122.436363   \n",
       "\n",
       "      survey_board_lon  survey_board_lat  survey_alight_lon  \\\n",
       "0          -122.271986         37.793520        -121.903040   \n",
       "1                  NaN               NaN        -122.291300   \n",
       "2                  NaN               NaN        -122.300943   \n",
       "3                  NaN               NaN        -122.291300   \n",
       "4                  NaN               NaN        -122.137097   \n",
       "...                ...               ...                ...   \n",
       "2401       -122.291300         37.840547                NaN   \n",
       "2402       -122.300943         37.867277                NaN   \n",
       "2403       -122.137097         38.019510                NaN   \n",
       "2404       -122.291300         37.840547                NaN   \n",
       "2405       -122.291300         37.840547                NaN   \n",
       "\n",
       "      survey_alight_lat  weight  \n",
       "0             37.329070     0.0  \n",
       "1             37.840547     0.0  \n",
       "2             37.867277     0.0  \n",
       "3             37.840547     0.0  \n",
       "4             38.019510     0.0  \n",
       "...                 ...     ...  \n",
       "2401                NaN     0.0  \n",
       "2402                NaN     0.0  \n",
       "2403                NaN     0.0  \n",
       "2404                NaN     0.0  \n",
       "2405                NaN     0.0  \n",
       "\n",
       "[2406 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_df = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\Weighting\\Capitol_Corridor_Weights.csv')\n",
    "print('read {} rows of updated weights: \\n{}'.format(weight_df.shape[0], weight_df.head()))\n",
    "\n",
    "df = df.merge(weight_df, left_on='CCGID', right_on='ID', how='left')\n",
    "print('total weights: {}'.format(df.weight.sum()))\n",
    "display(df.drop(columns = ['ID', 'WEIGHT'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute year_born from 'age group' <a class=\"anchor\" id=\"age\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989.0    520\n",
       "1979.0    497\n",
       "1969.0    421\n",
       "1959.0    415\n",
       "1949.0    209\n",
       "1998.0    202\n",
       "2004.0     36\n",
       "Name: year_born_four_digit, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_born_dict = {1: 2004,   # Under 18, 2019-15=2004\n",
    "                  2: 1998,   # 18-24, 2019-21=1998\n",
    "                  3: 1989,   # 25-34, 2019-30=1989\n",
    "                  4: 1979,   # 35-44, 2019-40=1979\n",
    "                  5: 1969,   # 45-54, 2019-50=1969\n",
    "                  6: 1959,   # 55-64, 2019-60=1959\n",
    "                  7: 1949,   # 65 and older, 2019-70=1949\n",
    "                 }\n",
    "\n",
    "df['year_born_four_digit'] = df['Q18'].map(year_born_dict)\n",
    "df.year_born_four_digit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export survey data <a class=\"anchor\" id=\"survey_export\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export 2406 rows of data to CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns = {'CCGID': 'ID'}, inplace=True)\n",
    "\n",
    "final_fname = 'CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv'\n",
    "print('export {} rows of data to {}'.format(df.shape[0], final_fname))\n",
    "\n",
    "df.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\As CSV\\CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build standard dictionary <a class=\"anchor\" id=\"standard_dict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read raw variable dictionary 'Field Guide'  <a class=\"anchor\" id=\"raw_dict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw survey dictionary\n",
    "survey_dict = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\CAPCO19 Data-For MTC.xlsx',\n",
    "                            sheet_name='Field Guide')\n",
    "\n",
    "# back fill name in 'Field' column\n",
    "survey_dict.loc[(survey_dict.Field == '       ') | (survey_dict.Field == '  ') | (survey_dict.Field == '        '),\n",
    "                'Field'] = np.nan\n",
    "survey_dict['Field'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# rename to correctly reflect the info\n",
    "survey_dict.rename(columns={'Field': 'Survey_Variable',\n",
    "                            'Question/Description': 'Survey_Response',\n",
    "                            'Unnamed: 2': 'Generic_Response_old'}, inplace=True)\n",
    "\n",
    "# only keep needed columns\n",
    "var_dict = survey_dict[['Survey_Variable', 'Survey_Response', 'Generic_Response_old']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add rows to the dictionary for the new fields added to the survey data <a class=\"anchor\" id=\"add_row\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "# add rows for 'access_mode'\n",
    "access_mode_dict = var_dict.loc[(var_dict.Survey_Variable == 'Q2B_1-Q2B_6') & (var_dict.Generic_Response_old.notnull())]\n",
    "access_mode_dict.loc[access_mode_dict.Survey_Variable == 'Q2B_1-Q2B_6', 'Survey_Variable'] = 'access_mode'\n",
    "# display(access_mode_dict)\n",
    "var_dict = var_dict.append(access_mode_dict, ignore_index=True)\n",
    "\n",
    "# replace 'Q2A_1-Q2A_6' with new field name 'egress_mode'\n",
    "var_dict.loc[(var_dict.Survey_Variable == 'Q2B_1-Q2B_6') & (var_dict.Generic_Response_old.notnull()), 'Survey_Variable'] = 'egress_mode'\n",
    "\n",
    "# add rows for 'Q1A'\n",
    "Q1A_dict = var_dict.loc[(var_dict.Survey_Variable == 'Q1B') & (var_dict.Generic_Response_old.notnull())]\n",
    "Q1A_dict.loc[Q1A_dict.Survey_Variable == 'Q1B', 'Survey_Variable'] = 'Q1A'\n",
    "# display(Q1A_dict)\n",
    "var_dict = var_dict.append(Q1A_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add race and hispanic fields to the dictionary\n",
    "race_dict = pd.DataFrame(np.array([['hispanic', 'YES', 'YES'],\n",
    "                                   ['hispanic', 'NO', 'NO'],\n",
    "                                   ['race_dmy_ind', 1, 1],\n",
    "                                   ['race_dmy_hwi', 1, 1],\n",
    "                                   ['race_dmy_blk', 1, 1],\n",
    "                                   ['race_dmy_wht', 1, 1],\n",
    "                                   ['race_dmy_asn', 1, 1],\n",
    "                                   ['race_dmy_mdl_estn', 1, 1],\n",
    "                                   ['race_dmy_ind', 0, 0],\n",
    "                                   ['race_dmy_hwi', 0, 0],\n",
    "                                   ['race_dmy_blk', 0, 0],\n",
    "                                   ['race_dmy_wht', 0, 0],\n",
    "                                   ['race_dmy_asn', 0, 0],\n",
    "                                   ['race_dmy_mdl_estn', 0, 0]]),\n",
    "                         columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "# display(race_dict)\n",
    "var_dict = var_dict.append(race_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add trip_purp rows\n",
    "trip_purpose_dict = df[['trip_purp']].drop_duplicates()\n",
    "trip_purpose_dict.columns = ['Survey_Response']\n",
    "trip_purpose_dict['Survey_Variable'] = 'trip_purp'\n",
    "trip_purpose_dict['Generic_Response_old'] = trip_purpose_dict['Survey_Response']\n",
    "# trip_purpose_dict[['Survey_Variable', 'Survey_Response', 'Generic_Response_old']]\n",
    "var_dict = var_dict.append(trip_purpose_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add home lat/lon rows\n",
    "home_dict = pd.DataFrame(np.array([['home_lat', 'NONCATEGORICAL', np.nan],\n",
    "                                   ['home_lon', 'NONCATEGORICAL', np.nan]]),\n",
    "                         columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(home_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add survey_board/alight lat/lon rows\n",
    "board_alight_dict = pd.DataFrame(np.array([['survey_board_lon', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_board_lat', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_alight_lon', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_alight_lat', 'NONCATEGORICAL', np.nan]]),\n",
    "                                 columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(board_alight_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add transfer routes rows\n",
    "trans_routes_dict = pd.DataFrame(np.array([['first_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['second_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['third_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['first_route_after_survey_alight', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['second_route_after_survey_alight', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['third_route_after_survey_alight', 'NONCATEGORICAL', np.nan]]),\n",
    "                                 columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(trans_routes_dict, ignore_index=True)\n",
    "\n",
    "# add new weight row\n",
    "var_dict.loc[len(var_dict.index)] = ['weight', 'NONCATEGORICAL', np.nan]\n",
    "\n",
    "# add year_born row\n",
    "var_dict.loc[len(var_dict.index)] = ['year_born_four_digit', 'NONCATEGORICAL', np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add default fields in the standard dictionary <a class=\"anchor\" id=\"add_fields\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns 'Generic_variable'\n",
    "var_dict['Generic_Variable'] = ''\n",
    "var_dict.loc[var_dict.Survey_Variable == 'CCGID', 'Generic_Variable'] = 'ID'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'CCGID', 'Survey_Variable'] = 'ID'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'TRAIN', 'Generic_Variable'] = 'route'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'INTDATE', 'Generic_Variable'] = 'date_string'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'PERIOD', 'Generic_Variable'] = 'weekpart'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Language', 'Generic_Variable'] = 'interview_language'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Language', 'Survey_Variable'] = 'LANGUAGE'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q9', 'Generic_Variable'] = 'fare_category'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q10', 'Generic_Variable'] = 'fare_medium'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q17', 'Generic_Variable'] = 'gender'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q19', 'Generic_Variable'] = 'household_income'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q21', 'Generic_Variable'] = 'persons'\n",
    "\n",
    "\n",
    "# newly created fields:\n",
    "var_dict.loc[var_dict.Survey_Variable.str.contains('race_dmy_',na=False), 'Generic_Variable'] = var_dict['Survey_Variable']\n",
    "\n",
    "for varname in ['access_mode', 'egress_mode', 'trip_purp', 'home_lat', 'home_lon', 'weight', 'hispanic',\n",
    "                'survey_board_lon', 'survey_board_lat', 'survey_alight_lon', 'survey_alight_lat',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "                'third_route_before_survey_board', 'first_route_after_survey_alight',\n",
    "                'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname,  'Generic_Variable'] = varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values for 'Survey_Response' and 'Generic_Response' for noncanonical variables\n",
    "var_dict['Generic_Response'] = ''\n",
    "\n",
    "for varname in ['ID', 'TRAIN', 'INTDATE', 'Q22', 'weight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname, 'Survey_Response'] = 'NONCATEGORICAL'\n",
    "    \n",
    "for varname in ['ID', 'TRAIN', 'INTDATE', 'Q22', 'weight', 'year_born_four_digit',\n",
    "                'home_lat', 'home_lon',\n",
    "                'survey_board_lon', 'survey_board_lat', 'survey_alight_lon', 'survey_alight_lat',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "                'third_route_before_survey_board', 'first_route_after_survey_alight',\n",
    "                'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname, 'Generic_Response'] = 'NONCATEGORICAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict['operator'] = 'Capitol Corridor'\n",
    "var_dict['Survey_year'] = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check consistency between values in survey data and in the dictionary <a class=\"anchor\" id=\"check\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERIOD\n",
      "LANGUAGE\n",
      "egress_mode\n",
      "Q9\n",
      "Q10\n",
      "Q17\n",
      "Q19\n",
      "Q21\n",
      "access_mode\n",
      "hispanic\n",
      "race_dmy_ind\n",
      "race_dmy_hwi\n",
      "race_dmy_blk\n",
      "race_dmy_wht\n",
      "race_dmy_asn\n",
      "race_dmy_mdl_estn\n",
      "trip_purp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5491: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# check if all values in the survey data are represented in the dictionary\n",
    "\n",
    "var_dict_cat = var_dict.loc[(var_dict.Survey_Response != 'NONCATEGORICAL') & (\n",
    "                             var_dict.Generic_Response_old.notnull()) & (\n",
    "                             var_dict.Generic_Variable != '')]\n",
    "\n",
    "for fieldname in list(var_dict_cat.Survey_Variable.unique()):\n",
    "#     fieldname = fieldname.upper()\n",
    "    print(fieldname)\n",
    "    values = var_dict.loc[var_dict.Survey_Variable == fieldname]\n",
    "    \n",
    "    if fieldname in ['race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_mdl_estn']:\n",
    "        values.Survey_Response = values.Survey_Response.apply(lambda x: int(x))\n",
    "        \n",
    "    comp = df.merge(values, left_on = fieldname, right_on = 'Survey_Response', how='left')\n",
    "    comp_diff = comp.loc[comp[fieldname].isnull()]\n",
    "    if comp_diff.shape[0] > 0:\n",
    "        print(comp_diff[fieldname].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export raw standard dictionary <a class=\"anchor\" id=\"export_dict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export raw dictionary with 33 variables:\n",
      "['ID' 'TRAIN' 'INTDATE' 'PERIOD' 'LANGUAGE' 'egress_mode' 'Q9' 'Q10' 'Q17'\n",
      " 'Q19' 'Q21' 'access_mode' 'hispanic' 'race_dmy_ind' 'race_dmy_hwi'\n",
      " 'race_dmy_blk' 'race_dmy_wht' 'race_dmy_asn' 'race_dmy_mdl_estn'\n",
      " 'trip_purp' 'home_lat' 'home_lon' 'survey_board_lon' 'survey_board_lat'\n",
      " 'survey_alight_lon' 'survey_alight_lat' 'first_route_before_survey_board'\n",
      " 'second_route_before_survey_board' 'third_route_before_survey_board'\n",
      " 'first_route_after_survey_alight' 'second_route_after_survey_alight'\n",
      " 'third_route_after_survey_alight' 'weight']\n"
     ]
    }
   ],
   "source": [
    "# will manually add 'Generic_Response' for canonical variables in the exported file\n",
    "\n",
    "# only keep rows for needed variables\n",
    "var_dict = var_dict.loc[(var_dict.Generic_Variable != '') & (\n",
    "    (var_dict.Generic_Response == 'NONCATEGORICAL') | var_dict.Generic_Response_old.notnull())]\n",
    "\n",
    "print('export raw dictionary with {} variables:\\n{}'.format(len(var_dict.Survey_Variable.unique()),\n",
    "                                                          var_dict.Survey_Variable.unique()))\n",
    "\n",
    "var_dict.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\var_dict_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build canonical route crosswalk <a class=\"anchor\" id=\"canonical_route\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_routes = pd.DataFrame(np.array([[5, 'BART___BART',             'BART',     'heavy rail'],\n",
    "                                          [6, 'CALTRAIN___CALTRAIN',     'Caltrain', 'commuter rail'],\n",
    "                                          [7, 'Missing___missing',       'Missing',  'light rail'],\n",
    "                                          [8, 'AMTRAK___Amtrak Shuttle', 'AMTRAK',   'local bus'],\n",
    "                                          [9, 'AMTRAK___AMTRAK',         'AMTRAK',   'commuter rail'],\n",
    "                                          [10,'Missing___missing',       'Missing',  'local_bus']]),\n",
    "                                columns=['survey_name','canonical_name','canonical_operator','technology'])\n",
    "\n",
    "canonical_routes['survey'] = 'Capitol Corridor'\n",
    "canonical_routes['survey_year'] = 2019\n",
    "canonical_routes.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\routes_canonical.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
