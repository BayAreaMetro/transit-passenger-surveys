{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [modify survey data](#modify_survey_data)\n",
    "    * [read raw data](#read_raw_data)\n",
    "    * [build before_transfers and 'access_mode' from raw access mode fields](#build_access_mode)\n",
    "    * [build after_transfers and 'egress_mode' from raw access mode fields](#build_egress_mode)\n",
    "    * [deal with 'hispanic' and 'ethnicity/race'](#race)\n",
    "    * [deal with trip purpose](#trip_purp)\n",
    "    * [code home lat/lon based on zipcode](#home_lat_lon)\n",
    "    * [code board/alight station name and lat/lon](#station_lat_lon)\n",
    "    * [update 'weight'](#weight)\n",
    "    * [impute year_born from 'age group'](#age)\n",
    "    * [export survey data](#survey_export)\n",
    "\n",
    "* [build standard dictionary](#standard_dict)\n",
    "    * [read raw variable dictionary 'Field Guide'](#raw_dict)\n",
    "    * [add rows to the dictionary for the new fields added to the survey data](#add_row)\n",
    "    * [add default fields in the standard dictionary](#add_fields)\n",
    "    * [check consistency between values in survey data and in the dictionary](#check)\n",
    "    * [export raw standard dictionary](#export_dict)\n",
    "    \n",
    "* [build canonical route crosswalk](#canonical_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify survey data <a class=\"anchor\" id=\"modify_survey_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read raw data  <a class=\"anchor\" id=\"read_raw_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2406 records, with 2406 unique CCGID\n",
      "['RESPNUM', 'CCGID', 'TRAIN', 'INTDAY', 'INTDATE', 'PERIOD', 'LANGUAGE', 'Q1A', 'BOARD', 'Q1B', 'ALIGHT', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6', 'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6', 'Q3', 'Q4', 'Q5_1', 'Q5_2', 'Q5_3', 'Q5_4', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q7', 'Q8_1', 'Q8_2', 'Q8_3', 'Q8_4', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13_1', 'Q13_2', 'Q13_3', 'Q13_4', 'Q15_1', 'Q15_2', 'Q15_3', 'Q15_4', 'Q16_1', 'Q16_2', 'Q16_3', 'Q16_4', 'Q17', 'Q18', 'Q19', 'Unnamed: 57', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4', 'Q21', 'Q22', 'CITY', 'CITY_CODE', 'COUNTY', 'COUNTY_CODE ', 'STATE', 'STATE_CODE ', 'COUNTRY', 'WEIGHT']\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\CAPCO19 Data-For MTC.xlsx',\n",
    "                       sheet_name='Data')\n",
    "print('read {} records, with {} unique CCGID'.format(df_raw.shape[0], len(df_raw.CCGID.unique())))\n",
    "\n",
    "df = df_raw.copy()\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build before_transfers and 'access_mode' from raw access mode fields Q2A_1-Q2A_6 <a class=\"anchor\" id=\"build_access_mode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>Q2A_1</th>\n",
       "      <th>Q2A_2</th>\n",
       "      <th>Q2A_3</th>\n",
       "      <th>Q2A_4</th>\n",
       "      <th>Q2A_5</th>\n",
       "      <th>Q2A_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11+H13:H32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CCGID  Q2A_1  Q2A_2       Q2A_3  Q2A_4  Q2A_5  Q2A_6\n",
       "62     63      4    NaN  11+H13:H32    NaN    NaN    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# row dictionary of Q2A_1-Q2A_6 / Q2B_1-Q2B_6:\n",
    "\n",
    "mode_dict = {1: 'Dropped off/Picked up', \n",
    "            2: 'Drove alone', \n",
    "            3: 'Carpool', \n",
    "            4: 'Taxi/Uber/Lyft', \n",
    "            5: 'BART', \n",
    "            6: 'Caltrain', \n",
    "            7: 'Light rail (VTA, Sacramento RT)', \n",
    "            8: 'Amtrak thruway bus', \n",
    "            9: 'Amtrak long distance train', \n",
    "            10: 'Bus transit', \n",
    "            11: 'Walked', \n",
    "            12: 'Bike', \n",
    "            13: 'Electric Scooter/Scooter', \n",
    "            14: 'Other (Specify)' \n",
    "            }\n",
    "\n",
    "mode_cat_dict = {'Dropped off/Picked up': 'knr',\n",
    "                 'Drove alone': 'pnr',\n",
    "                 'Carpool': 'carpool',\n",
    "                 'Taxi/Uber/Lyft': 'tnc',\n",
    "                 'BART': 'transit',\n",
    "                 'Caltrain': 'transit', \n",
    "                 'Light rail (VTA, Sacramento RT)': 'transit',\n",
    "                 'Amtrak thruway bus': 'transit', \n",
    "                 'Amtrak long distance train': 'transit', \n",
    "                 'Bus transit': 'transit', \n",
    "                 'Walked': 'walk',\n",
    "                 'Bike': 'bike',\n",
    "                 'Electric Scooter/Scooter': 'scooter', \n",
    "                 'Other (Specify)': 'other'}\n",
    "\n",
    "## create fields\n",
    "\n",
    "for colname in ['access_mode', 'egress_mode',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board', 'third_route_before_survey_board',\n",
    "                'first_route_after_survey_alight', 'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    df[colname] = np.nan\n",
    "    \n",
    "# first, error in CCGID 63 Q2A_3, update to nan\n",
    "display(df.loc[df.CCGID == 63][['CCGID', 'Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6']])\n",
    "df.loc[df.CCGID == 63, 'Q2A_3'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column to show the names for Q2A_1-6, Q2B_1-6, and count number of access_modes/egress_modes\n",
    "for i in ['Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6', 'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']:\n",
    "    df[i+'_name'] = df[i].map(mode_dict)\n",
    "    df[i+'_cat'] = df[i+'_name'].map(mode_cat_dict)\n",
    "\n",
    "df['access_count'] = df[['Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6']].count(axis=1)\n",
    "df['egress_count'] = df[['Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']].count(axis=1) \n",
    "\n",
    "# create a column as a placeholder to concatenate access_mode_categories and egress_mode_categories\n",
    "df['access_concat'] = ''\n",
    "df['egress_concat'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access_mode idx_1 find 1923 rows, 79.9% of total\n",
      "access_mode idx_2 find 303 rows, 12.6% of total\n",
      "\n",
      " responses with 2 access modes have the following unique combinations of mode categories:\n",
      "['knr_transit' 'pnr_tnc' 'transit_walk' 'knr_tnc' 'carpool_tnc'\n",
      " 'knr_carpool' 'transit_transit' 'transit_bike' 'knr_pnr' 'knr_walk'\n",
      " 'tnc_transit' 'pnr_walk' 'pnr_bike' 'pnr_transit' 'walk_knr'\n",
      " 'pnr_carpool' 'tnc_walk' 'bike_scooter' 'walk_bike' 'knr_bike'\n",
      " 'pnr_scooter' 'tnc_scooter' 'walk_transit' 'transit_pnr' 'bike_pnr'\n",
      " 'walk_scooter' 'pnr_knr' 'tnc_bike']\n",
      "\n",
      "access_mode idx_3 find 4 rows, 0.2% of total\n",
      "access_mode idx_4 find 18 rows, 0.7% of total\n",
      "access_mode idx_5 find 27 rows, 1.1% of total\n",
      "access_mode idx_6 find 87 rows, 3.6% of total\n",
      "\n",
      " responses with 3 access modes have the following unique combinations of mode categories:\n",
      "['knr_tnc_walk' 'knr_transit_transit' 'pnr_knr_transit' 'knr_transit_tnc'\n",
      " 'walk_knr_tnc' 'knr_pnr_bike' 'knr_transit_pnr' 'pnr_walk_bike'\n",
      " 'pnr_scooter_bike' 'pnr_transit_walk' 'transit_walk_bike' 'knr_pnr_tnc'\n",
      " 'knr_pnr_walk' 'tnc_transit_bike' 'knr_transit_walk' 'knr_carpool_tnc'\n",
      " 'transit_transit_transit' 'knr_pnr_transit' 'tnc_walk_bike'\n",
      " 'transit_walk_scooter' 'transit_knr_pnr' 'transit_walk_transit']\n",
      "\n",
      "access_mode idx_7 find 1 rows, 0.0% of total\n",
      "access_mode idx_8 find 3 rows, 0.1% of total\n",
      "access_mode idx_9 find 6 rows, 0.2% of total\n",
      "access_mode idx_10 find 4 rows, 0.2% of total\n",
      "access_mode idx_11 find 1 rows, 0.0% of total\n",
      "access_mode idx_12 find 1 rows, 0.0% of total\n",
      "access_mode idx_13 find 11 rows, 0.5% of total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>access_count</th>\n",
       "      <th>Q2A_1_cat</th>\n",
       "      <th>Q2A_2_cat</th>\n",
       "      <th>Q2A_3_cat</th>\n",
       "      <th>Q2A_4_cat</th>\n",
       "      <th>Q2A_5_cat</th>\n",
       "      <th>Q2A_6_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>knr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>bike</td>\n",
       "      <td>scooter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>knr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>443</td>\n",
       "      <td>5</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>pnr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>468</td>\n",
       "      <td>5</td>\n",
       "      <td>knr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>878</td>\n",
       "      <td>4</td>\n",
       "      <td>knr</td>\n",
       "      <td>transit</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>926</td>\n",
       "      <td>4</td>\n",
       "      <td>knr</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>967</td>\n",
       "      <td>4</td>\n",
       "      <td>bike</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>969</td>\n",
       "      <td>4</td>\n",
       "      <td>transit</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>994</td>\n",
       "      <td>4</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1018</td>\n",
       "      <td>6</td>\n",
       "      <td>pnr</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>scooter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1122</td>\n",
       "      <td>4</td>\n",
       "      <td>transit</td>\n",
       "      <td>knr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>bike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1134</td>\n",
       "      <td>4</td>\n",
       "      <td>bike</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1566</td>\n",
       "      <td>6</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>bike</td>\n",
       "      <td>tnc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1714</td>\n",
       "      <td>5</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>knr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2073</td>\n",
       "      <td>4</td>\n",
       "      <td>knr</td>\n",
       "      <td>pnr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2163</td>\n",
       "      <td>4</td>\n",
       "      <td>pnr</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>scooter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CCGID  access_count Q2A_1_cat Q2A_2_cat Q2A_3_cat Q2A_4_cat Q2A_5_cat  \\\n",
       "120     122             6       knr   carpool   transit      walk      bike   \n",
       "157     159             6       knr       tnc   transit   transit   transit   \n",
       "441     443             5       tnc   transit   transit      walk       pnr   \n",
       "466     468             5       knr       tnc   transit   transit      walk   \n",
       "876     878             4       knr   transit       tnc   transit       NaN   \n",
       "924     926             4       knr   transit   transit      walk       NaN   \n",
       "965     967             4      bike       knr       pnr       tnc       NaN   \n",
       "967     969             4   transit       tnc   transit   transit       NaN   \n",
       "992     994             4       knr       pnr       tnc   transit       NaN   \n",
       "1016   1018             6       pnr   transit   transit   transit      walk   \n",
       "1120   1122             4   transit       knr       tnc      bike       NaN   \n",
       "1132   1134             4      bike       knr       pnr   carpool       NaN   \n",
       "1564   1566             6       knr       pnr   transit      walk      bike   \n",
       "1712   1714             5       knr       pnr   transit   transit   transit   \n",
       "2008   2010             4       knr       tnc   transit   transit       NaN   \n",
       "2071   2073             4       knr       pnr   carpool       tnc       NaN   \n",
       "2161   2163             4       pnr   transit      walk   scooter       NaN   \n",
       "\n",
       "     Q2A_6_cat  \n",
       "120    scooter  \n",
       "157       walk  \n",
       "441        NaN  \n",
       "466        NaN  \n",
       "876        NaN  \n",
       "924        NaN  \n",
       "965        NaN  \n",
       "967        NaN  \n",
       "992        NaN  \n",
       "1016   scooter  \n",
       "1120       NaN  \n",
       "1132       NaN  \n",
       "1564       tnc  \n",
       "1712       NaN  \n",
       "2008       NaN  \n",
       "2071       NaN  \n",
       "2161       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## one access mode in raw data\n",
    "# 1. for responses with one access_mode (access_count==1) and the mode is not public transit,\n",
    "# set Q2A_1 as access mode, and no before-transfer\n",
    "idx_1 = ((df.access_count == 1) & (df.Q2A_1_cat != 'transit'))\n",
    "print('access_mode idx_1 find {} rows, {:.1%} of total'.format(idx_1.sum(), idx_1.sum()/df.shape[0]))\n",
    "df.loc[idx_1, 'access_mode'] = df['Q2A_1']\n",
    "\n",
    "# 2. for responses with one access_mode (access_count==1) and the mode is public transit,\n",
    "# set access mode as \"Missing\", and Q2A_1 as before-transfer\n",
    "idx_2 = ((df.access_count == 1) & (df.Q2A_1_cat == 'transit'))\n",
    "print('access_mode idx_2 find {} rows, {:.1%} of total'.format(idx_2.sum(), idx_2.sum()/df.shape[0]))\n",
    "df.loc[idx_2, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_2, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "## two access modes in raw data\n",
    "df.loc[df.access_count == 2, 'access_concat'] = df['Q2A_1_cat'] + '_' + df['Q2A_2_cat']\n",
    "print('\\n responses with 2 access modes have the following unique combinations of mode categories:\\n{}\\n'.format(df.loc[df.access_count == 2].access_concat.unique()))\n",
    "\n",
    "# 3. for responses with two access_mode (access_count==2) and both are public transit,\n",
    "# set access mode as \"Missing\", and before-transfer as \"transit_pending\"\n",
    "idx_3 = ((df.access_count == 2) & (df.access_concat == 'transit_transit'))\n",
    "print('access_mode idx_3 find {} rows, {:.1%} of total'.format(idx_3.sum(), idx_3.sum()/df.shape[0]))\n",
    "df.loc[idx_3, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_3, 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[idx_3, 'second_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "# 4/5. for responses with two access_mode (access_count==2) and only one value public transit,\n",
    "# set access mode as the non-transit value, and the transit-value as before-transfer\n",
    "\n",
    "idx_4 = ((df.access_count == 2) & (\n",
    "              (df.access_concat == 'transit_walk') | (\n",
    "               df.access_concat == 'transit_bike') | (\n",
    "               df.access_concat == 'transit_pnr')))            # Q2A_1 is public transit\n",
    "print('access_mode idx_4 find {} rows, {:.1%} of total'.format(idx_4.sum(), idx_4.sum()/df.shape[0]))\n",
    "df.loc[idx_4, 'access_mode'] = df['Q2A_2']\n",
    "df.loc[idx_4, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "idx_5 = ((df.access_count == 2) & (\n",
    "              (df.access_concat == 'knr_transit') | (\n",
    "               df.access_concat == 'tnc_transit') | (\n",
    "               df.access_concat == 'pnr_transit') | (\n",
    "               df.access_concat == 'walk_transit')))           # Q2A_2 is public transit\n",
    "print('access_mode idx_5 find {} rows, {:.1%} of total'.format(idx_5.sum(), idx_5.sum()/df.shape[0]))\n",
    "df.loc[idx_5, 'access_mode'] = df['Q2A_1']\n",
    "df.loc[idx_5, 'first_route_before_survey_board'] = df['Q2A_2']\n",
    "\n",
    "# 6. for responses with two access_mode (access_count==2) and both are not public transit,\n",
    "# set access mode as \"Missing\", and no before-transfer\n",
    "\n",
    "idx_6 = ((df.access_count == 2) & (df.access_concat.str.contains('transit') == False))\n",
    "print('access_mode idx_6 find {} rows, {:.1%} of total'.format(idx_6.sum(), idx_6.sum()/df.shape[0]))\n",
    "df.loc[idx_6, 'access_mode'] = 'Missing'\n",
    "\n",
    "\n",
    "## three access modes in raw data\n",
    "df.loc[df.access_count == 3, 'access_concat'] = df['Q2A_1_cat'] + '_' + df['Q2A_2_cat'] + '_' + df['Q2A_3_cat']\n",
    "print('\\n responses with 3 access modes have the following unique combinations of mode categories:\\n{}\\n'.format(df.loc[df.access_count == 3].access_concat.unique()))\n",
    "\n",
    "# 7. for responses with three access_mode (access_count==3) and all three are transit,\n",
    "# then access mode is \"Missing\", before-transfers are pending\n",
    "idx_7 = ((df.access_count == 3) & (df.access_concat == 'transit_transit_transit'))\n",
    "print('access_mode idx_7 find {} rows, {:.1%} of total'.format(idx_7.sum(), idx_7.sum()/df.shape[0]))\n",
    "df.loc[idx_7, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_7, 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[idx_7, 'second_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[idx_7, 'third_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "# 8/9/10. for responses with three access_mode (access_count==3) and only one value is public transit,\n",
    "# then access mode is \"Missing\", the transit value is before-transfer\n",
    "idx_8 = ((df.access_count == 3) & (\n",
    "              (df.access_concat == 'transit_walk_bike') | (\n",
    "               df.access_concat == 'transit_walk_scooter') | (\n",
    "               df.access_concat == 'transit_knr_pnr')))         # Q2A_1 is public transit\n",
    "print('access_mode idx_8 find {} rows, {:.1%} of total'.format(idx_8.sum(), idx_8.sum()/df.shape[0]))\n",
    "df.loc[idx_8, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_8, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "idx_9 = ((df.access_count == 3) & (\n",
    "              (df.access_concat == 'knr_transit_tnc') | (\n",
    "               df.access_concat == 'knr_transit_pnr') | (\n",
    "               df.access_concat == 'pnr_transit_walk') | (\n",
    "               df.access_concat == 'tnc_transit_bike') | (\n",
    "               df.access_concat == 'knr_transit_walk')))        # Q2A_2 is public transit\n",
    "print('access_mode idx_9 find {} rows, {:.1%} of total'.format(idx_9.sum(), idx_9.sum()/df.shape[0]))\n",
    "df.loc[idx_9, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_9, 'first_route_before_survey_board'] = df['Q2A_2']\n",
    "\n",
    "idx_10 = ((df.access_count == 3) & (\n",
    "              (df.access_concat == 'pnr_knr_transit') | (\n",
    "               df.access_concat == 'knr_pnr_transit')))        # Q1A_3 is public transit\n",
    "print('access_mode idx_10 find {} rows, {:.1%} of total'.format(idx_10.sum(), idx_10.sum()/df.shape[0]))\n",
    "df.loc[idx_10, 'access_mode'] = 'Missing'\n",
    "df.loc[idx_10, 'first_route_before_survey_board'] = df['Q2A_3']\n",
    "\n",
    "# 11/12. for responses with three access_mode (access_count==3) and two are transits,\n",
    "# then access mode is the non-transit value, before-transfers are pending\n",
    "idx_11 = ((df.access_count == 3) & (df.access_concat == 'knr_transit_transit'))  # Q2A_1 not transit\n",
    "print('access_mode idx_11 find {} rows, {:.1%} of total'.format(idx_11.sum(), idx_11.sum()/df.shape[0]))\n",
    "df.loc[idx_11, 'access_mode'] = df['Q2A_1']\n",
    "df.loc[idx_11, 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[idx_11, 'second_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "idx_12 = ((df.access_count == 3) & (df.access_concat == 'transit_walk_transit'))  # Q2A_2 not transit\n",
    "print('access_mode idx_12 find {} rows, {:.1%} of total'.format(idx_12.sum(), idx_12.sum()/df.shape[0]))\n",
    "df.loc[idx_12, 'access_mode'] = df['Q2A_2']\n",
    "df.loc[idx_12, 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[idx_12, 'second_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "# 13. for responses with three access_mode (access_count==3) and all are non-transit,\n",
    "# set access mode as \"Missing\", and no before-transfer\n",
    "\n",
    "idx_13 = ((df.access_count == 3) & (df.access_concat.str.contains('transit') == False))\n",
    "print('access_mode idx_13 find {} rows, {:.1%} of total'.format(idx_13.sum(), idx_13.sum()/df.shape[0]))\n",
    "df.loc[idx_13, 'access_mode'] = 'Missing'\n",
    "\n",
    "# examine the remaining access_mode.isnull()\n",
    "display(df.loc[df.access_mode.isnull()][['CCGID', 'access_count', 'Q2A_1_cat', 'Q2A_2_cat',\n",
    "                                         'Q2A_3_cat', 'Q2A_4_cat',\n",
    "                                         'Q2A_5_cat', 'Q2A_6_cat']].dropna(how='all', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows is missing access_mode\n"
     ]
    }
   ],
   "source": [
    "## cases with one transit mode and multiple non-transit modes - set the transit mode as before-transfer, access_mode is 'Missing'\n",
    "# CCGID 122 (knr-carpool-transit-walk-bike-scooter): Q2A_3 before-transfer\n",
    "# CCGID 1566 (knr-pnr-transit-walk-bike-tnc): Q2A_3 before-transfer\n",
    "# CCGID 994 (knr-pnr-tnc-transit): Q2A_4 before-transfer\n",
    "# CCGID 2163 (pnr-transit-walk-scooter): Q2A_2 before-transfer\n",
    "# CCGID 1122 (transit-knr-tnc-bike): Q2A_1 before-transfer\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==1566) | (df.CCGID==994) | (df.CCGID==2163) | (df.CCGID==1122),\n",
    "       'access_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==1566), 'first_route_before_survey_board'] = df['Q2A_3']\n",
    "df.loc[df.CCGID==994, 'first_route_before_survey_board'] = df['Q2A_4']\n",
    "df.loc[df.CCGID==2163, 'first_route_before_survey_board'] = df['Q2A_2']\n",
    "df.loc[df.CCGID==1122, 'first_route_before_survey_board'] = df['Q2A_1']\n",
    "\n",
    "## cases with two transit modes and multiple non-transit modes - before-transfers as 'pending', access_mode 'Missing'\n",
    "# CCGID 443 (tnc-transit-transit-walk-pnr)\n",
    "# CCGID 468 (knr-tnc-transit-transit-walk)\n",
    "# CCGID 878 (knr-transit-tnc-transit)\n",
    "# CCGID 926 (knr-transit-transit-walk)\n",
    "# CCGID 2010 (knr-tnc-transit-transit)\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==468) | (df.CCGID==878) | (df.CCGID==926) | (df.CCGID==2010),\n",
    "       'access_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==468) | (df.CCGID==878) | (df.CCGID==926) | (df.CCGID==2010),\n",
    "       'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==468) | (df.CCGID==878) | (df.CCGID==926) | (df.CCGID==2010),\n",
    "       'second_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "## cases with three transit modes and one non-transit mode - before-transfer as 'pending', access_mode is the non-transit mode\n",
    "# CCGID 969 (transit-tnc-transit-transit)\n",
    "df.loc[df.CCGID==969, 'access_mode'] = df['Q2A_2']\n",
    "df.loc[df.CCGID==969, 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[df.CCGID==969, 'second_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[df.CCGID==969, 'third_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "## cases with three transit modes and multiple non-transit modes - before-transfers as 'pending', access_mode 'Missing'\n",
    "# CCGID 159 (knr-tnc-transit-transit-transit-walk)\n",
    "# CCGID 1018 (pnr-transit-transit-transit-walk-scooter)\n",
    "# CCGID 1714 (knr-pnr-transit-transit-transit)\n",
    "df.loc[(df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1714), 'access_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1714), 'first_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1714), 'second_route_before_survey_board'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1714), 'third_route_before_survey_board'] = 'transit_pending'\n",
    "\n",
    "## cases with no transit modes and multiple non-transit modes - access_mode 'Missing', no before-transfer\n",
    "# CCGID 967 (bike-knr-pnr-tnc)\n",
    "# CCGID 1134 (bike-knr-pnr-carpool)\n",
    "# CCGID 2073 (knr-pnr-carpool-tnc)\n",
    "df.loc[(df.CCGID==967) | (df.CCGID==1134) | (df.CCGID==2073), 'access_mode'] = 'Missing'\n",
    "\n",
    "# finally, check there is no row with access_mode.isnull()\n",
    "print('{} rows is missing access_mode'.format(df.access_mode.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build after_transfers and 'egress_mode' from raw access mode fields Q2B_1-Q2B_6  <a class=\"anchor\" id=\"build_egress_mode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egress_mode idx_1 find 1886 rows, 78.4% of total\n",
      "egress_mode idx_2 find 329 rows, 13.7% of total\n",
      "\n",
      " responses with 2 egress modes have the following unique combinations of mode categories:\n",
      "['transit_transit' 'transit_walk' 'transit_bike' 'walk_transit' 'knr_tnc'\n",
      " 'tnc_transit' 'pnr_walk' 'knr_walk' 'knr_pnr' 'walk_bike'\n",
      " 'carpool_transit' 'knr_transit' 'pnr_scooter' 'pnr_transit' 'scooter_tnc'\n",
      " 'walk_tnc' 'pnr_carpool' 'walk_knr' 'bike_scooter' 'knr_carpool'\n",
      " 'carpool_tnc' 'transit_scooter' 'pnr_tnc' 'tnc_walk' nan 'walk_pnr'\n",
      " 'transit_carpool' 'bike_walk' 'tnc_bike' 'carpool_pnr' 'walk_scooter'\n",
      " 'pnr_bike']\n",
      "\n",
      "egress_mode idx_3 find 6 rows, 0.2% of total\n",
      "egress_mode idx_4 find 47 rows, 2.0% of total\n",
      "egress_mode idx_5 find 28 rows, 1.2% of total\n",
      "egress_mode idx_6 find 64 rows, 2.7% of total\n",
      "\n",
      " responses with 3 egress modes have the following unique combinations of mode categories:\n",
      "['knr_tnc_walk' 'tnc_transit_walk' 'knr_pnr_transit' 'knr_transit_walk'\n",
      " 'knr_tnc_transit' 'walk_bike_scooter' 'pnr_walk_bike' 'pnr_tnc_bike'\n",
      " 'pnr_bike_scooter' 'transit_walk_transit' 'transit_transit_transit'\n",
      " 'transit_walk_bike' 'transit_transit_walk' 'pnr_transit_walk'\n",
      " 'knr_tnc_bike' 'transit_bike_walk' 'carpool_walk_bike' 'transit_knr_pnr'\n",
      " 'transit_walk_scooter' 'transit_knr_transit' 'knr_carpool_tnc']\n",
      "\n",
      "egress_mode idx_7 find 1 rows, 0.0% of total\n",
      "egress_mode idx_8 find 6 rows, 0.2% of total\n",
      "egress_mode idx_9 find 6 rows, 0.2% of total\n",
      "egress_mode idx_10 find 5 rows, 0.2% of total\n",
      "egress_mode idx_11 find 2 rows, 0.1% of total\n",
      "egress_mode idx_12 find 3 rows, 0.1% of total\n",
      "egress_mode idx_13 find 12 rows, 0.5% of total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCGID</th>\n",
       "      <th>Q2B_1_cat</th>\n",
       "      <th>Q2B_2_cat</th>\n",
       "      <th>Q2B_3_cat</th>\n",
       "      <th>Q2B_4_cat</th>\n",
       "      <th>Q2B_5_cat</th>\n",
       "      <th>Q2B_6_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>122</td>\n",
       "      <td>pnr</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>159</td>\n",
       "      <td>walk</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>tnc</td>\n",
       "      <td>knr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>443</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>pnr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>572</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>bike</td>\n",
       "      <td>scooter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>926</td>\n",
       "      <td>knr</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1018</td>\n",
       "      <td>knr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1055</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1566</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1714</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>scooter</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1774</td>\n",
       "      <td>pnr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2073</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2147</td>\n",
       "      <td>knr</td>\n",
       "      <td>carpool</td>\n",
       "      <td>tnc</td>\n",
       "      <td>transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CCGID Q2B_1_cat Q2B_2_cat Q2B_3_cat Q2B_4_cat Q2B_5_cat Q2B_6_cat\n",
       "120     122       pnr       tnc   transit   transit   transit   transit\n",
       "157     159      walk   transit   transit   transit       tnc       knr\n",
       "441     443   transit   transit      walk       pnr       NaN       NaN\n",
       "570     572   transit      walk      bike   scooter       NaN       NaN\n",
       "924     926       knr   transit   transit      walk       NaN       NaN\n",
       "1016   1018       knr   carpool       tnc   transit   transit   transit\n",
       "1053   1055   transit       NaN       NaN       NaN       NaN       NaN\n",
       "1564   1566       tnc   transit   transit      walk       NaN       NaN\n",
       "1712   1714   carpool       tnc   scooter     other       NaN       NaN\n",
       "1772   1774       pnr   carpool       tnc   transit   transit   transit\n",
       "2071   2073   carpool       tnc   transit      walk       NaN       NaN\n",
       "2145   2147       knr   carpool       tnc   transit       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. for responses with one egress_mode (egress_count==1) and the mode is not public transit,\n",
    "# set Q2B_1 as egress mode, and no after-transfer\n",
    "idx_1 = ((df.egress_count == 1) & (df.Q2B_1_cat != 'transit'))\n",
    "print('egress_mode idx_1 find {} rows, {:.1%} of total'.format(idx_1.sum(), idx_1.sum()/df.shape[0]))\n",
    "df.loc[idx_1, 'egress_mode'] = df['Q2B_1']\n",
    "\n",
    "# 2. for responses with one egress_mode (egress_count==1) and the mode is public transit,\n",
    "# set egress mode as \"Missing\", and Q2B_1 as after-transfer\n",
    "idx_2 = ((df.egress_count == 1) & (df.Q2B_1_cat == 'transit'))\n",
    "print('egress_mode idx_2 find {} rows, {:.1%} of total'.format(idx_2.sum(), idx_2.sum()/df.shape[0]))\n",
    "df.loc[idx_2, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_2, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "\n",
    "## two egress modes in raw data\n",
    "df.loc[df.egress_count == 2, 'egress_concat'] = df['Q2B_1_cat'] + '_' + df['Q2B_2_cat']\n",
    "print('\\n responses with 2 egress modes have the following unique combinations of mode categories:\\n{}\\n'.format(df.loc[df.egress_count == 2].egress_concat.unique()))\n",
    "\n",
    "# 3. for responses with two egress_mode (egress_count==2) and both are public transit,\n",
    "# set egress mode as \"Missing\", and after-transfer as \"transit_pending\"\n",
    "idx_3 = ((df.egress_count == 2) & (df.egress_concat == 'transit_transit'))\n",
    "print('egress_mode idx_3 find {} rows, {:.1%} of total'.format(idx_3.sum(), idx_3.sum()/df.shape[0]))\n",
    "df.loc[idx_3, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_3, 'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[idx_3, 'second_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "# 4/5. for responses with two egress_mode (egress_count==2) and only one value public transit,\n",
    "# set egress mode as the non-transit value, and the transit-value as after-transfer\n",
    "\n",
    "idx_4 = ((df.egress_count == 2) & (\n",
    "              (df.egress_concat == 'transit_walk') | (\n",
    "               df.egress_concat == 'transit_bike') | (\n",
    "               df.egress_concat == 'transit_scooter') | (\n",
    "               df.egress_concat == 'transit_carpool')))            # Q2B_1 is public transit\n",
    "print('egress_mode idx_4 find {} rows, {:.1%} of total'.format(idx_4.sum(), idx_4.sum()/df.shape[0]))\n",
    "df.loc[idx_4, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[idx_4, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "\n",
    "idx_5 = ((df.egress_count == 2) & (\n",
    "              (df.egress_concat == 'walk_transit') | (\n",
    "               df.egress_concat == 'tnc_transit') | (\n",
    "               df.egress_concat == 'carpool_transit') | (\n",
    "               df.egress_concat == 'knr_transit') | (\n",
    "               df.egress_concat == 'pnr_transit')))             # Q2B_2 is public transit\n",
    "print('egress_mode idx_5 find {} rows, {:.1%} of total'.format(idx_5.sum(), idx_5.sum()/df.shape[0]))\n",
    "df.loc[idx_5, 'egress_mode'] = df['Q2B_1']\n",
    "df.loc[idx_5, 'first_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "# 6. for responses with two egress_mode (egress_count==2) and both are not public transit,\n",
    "# set egress mode as \"Missing\", and no after-transfer\n",
    "\n",
    "idx_6 = ((df.egress_count == 2) & (df.egress_concat.str.contains('transit') == False))\n",
    "print('egress_mode idx_6 find {} rows, {:.1%} of total'.format(idx_6.sum(), idx_6.sum()/df.shape[0]))\n",
    "df.loc[idx_6, 'egress_mode'] = 'Missing'\n",
    "\n",
    "\n",
    "## three egress modes in raw data\n",
    "df.loc[df.egress_count == 3, 'egress_concat'] = df['Q2B_1_cat'] + '_' + df['Q2B_2_cat'] + '_' + df['Q2B_3_cat']\n",
    "print('\\n responses with 3 egress modes have the following unique combinations of mode categories:\\n{}\\n'.format(df.loc[df.egress_count == 3].egress_concat.unique()))\n",
    "\n",
    "# 7. for responses with three egress_mode (egress_count==3) and all three are transit,\n",
    "# then egress mode is \"Missing\", after-transfers are pending\n",
    "\n",
    "idx_7 = ((df.egress_count == 3) & (df.egress_concat == 'transit_transit_transit'))\n",
    "print('egress_mode idx_7 find {} rows, {:.1%} of total'.format(idx_7.sum(), idx_7.sum()/df.shape[0]))\n",
    "df.loc[idx_7, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_7, 'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[idx_7, 'second_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[idx_7, 'third_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "# 8/9/10. for responses with three egress_mode (egress_count==3) and only one value is public transit,\n",
    "# then egress mode is \"Missing\", the transit value is after-transfer\n",
    "idx_8 = ((df.egress_count == 3) & (\n",
    "              (df.egress_concat == 'transit_walk_bike') | (\n",
    "               df.egress_concat == 'transit_bike_walk') | (\n",
    "               df.egress_concat == 'transit_knr_pnr') | (\n",
    "               df.egress_concat == 'transit_walk_scooter') | (\n",
    "               df.egress_concat == 'transit_knr_transit')))         # Q2B_1 is public transit\n",
    "print('egress_mode idx_8 find {} rows, {:.1%} of total'.format(idx_8.sum(), idx_8.sum()/df.shape[0]))\n",
    "df.loc[idx_8, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_8, 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "\n",
    "idx_9 = ((df.egress_count == 3) & (\n",
    "              (df.egress_concat == 'tnc_transit_walk') | (\n",
    "               df.egress_concat == 'knr_transit_walk') | (\n",
    "               df.egress_concat == 'pnr_transit_walk')))        # Q2B_2 is public transit\n",
    "print('egress_mode idx_9 find {} rows, {:.1%} of total'.format(idx_9.sum(), idx_9.sum()/df.shape[0]))\n",
    "df.loc[idx_9, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_9, 'first_route_after_survey_alight'] = df['Q2B_2']\n",
    "\n",
    "idx_10 = ((df.egress_count == 3) & (\n",
    "              (df.egress_concat == 'knr_pnr_transit') | (\n",
    "               df.egress_concat == 'knr_tnc_transit')))        # Q2B_3 is public transit\n",
    "print('egress_mode idx_10 find {} rows, {:.1%} of total'.format(idx_10.sum(), idx_10.sum()/df.shape[0]))\n",
    "df.loc[idx_10, 'egress_mode'] = 'Missing'\n",
    "df.loc[idx_10, 'first_route_after_survey_alight'] = df['Q2B_3']\n",
    "\n",
    "# 11/12. for responses with three egress_mode (egress_count==3) and two are transits,\n",
    "# then egress mode is the non-transit value, after-transfers are pending\n",
    "idx_11 = ((df.egress_count == 3) & (\n",
    "            (df.egress_concat == 'transit_walk_transit') | (\n",
    "             df.egress_concat == 'transit_knr_transit')))     # Q2B_2 not transit\n",
    "print('egress_mode idx_11 find {} rows, {:.1%} of total'.format(idx_11.sum(), idx_11.sum()/df.shape[0]))\n",
    "df.loc[idx_11, 'egress_mode'] = df['Q2B_2']\n",
    "df.loc[idx_11, 'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[idx_11, 'second_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "idx_12 = ((df.egress_count == 3) & (df.egress_concat == 'transit_transit_walk'))  # Q2B_3 not transit\n",
    "print('egress_mode idx_12 find {} rows, {:.1%} of total'.format(idx_12.sum(), idx_12.sum()/df.shape[0]))\n",
    "df.loc[idx_12, 'egress_mode'] = df['Q2B_3']\n",
    "df.loc[idx_12, 'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[idx_12, 'second_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "# 13. for responses with three egress_mode (egress_count==3) and all are non-transit,\n",
    "# set egress mode as \"Missing\", and no after-transfer\n",
    "\n",
    "idx_13 = ((df.egress_count == 3) & (df.egress_concat.str.contains('transit') == False))\n",
    "print('egress_mode idx_13 find {} rows, {:.1%} of total'.format(idx_13.sum(), idx_13.sum()/df.shape[0]))\n",
    "df.loc[idx_13, 'egress_mode'] = 'Missing'\n",
    "\n",
    "\n",
    "# examine the remaining egress_mode.isnull()\n",
    "display(df.loc[df.egress_mode.isnull()][['CCGID', 'Q2B_1_cat', 'Q2B_2_cat',\n",
    "                                         'Q2B_3_cat', 'Q2B_4_cat',\n",
    "                                         'Q2B_5_cat', 'Q2B_6_cat']].dropna(how='all', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows is missing egress_mode\n"
     ]
    }
   ],
   "source": [
    "## cases with one transit mode and multiple non-transit modes - set the transit mode as after-transfer, egress_mode is 'Missing'\n",
    "# CCGID 572 (transit-walk-bike-scooter): Q2B_1 after-transfer\n",
    "# CCGID 1055 (transit): Q2B_1 after-transfer\n",
    "# CCGID 2073 (carpool-tnc-transit-walk): Q2B_3 after-transfer\n",
    "# CCGID 2147 (knr-carpool-tnc-transit): Q2B_4 after-transfer\n",
    "df.loc[(df.CCGID==572) | (df.CCGID==1055) | (df.CCGID==2073) | (df.CCGID==2147),\n",
    "       'egress_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==572) | (df.CCGID==1055), 'first_route_after_survey_alight'] = df['Q2B_1']\n",
    "df.loc[df.CCGID==2073, 'first_route_after_survey_alight'] = df['Q2B_3']\n",
    "df.loc[df.CCGID==2147, 'first_route_after_survey_alight'] = df['Q2B_4']\n",
    "\n",
    "# cases with two transit modes and multiple non-transit modes - set after-transfers as pending, egress_mode as 'Missing'\n",
    "# CCGID 443 (transit-transit-walk-pnr)\n",
    "# CCGID 926 (knr-transit-transit-walk)\n",
    "# CCGID 1566 (tnc-transit-transit-walk)\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==926) | (df.CCGID==1566),\n",
    "       'egress_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==926) | (df.CCGID==1566),\n",
    "       'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==443) | (df.CCGID==926) | (df.CCGID==1566),\n",
    "       'second_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "# cases with three or more transit modes and multiple non-transit modes - set after-transfers as pending, egress_mode as 'Missing'\n",
    "# CCGID 122 (pnr-tnc-transit-transit-transit-transit)\n",
    "# CCGID 159 (walk-transit-transit-transit-tnc-knr)\n",
    "# CCGID 1018 (knr-carpool-tnc-transit-transit-transit)\n",
    "# CCGID 1774 (pnr-carpool-tnc-transit-transit-transit)\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1774),\n",
    "       'egress_mode'] = 'Missing'\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1774),\n",
    "       'first_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1774),\n",
    "       'second_route_after_survey_alight'] = 'transit_pending'\n",
    "df.loc[(df.CCGID==122) | (df.CCGID==159) | (df.CCGID==1018) | (df.CCGID==1774),\n",
    "       'third_route_after_survey_alight'] = 'transit_pending'\n",
    "\n",
    "# cases with no transit mode and multiple non-transit modes - egree_mode is 'Missing', no after-transfer\n",
    "# CCGID 1714 (carpool-tnc-scooter-other)\n",
    "df.loc[df.CCGID==1714, 'egress_mode'] = 'Missing'\n",
    "\n",
    "\n",
    "# finally, check there is no row with egress_mode.isnull()\n",
    "print('{} rows is missing egress_mode'.format(df.egress_mode.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export 30 rows with pending before/after transfers\n"
     ]
    }
   ],
   "source": [
    "# export records with 'transit_pending' for further investigation\n",
    "df_pending = df.loc[(df.first_route_before_survey_board == 'transit_pending') | (\n",
    "                     df.first_route_after_survey_alight == 'transit_pending')]\n",
    "print('export {} rows with pending before/after transfers'.format(df_pending.shape[0]))\n",
    "df_pending.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\pending_transfers.csv', index=False)\n",
    "\n",
    "\n",
    "# drop interim fields\n",
    "df.drop(columns = [x + '_name' for x in ['Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6', \n",
    "                                         'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']] + \\\n",
    "                  [x + '_cat' for x in ['Q2A_1', 'Q2A_2', 'Q2A_3', 'Q2A_4', 'Q2A_5', 'Q2A_6', \n",
    "                                        'Q2B_1', 'Q2B_2', 'Q2B_3', 'Q2B_4', 'Q2B_5', 'Q2B_6']] + \\\n",
    "                  ['access_count', 'egress_count', 'access_concat', 'egress_concat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with 'hispanic' and 'ethnicity/race'  <a class=\"anchor\" id=\"race\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hispanic/Latino_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Middle Eastern_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_Middle Eastern_Middle Eastern_Middle Eastern', 'Black/African American_Middle Eastern_Middle Eastern_Middle Eastern', 'Other_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Hispanic/Latino_Middle Eastern_Middle Eastern', 'Mixed_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_Middle Eastern_Middle Eastern', 'White_Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern', 'NA_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_Asian/Pacific Islander_Middle Eastern', 'American Indian/Alaskan Native_Middle Eastern_Middle Eastern_Middle Eastern', 'White_Black/African American_American Indian/Alaskan Native_Middle Eastern', 'Asian/Pacific Islander_Hispanic/Latino_Middle Eastern_Middle Eastern', 'White_Black/African American_Asian/Pacific Islander_Hispanic/Latino', 'Black/African American_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern', 'White_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Black/African American_Other_Middle Eastern_Middle Eastern', 'White_Asian/Pacific Islander_Hispanic/Latino_American Indian/Alaskan Native', 'White_Black/African American_Hispanic/Latino_American Indian/Alaskan Native', 'White_American Indian/Alaskan Native_Middle Eastern_Middle Eastern', 'White_East Indian/Pakistani_Middle Eastern_Middle Eastern', 'Middle Eastern_Middle Eastern_Middle Eastern_Middle Eastern', 'East Indian/Pakistani_Middle Eastern_Middle Eastern_Middle Eastern', 'Hispanic/Latino_American Indian/Alaskan Native_Middle Eastern_Middle Eastern', 'White_Black/African American_Hispanic/Latino_Middle Eastern', 'Hispanic/Latino_Asian/Pacific Islander_Middle Eastern_Middle Eastern', 'Asian/Pacific Islander_White_Middle Eastern_Middle Eastern', 'Black/African American_Hispanic/Latino_Middle Eastern_Middle Eastern', 'White_Asian/Pacific Islander_American Indian/Alaskan Native_Middle Eastern']\n"
     ]
    }
   ],
   "source": [
    "race_dict = {1: 'White',\n",
    "             2: 'Black/African American',\n",
    "             3: 'Asian/Pacific Islander',\n",
    "             4: 'Hispanic/Latino',\n",
    "             5: 'American Indian/Alaskan Native',\n",
    "             6: 'Other',\n",
    "             7: 'Other',\n",
    "             8: 'Other',\n",
    "             9: 'Mixed',\n",
    "             10: 'Middle Eastern',\n",
    "             11: 'East Indian/Pakistani',\n",
    "             0: 'NA'}\n",
    "\n",
    "for i in ['Q20_1', 'Q20_2', 'Q20_3', 'Q20_4']:\n",
    "    df[i] = df[i].fillna(10)\n",
    "    df[i].replace(to_replace = ' ', value = 10, inplace=True)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(race_dict)\n",
    "    \n",
    "df['race_concat'] = df['Q20_1_temp'] + '_' + df['Q20_2_temp'] + '_' + df['Q20_3_temp'] + '_' + df['Q20_4_temp']\n",
    "print(list(df['race_concat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     2142\n",
       "YES     264\n",
       "Name: hispanic, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'hispanic' field\n",
    "df['hispanic'] = 'NO'\n",
    "df.loc[df.race_concat.str.contains('Hispanic',na=False), 'hispanic'] = 'YES'\n",
    "df.hispanic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create race_dmy_xx\n",
    "\n",
    "df['race_dmy_ind'] = 0\n",
    "df.loc[df.race_concat.str.contains('American Indian/Alaskan Native',na=False), 'race_dmy_ind'] = 1\n",
    "\n",
    "df['race_dmy_hwi'] = 0\n",
    "df.loc[df.race_concat.str.contains('Native Hawaiian/Pacific Islander',na=False), 'race_dmy_hwi'] = 1\n",
    "\n",
    "df['race_dmy_blk'] = 0\n",
    "df.loc[df.race_concat.str.contains('Black/African American',na=False), 'race_dmy_blk'] = 1\n",
    "\n",
    "df['race_dmy_wht'] = 0\n",
    "df.loc[df.race_concat.str.contains('White',na=False), 'race_dmy_wht'] = 1\n",
    "\n",
    "df['race_dmy_asn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Asian',na=False) | df.race_concat.str.contains('East Indian/Pakistani',na=False), 'race_dmy_asn'] = 1\n",
    "\n",
    "df['race_dmy_mdl_estn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Middle Eastern',na=False), 'race_dmy_mdl_estn'] = 1\n",
    "\n",
    "# drop temp fields\n",
    "df.drop(columns = ['Q20_1_temp', 'Q20_2_temp', 'Q20_3_temp', 'Q20_4_temp', 'race_concat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with trip purpose <a class=\"anchor\" id=\"trip_purp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_3</th>\n",
       "      <th>Q8_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Moving/traveling between homes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Church/volunteering/political</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Personal / Family business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Personal / Family business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Airport trip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Going Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Moving/traveling between homes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Commute to/from work</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>Vacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Travel to/from school</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Vacation</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Leisure/Recreation</td>\n",
       "      <td>Visit family/friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>Business travel</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Q8_1                            Q8_2  \\\n",
       "0               Visit family/friends                             NaN   \n",
       "1                 Leisure/Recreation                             NaN   \n",
       "2              Travel to/from school                             NaN   \n",
       "3                 Leisure/Recreation            Visit family/friends   \n",
       "4                                NaN                             NaN   \n",
       "6                           Vacation                             NaN   \n",
       "8                              Other                             NaN   \n",
       "14              Commute to/from work                             NaN   \n",
       "23                   Business travel                             NaN   \n",
       "34              Visit family/friends                        Vacation   \n",
       "52                Leisure/Recreation  Moving/traveling between homes   \n",
       "79              Commute to/from work           Travel to/from school   \n",
       "84     Church/volunteering/political                             NaN   \n",
       "85                   Business travel            Visit family/friends   \n",
       "95                Leisure/Recreation            Visit family/friends   \n",
       "96        Personal / Family business                             NaN   \n",
       "131             Commute to/from work              Leisure/Recreation   \n",
       "188                  Business travel              Leisure/Recreation   \n",
       "215            Travel to/from school              Leisure/Recreation   \n",
       "278             Visit family/friends      Personal / Family business   \n",
       "316             Commute to/from work            Visit family/friends   \n",
       "428                  Business travel              Leisure/Recreation   \n",
       "480             Commute to/from work                 Business travel   \n",
       "561                  Business travel              Leisure/Recreation   \n",
       "813             Commute to/from work                 Business travel   \n",
       "844                     Airport trip                             NaN   \n",
       "905                       Going Home                             NaN   \n",
       "910               Leisure/Recreation                        Vacation   \n",
       "929             Commute to/from work           Travel to/from school   \n",
       "941               Leisure/Recreation            Commute to/from work   \n",
       "1087           Travel to/from school              Leisure/Recreation   \n",
       "1133            Commute to/from work                 Business travel   \n",
       "1209  Moving/traveling between homes                             NaN   \n",
       "1473            Commute to/from work                 Business travel   \n",
       "1792           Travel to/from school            Visit family/friends   \n",
       "1971                        Vacation              Leisure/Recreation   \n",
       "1992              Leisure/Recreation                           Other   \n",
       "2011                 Business travel              Leisure/Recreation   \n",
       "2275                 Business travel                        Vacation   \n",
       "\n",
       "                       Q8_3                  Q8_4  \n",
       "0                       NaN                   NaN  \n",
       "1                       NaN                   NaN  \n",
       "2                       NaN                   NaN  \n",
       "3                       NaN                   NaN  \n",
       "4                       NaN                   NaN  \n",
       "6                       NaN                   NaN  \n",
       "8                       NaN                   NaN  \n",
       "14                      NaN                   NaN  \n",
       "23                      NaN                   NaN  \n",
       "34                      NaN                   NaN  \n",
       "52                      NaN                   NaN  \n",
       "79                      NaN                   NaN  \n",
       "84                      NaN                   NaN  \n",
       "85                      NaN                   NaN  \n",
       "95                 Vacation                   NaN  \n",
       "96                      NaN                   NaN  \n",
       "131                     NaN                   NaN  \n",
       "188                Vacation                   NaN  \n",
       "215                     NaN                   NaN  \n",
       "278                     NaN                   NaN  \n",
       "316                     NaN                   NaN  \n",
       "428                     NaN                   NaN  \n",
       "480                     NaN                   NaN  \n",
       "561    Visit family/friends              Vacation  \n",
       "813      Leisure/Recreation  Visit family/friends  \n",
       "844                     NaN                   NaN  \n",
       "905                     NaN                   NaN  \n",
       "910                     NaN                   NaN  \n",
       "929                Vacation                   NaN  \n",
       "941                     NaN                   NaN  \n",
       "1087   Visit family/friends                   NaN  \n",
       "1133  Travel to/from school    Leisure/Recreation  \n",
       "1209                    NaN                   NaN  \n",
       "1473   Visit family/friends              Vacation  \n",
       "1792                    NaN                   NaN  \n",
       "1971                    NaN                   NaN  \n",
       "1992                    NaN                   NaN  \n",
       "2011   Visit family/friends                   NaN  \n",
       "2275                    NaN                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trip_purp_dict = {\n",
    "    '1': 'Commute to/from work', \n",
    "    '2': 'Business travel', \n",
    "    '3': 'Travel to/from school', \n",
    "    '4': 'Leisure/Recreation', \n",
    "    '5': 'Visit family/friends', \n",
    "    '6': 'Vacation', \n",
    "    '7': 'Other', \n",
    "    '8': 'Personal / Family business', \n",
    "    '9': 'Travel to or from school', \n",
    "    '10': 'Other (specify)', \n",
    "    '11': 'School/ Group Trip', \n",
    "    '12': 'Church/volunteering/political', \n",
    "    '13': 'Just to enjoy the train/Outing to ride train', \n",
    "    '14': 'Moving/traveling between homes', \n",
    "    '15': 'Going Home', \n",
    "    '16': 'Airport trip'}\n",
    "\n",
    "for colname in ['Q8_1','Q8_2','Q8_3','Q8_4']:\n",
    "    df[colname].fillna(0, inplace=True)\n",
    "    df[colname] = df[colname].apply(lambda x: str(int(x)))\n",
    "    df[colname] = df[colname].map(trip_purp_dict)\n",
    "\n",
    "# print out all possible combinations in the data\n",
    "display(df[['Q8_1','Q8_2','Q8_3','Q8_4']].dropna(how='all', axis=1).drop_duplicates())\n",
    "\n",
    "# \"work\" takes precedent when non-work is in front of work\n",
    "df.loc[(df.Q8_1 == 'Leisure/Recreation') & (df.Q8_2 == 'Commute to/from work'), 'trip_purp'] = df['Q8_2']\n",
    "\n",
    "# otherwise, Q8_1 seems the proper trip_purp\n",
    "df['trip_purp'] = df['Q8_1']\n",
    "df.loc[df.trip_purp.isnull(), 'trip_purp'] = 'missing' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code home lat/lon based on zipcode <a class=\"anchor\" id=\"home_lat_lon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 records are missing home lat/lon, accounting for 26.1% of all\n"
     ]
    }
   ],
   "source": [
    "# read zipcode spatial data\n",
    "zip_shp = gpd.read_file(r'M:\\Data\\GIS layers\\zip_code_sr\\zip_code_sr.shp')\n",
    "\n",
    "# get lat/lon\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = zip_shp['geometry'].centroid\n",
    "x,y = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "\n",
    "zip_shp['lat'] = y\n",
    "zip_shp['lon'] = x\n",
    "\n",
    "zip_shp['postcode'] = zip_shp['postcode'].apply(lambda x: int(x))\n",
    "\n",
    "# merge into the survey data\n",
    "df = df.merge(zip_shp[['postcode', 'lat', 'lon']], left_on='Q22', right_on='postcode', how='left')\n",
    "\n",
    "no_latlon = df.loc[df.lat.isnull() | df.lon.isnull()].shape[0]\n",
    "print('{} records are missing home lat/lon, accounting for {:.1%} of all'.format(no_latlon, no_latlon/df.shape[0]))\n",
    "\n",
    "# rename\n",
    "df.rename(columns = {'lat': 'home_lat',\n",
    "                     'lon': 'home_lon'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code board/alight station name and lat/lon <a class=\"anchor\" id=\"station_lat_lon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# read x/y data\n",
    "station_xy = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\passenger_rail_stations.csv',\n",
    "                         usecols = ['routename', 'station_na', 'x', 'y'])\n",
    "\n",
    "station_xy_cc  = station_xy.loc[station_xy.routename == 'Capitol Corridor']\n",
    "\n",
    "# rename 'Santa Clara' to 'Santa Clara Great America' and add one row for 'Santa Clara University'\n",
    "station_xy_cc.loc[station_xy_cc.station_na == 'Santa Clara', 'station_na'] = 'Santa Clara Great America'\n",
    "\n",
    "add_station = {'routename': 'Capitol Corridor', 'station_na': 'Santa Clara University', 'x': -121.9396494, 'y': 37.3517273} \n",
    "station_xy_cc = station_xy_cc.append(add_station, ignore_index = True)\n",
    "\n",
    "\n",
    "# build dictionary for Boarding/Alighting Station\n",
    "# for survey responses with value 21 Fairfield (Unspecified), \n",
    "# 22 Oakland (Unspecified), 23 Santa Clara (Unspecified),\n",
    "# need to re-assign to the station with more ridership within the same city\n",
    "\n",
    "cc_station_dict = {'1': 'Auburn',\n",
    "                   '2': 'Berkeley',\n",
    "                   '3': 'Colfax',\n",
    "                   '4': 'Davis',\n",
    "                   '5': 'Emeryville',\n",
    "                   '6': 'Suisun-fairfield',\n",
    "                   '7': 'Fairfield/Vacaville Station',\n",
    "                   '8': 'Fremont',\n",
    "                   '9': 'Hayward',\n",
    "                   '10': 'Martinez',\n",
    "                   '11': 'Jack London Square',\n",
    "                   '12': 'Oakland Coliseum',\n",
    "                   '13': 'Richmond',\n",
    "                   '14': 'Rocklin',\n",
    "                   '15': 'Roseville',\n",
    "                   '16': 'Sacramento',\n",
    "                   '17': 'San Jose',\n",
    "                   '18': 'Santa Clara Great America',\n",
    "                   '19': 'Santa Clara University',\n",
    "                   '20': 'Other',\n",
    "                   '21': 'Suisun-fairfield',\n",
    "                   '22': 'Jack London Square',\n",
    "                   '23': 'Santa Clara Great America'}\n",
    "\n",
    "# merge station names into the survey data\n",
    "for colname in ['Q1A', 'Q1B']:\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].apply(lambda x: str(x))\n",
    "    df[colname] = df[colname].map(cc_station_dict)\n",
    "    \n",
    "# merge lat/lon into the survey data\n",
    "df_board = df[['CCGID', 'Q1A']].merge(station_xy_cc, left_on='Q1A', right_on='station_na', how='left')\n",
    "df_board = df_board[['CCGID', 'x', 'y']].rename(columns = {'x': 'survey_board_lon',\n",
    "                                                        'y': 'survey_board_lat'})\n",
    "\n",
    "df_alight = df[['CCGID', 'Q1B']].merge(station_xy_cc, left_on='Q1B', right_on='station_na', how='left')\n",
    "df_alight = df_alight[['CCGID', 'x', 'y']].rename(columns = {'x': 'survey_alight_lon',\n",
    "                                                          'y': 'survey_alight_lat'})\n",
    "\n",
    "df = df.merge(df_board, on='CCGID', how='left').merge(df_alight, on='CCGID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update 'weight' <a class=\"anchor\" id=\"weight\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2406 rows of updated weights: \n",
      "   CCGID  weight\n",
      "0      1     0.0\n",
      "1      2     0.0\n",
      "2      3     0.0\n",
      "3      4     0.0\n",
      "4      5     0.0\n",
      "total weights: 5762.2030651341\n"
     ]
    }
   ],
   "source": [
    "weight_df = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\Weighting\\Capitol_Corridor_Weights.csv')\n",
    "print('read {} rows of updated weights: \\n{}'.format(weight_df.shape[0], weight_df.head()))\n",
    "\n",
    "df = df.merge(weight_df, on='CCGID', how='left')\n",
    "print('total weights: {}'.format(df.weight.sum()))\n",
    "\n",
    "# drop the raw 'weight' column\n",
    "df.drop(columns = ['WEIGHT'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute year_born from 'age group' <a class=\"anchor\" id=\"age\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989.0    520\n",
       "1979.0    497\n",
       "1969.0    421\n",
       "1959.0    415\n",
       "1949.0    209\n",
       "1998.0    202\n",
       "2004.0     36\n",
       "Name: year_born_four_digit, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_born_dict = {1: 2004,   # Under 18, 2019-15=2004\n",
    "                  2: 1998,   # 18-24, 2019-21=1998\n",
    "                  3: 1989,   # 25-34, 2019-30=1989\n",
    "                  4: 1979,   # 35-44, 2019-40=1979\n",
    "                  5: 1969,   # 45-54, 2019-50=1969\n",
    "                  6: 1959,   # 55-64, 2019-60=1959\n",
    "                  7: 1949,   # 65 and older, 2019-70=1949\n",
    "                 }\n",
    "\n",
    "df['year_born_four_digit'] = df['Q18'].map(year_born_dict)\n",
    "df.year_born_four_digit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export survey data <a class=\"anchor\" id=\"survey_export\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export 2406 rows of data to CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns = {'CCGID': 'ID'}, inplace=True)\n",
    "\n",
    "final_fname = 'CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv'\n",
    "print('export {} rows of data to {}'.format(df.shape[0], final_fname))\n",
    "\n",
    "df.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\As CSV\\CAPCO19 Data-For MTC_NO POUND OR SINGLE QUOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build standard dictionary <a class=\"anchor\" id=\"standard_dict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read raw variable dictionary 'Field Guide'  <a class=\"anchor\" id=\"raw_dict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw survey dictionary\n",
    "survey_dict = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\CAPCO19 Data-For MTC.xlsx',\n",
    "                            sheet_name='Field Guide')\n",
    "\n",
    "# back fill name in 'Field' column\n",
    "survey_dict.loc[(survey_dict.Field == '       ') | (survey_dict.Field == '  ') | (survey_dict.Field == '        '),\n",
    "                'Field'] = np.nan\n",
    "survey_dict['Field'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# rename to correctly reflect the info\n",
    "survey_dict.rename(columns={'Field': 'Survey_Variable',\n",
    "                            'Question/Description': 'Survey_Response',\n",
    "                            'Unnamed: 2': 'Generic_Response_old'}, inplace=True)\n",
    "\n",
    "# only keep needed columns\n",
    "var_dict = survey_dict[['Survey_Variable', 'Survey_Response', 'Generic_Response_old']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_Variable</th>\n",
       "      <th>Survey_Response</th>\n",
       "      <th>Generic_Response_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RespNum</td>\n",
       "      <td>Software added ID number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCGID</td>\n",
       "      <td>CCG ID Number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Train Number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTDATE</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PERIOD</td>\n",
       "      <td>STRATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PERIOD</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PERIOD</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language of survey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Language</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Language</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Language</td>\n",
       "      <td>3</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q1A</td>\n",
       "      <td>Boarding Station</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>Alighting Station</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>1</td>\n",
       "      <td>Auburn (Grass Valley/Nevada City/Reno/Truckee)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>2</td>\n",
       "      <td>Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>3</td>\n",
       "      <td>Colfax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>4</td>\n",
       "      <td>Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>5</td>\n",
       "      <td>Emeryville (San Francisco/ SFO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>6</td>\n",
       "      <td>Fairfield-Suisun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>7</td>\n",
       "      <td>Fairfield-Vacaville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>8</td>\n",
       "      <td>Fremont  (Centerville)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>9</td>\n",
       "      <td>Hayward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>10</td>\n",
       "      <td>Martinez (Bakersfield, Eureka, Ukiah)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>11</td>\n",
       "      <td>Oakland – JLS (Modesto/Merced)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>12</td>\n",
       "      <td>Oakland Coliseum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>13</td>\n",
       "      <td>Richmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>14</td>\n",
       "      <td>Rocklin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>15</td>\n",
       "      <td>Roseville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>16</td>\n",
       "      <td>Sacramento (Fresno/Chico/Placerville/Stateline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q1B</td>\n",
       "      <td>17</td>\n",
       "      <td>San Jose (Salinas / Monterey / Santa Cruz)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survey_Variable           Survey_Response  \\\n",
       "0          RespNum  Software added ID number   \n",
       "1            CCGID             CCG ID Number   \n",
       "2            TRAIN              Train Number   \n",
       "3          INTDATE            Interview Date   \n",
       "4           PERIOD                    STRATA   \n",
       "5           PERIOD                         1   \n",
       "6           PERIOD                         2   \n",
       "7         Language        Language of survey   \n",
       "8         Language                         1   \n",
       "9         Language                         2   \n",
       "10        Language                         3   \n",
       "11             Q1A          Boarding Station   \n",
       "12             Q1B         Alighting Station   \n",
       "13             Q1B                         1   \n",
       "14             Q1B                         2   \n",
       "15             Q1B                         3   \n",
       "16             Q1B                         4   \n",
       "17             Q1B                         5   \n",
       "18             Q1B                         6   \n",
       "19             Q1B                         7   \n",
       "20             Q1B                         8   \n",
       "21             Q1B                         9   \n",
       "22             Q1B                        10   \n",
       "23             Q1B                        11   \n",
       "24             Q1B                        12   \n",
       "25             Q1B                        13   \n",
       "26             Q1B                        14   \n",
       "27             Q1B                        15   \n",
       "28             Q1B                        16   \n",
       "29             Q1B                        17   \n",
       "\n",
       "                                 Generic_Response_old  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                            Weekday   \n",
       "6                                             Weekend  \n",
       "7                                                 NaN  \n",
       "8                                             English  \n",
       "9                                             Spanish  \n",
       "10                                            Chinese  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13    Auburn (Grass Valley/Nevada City/Reno/Truckee)   \n",
       "14                                           Berkeley  \n",
       "15                                             Colfax  \n",
       "16                                              Davis  \n",
       "17                    Emeryville (San Francisco/ SFO)  \n",
       "18                                   Fairfield-Suisun  \n",
       "19                                Fairfield-Vacaville  \n",
       "20                             Fremont  (Centerville)  \n",
       "21                                            Hayward  \n",
       "22              Martinez (Bakersfield, Eureka, Ukiah)  \n",
       "23                     Oakland – JLS (Modesto/Merced)  \n",
       "24                                   Oakland Coliseum  \n",
       "25                                           Richmond  \n",
       "26                                            Rocklin  \n",
       "27                                          Roseville  \n",
       "28  Sacramento (Fresno/Chico/Placerville/Stateline...  \n",
       "29         San Jose (Salinas / Monterey / Santa Cruz)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add rows to the dictionary for the new fields added to the survey data <a class=\"anchor\" id=\"add_row\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "# add rows for 'access_mode'\n",
    "access_mode_dict = var_dict.loc[(var_dict.Survey_Variable == 'Q2B_1-Q2B_6') & (var_dict.Generic_Response_old.notnull())]\n",
    "access_mode_dict.loc[access_mode_dict.Survey_Variable == 'Q2B_1-Q2B_6', 'Survey_Variable'] = 'access_mode'\n",
    "# display(access_mode_dict)\n",
    "var_dict = var_dict.append(access_mode_dict, ignore_index=True)\n",
    "\n",
    "# replace 'Q2A_1-Q2A_6' with new field name 'egress_mode'\n",
    "var_dict.loc[(var_dict.Survey_Variable == 'Q2B_1-Q2B_6') & (var_dict.Generic_Response_old.notnull()), 'Survey_Variable'] = 'egress_mode'\n",
    "\n",
    "# drop the categoric dictionary part of Q1B\n",
    "var_dict = var_dict.loc[(var_dict.Survey_Variable != 'Q1B') | (\n",
    "                             (var_dict.Survey_Variable == 'Q1B') & (var_dict.Survey_Response == 'Alighting Station'))]\n",
    "\n",
    "# add race and hispanic fields to the dictionary\n",
    "race_dict = pd.DataFrame(np.array([['hispanic', 'YES', 'YES'],\n",
    "                                   ['hispanic', 'NO', 'NO'],\n",
    "                                   ['race_dmy_ind', 1, 1],\n",
    "                                   ['race_dmy_hwi', 1, 1],\n",
    "                                   ['race_dmy_blk', 1, 1],\n",
    "                                   ['race_dmy_wht', 1, 1],\n",
    "                                   ['race_dmy_asn', 1, 1],\n",
    "                                   ['race_dmy_mdl_estn', 1, 1],\n",
    "                                   ['race_dmy_ind', 0, 0],\n",
    "                                   ['race_dmy_hwi', 0, 0],\n",
    "                                   ['race_dmy_blk', 0, 0],\n",
    "                                   ['race_dmy_wht', 0, 0],\n",
    "                                   ['race_dmy_asn', 0, 0],\n",
    "                                   ['race_dmy_mdl_estn', 0, 0]]),\n",
    "                         columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "# display(race_dict)\n",
    "var_dict = var_dict.append(race_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add trip_purp rows\n",
    "trip_purpose_dict = df[['trip_purp']].drop_duplicates()\n",
    "trip_purpose_dict.columns = ['Survey_Response']\n",
    "trip_purpose_dict['Survey_Variable'] = 'trip_purp'\n",
    "trip_purpose_dict['Generic_Response_old'] = trip_purpose_dict['Survey_Response']\n",
    "# trip_purpose_dict[['Survey_Variable', 'Survey_Response', 'Generic_Response_old']]\n",
    "var_dict = var_dict.append(trip_purpose_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add home lat/lon rows\n",
    "home_dict = pd.DataFrame(np.array([['home_lat', 'NONCATEGORICAL', np.nan],\n",
    "                                   ['home_lon', 'NONCATEGORICAL', np.nan]]),\n",
    "                         columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(home_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add survey_board/alight lat/lon rows\n",
    "board_alight_dict = pd.DataFrame(np.array([['survey_board_lon', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_board_lat', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_alight_lon', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['survey_alight_lat', 'NONCATEGORICAL', np.nan]]),\n",
    "                                 columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(board_alight_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "# add transfer routes rows\n",
    "trans_routes_dict = pd.DataFrame(np.array([['first_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['second_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['third_route_before_survey_board', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['first_route_after_survey_alight', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['second_route_after_survey_alight', 'NONCATEGORICAL', np.nan],\n",
    "                                           ['third_route_after_survey_alight', 'NONCATEGORICAL', np.nan]]),\n",
    "                                 columns=['Survey_Variable', 'Survey_Response', 'Generic_Response_old'])\n",
    "var_dict = var_dict.append(trans_routes_dict, ignore_index=True)\n",
    "\n",
    "# add new weight row\n",
    "var_dict.loc[len(var_dict.index)] = ['weight', 'NONCATEGORICAL', np.nan]\n",
    "\n",
    "# add year_born row\n",
    "var_dict.loc[len(var_dict.index)] = ['year_born_four_digit', 'NONCATEGORICAL', np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add default fields in the standard dictionary <a class=\"anchor\" id=\"add_fields\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns 'Generic_variable'\n",
    "var_dict['Generic_Variable'] = ''\n",
    "var_dict.loc[var_dict.Survey_Variable == 'CCGID', 'Generic_Variable'] = 'ID'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'CCGID', 'Survey_Variable'] = 'ID'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'TRAIN', 'Generic_Variable'] = 'route'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'INTDATE', 'Generic_Variable'] = 'date_string'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'PERIOD', 'Generic_Variable'] = 'weekpart'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Language', 'Generic_Variable'] = 'interview_language'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Language', 'Survey_Variable'] = 'LANGUAGE'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q1A', 'Generic_Variable'] = 'onoff_enter_station'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q1B', 'Generic_Variable'] = 'onoff_exit_station'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q9', 'Generic_Variable'] = 'fare_category'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q10', 'Generic_Variable'] = 'fare_medium'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q17', 'Generic_Variable'] = 'gender'\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q19', 'Generic_Variable'] = 'household_income'\n",
    "\n",
    "var_dict.loc[var_dict.Survey_Variable == 'Q21', 'Generic_Variable'] = 'persons'\n",
    "\n",
    "# newly created fields:\n",
    "var_dict.loc[var_dict.Survey_Variable.str.contains('race_dmy_',na=False), 'Generic_Variable'] = var_dict['Survey_Variable']\n",
    "\n",
    "for varname in ['access_mode', 'egress_mode', 'trip_purp', 'home_lat', 'home_lon', 'weight', 'hispanic',\n",
    "                'survey_board_lon', 'survey_board_lat', 'survey_alight_lon', 'survey_alight_lat',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "                'third_route_before_survey_board', 'first_route_after_survey_alight',\n",
    "                'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname,  'Generic_Variable'] = varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values for 'Survey_Response' and 'Generic_Response' for noncanonical variables\n",
    "var_dict['Generic_Response'] = ''\n",
    "\n",
    "for varname in ['ID', 'TRAIN', 'INTDATE', 'Q1A', 'Q1B', 'Q22', 'weight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname, 'Survey_Response'] = 'NONCATEGORICAL'\n",
    "    \n",
    "for varname in ['ID', 'TRAIN', 'INTDATE', 'Q1A', 'Q1B', 'Q22', 'weight', 'year_born_four_digit',\n",
    "                'home_lat', 'home_lon',\n",
    "                'survey_board_lon', 'survey_board_lat', 'survey_alight_lon', 'survey_alight_lat',\n",
    "                'first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "                'third_route_before_survey_board', 'first_route_after_survey_alight',\n",
    "                'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    var_dict.loc[var_dict.Survey_Variable == varname, 'Generic_Response'] = 'NONCATEGORICAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict['operator'] = 'Capitol Corridor'\n",
    "var_dict['Survey_year'] = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check consistency between values in survey data and in the dictionary <a class=\"anchor\" id=\"check\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERIOD\n",
      "LANGUAGE\n",
      "egress_mode\n",
      "Q9\n",
      "Q10\n",
      "Q17\n",
      "Q19\n",
      "Q21\n",
      "access_mode\n",
      "hispanic\n",
      "race_dmy_ind\n",
      "race_dmy_hwi\n",
      "race_dmy_blk\n",
      "race_dmy_wht\n",
      "race_dmy_asn\n",
      "race_dmy_mdl_estn\n",
      "trip_purp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5491: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# check if all values in the survey data are represented in the dictionary\n",
    "\n",
    "var_dict_cat = var_dict.loc[(var_dict.Survey_Response != 'NONCATEGORICAL') & (\n",
    "                             var_dict.Generic_Response_old.notnull()) & (\n",
    "                             var_dict.Generic_Variable != '')]\n",
    "\n",
    "for fieldname in list(var_dict_cat.Survey_Variable.unique()):\n",
    "#     fieldname = fieldname.upper()\n",
    "    print(fieldname)\n",
    "    values = var_dict.loc[var_dict.Survey_Variable == fieldname]\n",
    "    \n",
    "    if fieldname in ['race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_mdl_estn']:\n",
    "        values.Survey_Response = values.Survey_Response.apply(lambda x: int(x))\n",
    "        \n",
    "    comp = df.merge(values, left_on = fieldname, right_on = 'Survey_Response', how='left')\n",
    "    comp_diff = comp.loc[comp[fieldname].isnull()]\n",
    "    if comp_diff.shape[0] > 0:\n",
    "        print(comp_diff[fieldname].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export raw standard dictionary <a class=\"anchor\" id=\"export_dict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export raw dictionary with 35 variables:\n",
      "['ID' 'TRAIN' 'INTDATE' 'PERIOD' 'LANGUAGE' 'Q1A' 'Q1B' 'egress_mode' 'Q9'\n",
      " 'Q10' 'Q17' 'Q19' 'Q21' 'access_mode' 'hispanic' 'race_dmy_ind'\n",
      " 'race_dmy_hwi' 'race_dmy_blk' 'race_dmy_wht' 'race_dmy_asn'\n",
      " 'race_dmy_mdl_estn' 'trip_purp' 'home_lat' 'home_lon' 'survey_board_lon'\n",
      " 'survey_board_lat' 'survey_alight_lon' 'survey_alight_lat'\n",
      " 'first_route_before_survey_board' 'second_route_before_survey_board'\n",
      " 'third_route_before_survey_board' 'first_route_after_survey_alight'\n",
      " 'second_route_after_survey_alight' 'third_route_after_survey_alight'\n",
      " 'weight']\n"
     ]
    }
   ],
   "source": [
    "# will manually add 'Generic_Response' for canonical variables in the exported file\n",
    "\n",
    "# only keep rows for needed variables\n",
    "var_dict = var_dict.loc[(var_dict.Generic_Variable != '') & (\n",
    "    (var_dict.Generic_Response == 'NONCATEGORICAL') | var_dict.Generic_Response_old.notnull())]\n",
    "\n",
    "print('export raw dictionary with {} variables:\\n{}'.format(len(var_dict.Survey_Variable.unique()),\n",
    "                                                          var_dict.Survey_Variable.unique()))\n",
    "\n",
    "var_dict.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\var_dict_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build canonical route crosswalk <a class=\"anchor\" id=\"canonical_route\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_routes = pd.DataFrame(np.array([[5, 'BART___BART',             'BART',     'heavy rail'],\n",
    "                                          [6, 'CALTRAIN___CALTRAIN',     'Caltrain', 'commuter rail'],\n",
    "                                          [7, 'Missing___missing',       'Missing',  'light rail'],\n",
    "                                          [8, 'AMTRAK___Amtrak Shuttle', 'AMTRAK',   'local bus'],\n",
    "                                          [9, 'AMTRAK___AMTRAK',         'AMTRAK',   'commuter rail'],\n",
    "                                          [10,'Missing___missing',       'Missing',  'local_bus']]),\n",
    "                                columns=['survey_name','canonical_name','canonical_operator','technology'])\n",
    "\n",
    "canonical_routes['survey'] = 'Capitol Corridor'\n",
    "canonical_routes['survey_year'] = 2019\n",
    "canonical_routes.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Capitol Corridor\\OD Survey 2019\\routes_canonical.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
