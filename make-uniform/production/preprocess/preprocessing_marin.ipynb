{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 1216 records, with 1216 unique RespNum and 1216 unique CCGID\n",
      "sum of WEIGHT of all records: 18016.96681668181\n",
      "sum of TWEIGHT of all records: 53322.704040519806\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel(r'M:\\Data\\OnBoard\\Data and Reports\\Marin Transit\\Final Data\\marin transit_data file_finalreweighted043018_01222021.xlsx', sheet_name='MarinTransit_Data File')\n",
    "print('dataset has {} records, with {} unique RespNum and {} unique CCGID'.format(df_raw.shape[0],\n",
    "                                                                                  len(df_raw.sys_RespNum.unique()),\n",
    "                                                                                  len(df_raw.CCGID.unique())))\n",
    "print('sum of WEIGHT of all records: {}'.format(df_raw.WEIGHT.sum()))\n",
    "print('sum of TWEIGHT of all records: {}'.format(df_raw.TWEIGHT.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-03-28' '2017-03-29' '2017-03-31' '2017-04-01' '2017-04-03'\n",
      " '2017-04-08' '2017-03-30' '2017-04-06' '2017-04-09' '2017-04-17'\n",
      " '2017-04-21' '2017-04-23' '2017-04-24' '2017-04-28' '2017-04-30'\n",
      " '2017-04-07' '2017-04-04' '2017-04-05' '2017-04-18' '2017-04-19'\n",
      " '2017-04-20' '2017-04-22' '2017-04-27' '2017-04-29' '2017-05-01'\n",
      " '2017-05-02' '2017-05-06' '2017-05-09' '2017-05-10' '2017-05-11'\n",
      " '2017-05-24' '2017-04-25' '2017-04-26' '2017-05-03' '2017-05-05'\n",
      " '2017-05-08' '2017-04-02' '4/26/2017' '2017-05-04' '2017-05-07'\n",
      " '2017-03-09' '2017-03-16' '2017-03-01' '2017-03-13' '2017-03-08'\n",
      " '4/18/2017' '4/23/2017' '4/20/2017' '4/24/2017' '4/21/2017' '4/22/2017'\n",
      " '4/25/2017' '4/3/2017' '4/17/2017' '4/28/2017' '4/27/2017' '4/7/2017'\n",
      " '3/31/2017' '3/1/2017' '3/30/2017' '3/3/2017' '3/16/2017' '3/8/2017'\n",
      " '3/13/2017' '4/19/2017' '2017-05-18' '2027-05-24']\n",
      "['2017-03-28' '2017-03-29' '2017-03-31' '2017-04-01' '2017-04-03'\n",
      " '2017-04-08' '2017-03-30' '2017-04-06' '2017-04-09' '2017-04-17'\n",
      " '2017-04-21' '2017-04-23' '2017-04-24' '2017-04-28' '2017-04-30'\n",
      " '2017-04-07' '2017-04-04' '2017-04-05' '2017-04-18' '2017-04-19'\n",
      " '2017-04-20' '2017-04-22' '2017-04-27' '2017-04-29' '2017-05-01'\n",
      " '2017-05-02' '2017-05-06' '2017-05-09' '2017-05-10' '2017-05-11'\n",
      " '2017-05-24' '2017-04-25' '2017-04-26' '2017-05-03' '2017-05-05'\n",
      " '2017-05-08' '2017-04-02' '4/26/2017' '2017-05-04' '2017-05-07'\n",
      " '2017-03-09' '2017-03-16' '2017-03-01' '2017-03-13' '2017-03-08'\n",
      " '4/18/2017' '4/23/2017' '4/20/2017' '4/24/2017' '4/21/2017' '4/22/2017'\n",
      " '4/25/2017' '4/3/2017' '4/17/2017' '4/28/2017' '4/27/2017' '4/7/2017'\n",
      " '3/31/2017' '3/1/2017' '3/30/2017' '3/3/2017' '3/16/2017' '3/8/2017'\n",
      " '3/13/2017' '4/19/2017' '2017-05-18']\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# remove space in columns names\n",
    "cols = [x.strip().replace(' ','_') for x in list(df)]\n",
    "df.columns = cols\n",
    "\n",
    "# use sys_RespNum as ID\n",
    "df['ID'] = df['sys_RespNum']\n",
    "\n",
    "# the data doesn't have time_string\n",
    "df['time_string'] = np.nan\n",
    "\n",
    "# convert the data type of the 'DATE' variable from datetime to string and then remove the hour/min/sec part\n",
    "df['DATE'] = df['DATE'].apply(lambda x: str(x)[:10])\n",
    "print(df.DATE.unique())\n",
    "\n",
    "# there is a '2027-05-24' which should be '2017-05-24'\n",
    "df.loc[df.DATE == '2027-05-24','DATE'] = '2017-05-24'\n",
    "print(df.DATE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on the answer to the \"Morebus\" question (if has transfer), \n",
    "# access_mode could be 'Gettolotsbus_c1' or 'Getto1bus_c1'\n",
    "# egress_mode could be 'Gettolotsbus_c2' or 'Getto1bus_c2'\n",
    "# therefore, create new columns to consolidate these fields\n",
    "\n",
    "for i in ['Gettolotsbus_c1', 'Getto1bus_c1', 'Gettolotsbus_c2', 'Getto1bus_c2']:\n",
    "    df[i].replace(to_replace = ' ', value = np.nan, inplace=True)\n",
    "    \n",
    "df['access_mode'] = df['Gettolotsbus_c1']\n",
    "df.loc[df.access_mode.isnull(), 'access_mode'] = df['Getto1bus_c1']\n",
    "\n",
    "df['egress_mode'] = df['Gettolotsbus_c2']\n",
    "df.loc[df.egress_mode.isnull(), 'egress_mode'] = df['Getto1bus_c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new field to aggregate survey route number and direction\n",
    "df['survey_route'] = df['ROUTE'].astype(str) + df['DIR'].apply(lambda x: x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code transfer system and create columns for 'system + route' which will be used for canonical_route mapping\n",
    "\n",
    "system_dict = {1: 'Marin Transit',\n",
    "               2: 'Golden Gate Transit',\n",
    "               3: 'Sonoma County Transit',        \n",
    "               4: 'Santa Rosa CityBus',          \n",
    "               5: 'Golden Gate Ferry',   \n",
    "               6: 'Napa Vine',\n",
    "               7: 'SolTrans (Solano County Transit)',\n",
    "               8: 'FAST (Fairfield-Suisun Transit)',       \n",
    "               9: 'Vacaville City Coach', \n",
    "               10: 'BART',\n",
    "               11: 'Muni',\n",
    "               12: 'AC Transit',\n",
    "               13: 'SamTrans',\n",
    "               14: 'Caltrain',\n",
    "               15: 'VTA',\n",
    "               16: 'Tri Delta Transit',\n",
    "               17: 'WestCat',\n",
    "               18: 'County Connection',\n",
    "               19: 'WHEELS', \n",
    "               20: 'Other (not specified)'}\n",
    "\n",
    "for i in ['sys1', 'sys2', 'sys3', 'sys4']:\n",
    "    #print(i)\n",
    "    #print(df[i])\n",
    "#     df[i].replace(to_replace = ' ', value = 0, inplace=True)\n",
    "    df[i] = df[i].fillna(0)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(system_dict)\n",
    "\n",
    "# for i in ['businfo1', 'businfo2', 'businfo3', 'businfo4']:\n",
    "#     df[i].replace(to_replace = ' ', value = np.nan, inplace=True)  \n",
    "\n",
    "df['route1'] = df['sys1_temp'] + '___' + df['businfo1'].astype(str)\n",
    "df['route2'] = df['sys2_temp'] + '___' + df['businfo2'].astype(str)\n",
    "df['route3'] = df['sys3_temp'] + '___' + df['businfo3'].astype(str)\n",
    "df['route4'] = df['sys4_temp'] + '___' + df['businfo4'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route1/2/3/4 include the current survey route, so need to identify before transfers and after transfers\n",
    "\n",
    "df['first_route_before_survey_board'] = ''\n",
    "df['second_route_before_survey_board'] = ''\n",
    "df['third_route_before_survey_board'] = ''\n",
    "df['first_route_after_survey_alight'] = ''\n",
    "df['second_route_after_survey_alight'] = ''\n",
    "df['third_route_after_survey_alight'] = ''\n",
    "\n",
    "# add 'Marin Transit' to survey route name in order to compare\n",
    "df['survey_route_temp'] = 'Marin Transit___' + df['survey_route']\n",
    "\n",
    "# if the first route is the survey route, then the later routes are after transfers\n",
    "df['first_route_idx'] = df.survey_route_temp == df.route1\n",
    "df.loc[df.first_route_idx == True, 'first_route_after_survey_alight'] = df['route2']\n",
    "df.loc[df.first_route_idx == True, 'second_route_after_survey_alight'] = df['route3']\n",
    "df.loc[df.first_route_idx == True, 'third_route_after_survey_alight'] = df['route4']\n",
    "\n",
    "# if the second route is the survey route, then route1 is before transfer and route3/route4 are after transfers\n",
    "df['second_route_idx'] = df.survey_route_temp == df.route2\n",
    "df.loc[df.second_route_idx == True, 'first_route_before_survey_board'] = df['route1']\n",
    "df.loc[df.second_route_idx == True, 'first_route_after_survey_alight'] = df['route3']\n",
    "df.loc[df.second_route_idx == True, 'second_route_after_survey_alight'] = df['route4']\n",
    "\n",
    "# if the third route is the survey route, then route1/route2 are before transfers and route4 is after transfer\n",
    "df['third_route_idx'] = df.survey_route_temp == df.route3\n",
    "df.loc[df.third_route_idx == True, 'first_route_before_survey_board'] = df['route1']\n",
    "df.loc[df.third_route_idx == True, 'second_route_before_survey_board'] = df['route2']\n",
    "df.loc[df.third_route_idx == True, 'first_route_after_survey_alight'] = df['route4']\n",
    "\n",
    "# if the fourth route is the survey route, then route1/route2/route3 are before transfers\n",
    "df['fourth_route_idx'] = df.survey_route_temp == df.route4\n",
    "df.loc[df.fourth_route_idx == True, 'first_route_before_survey_board'] = df['route1']\n",
    "df.loc[df.fourth_route_idx == True, 'second_route_before_survey_board'] = df['route2']\n",
    "df.loc[df.fourth_route_idx == True, 'third_route_before_survey_board'] = df['route3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive first_board_lat/lon and last_alight_lat/lon\n",
    "\n",
    "# first_board_lat/lon = ONBUS-LAT1/LONG1\n",
    "df['first_board_lat'] = df['ONBUS-LAT1']\n",
    "df['first_board_lon'] = df['ONBUS-LONG1']\n",
    "\n",
    "# last_alight_lat/lon = the last available OFFBUS-LAT/LONG\n",
    "df['last_alight_lat'] = df['OFFBUS-LAT4']\n",
    "df.loc[df.last_alight_lat.isnull(), 'last_alight_lat'] = df['OFFBUS-LAT3']\n",
    "df.loc[df.last_alight_lat.isnull(), 'last_alight_lat'] = df['OFFBUS-LAT2']\n",
    "df.loc[df.last_alight_lat.isnull(), 'last_alight_lat'] = df['OFFBUS-LAT1']\n",
    "\n",
    "df['last_alight_lon'] = df['OFFBUS-LONG4']\n",
    "df.loc[df.last_alight_lon.isnull(), 'last_alight_lon'] = df['OFFBUS-LONG3']\n",
    "df.loc[df.last_alight_lon.isnull(), 'last_alight_lon'] = df['OFFBUS-LONG2']\n",
    "df.loc[df.last_alight_lon.isnull(), 'last_alight_lon'] = df['OFFBUS-LONG1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White/Caucasian_NA_NA_NA_NA', 'Hispanic_NA_NA_NA_NA', 'Refused_NA_NA_NA_NA', 'White/Caucasian_Hispanic_NA_NA_NA', 'Black/African American_NA_NA_NA_NA', 'Asian_NA_NA_NA_NA', 'American Indian/Alaska Native_Native Hawaiian/Pacific Islander_Black/African American_White/Caucasian_Asian', 'American Indian/Alaska Native_NA_NA_NA_NA', 'Native Hawaiian/Pacific Islander_White/Caucasian_NA_NA_NA', 'American Indian/Alaska Native_White/Caucasian_NA_NA_NA', 'Persian/Arab/North African/Middle Eastern_NA_NA_NA_NA', 'White/Caucasian_Asian_NA_NA_NA', 'Black/African American_White/Caucasian_NA_NA_NA', 'Native Hawaiian/Pacific Islander_NA_NA_NA_NA', 'Native Hawaiian/Pacific Islander_Black/African American_NA_NA_NA', 'Native Hawaiian/Pacific Islander_Asian_NA_NA_NA', 'Mixed_NA_NA_NA_NA', 'Black/African American_White/Caucasian_Asian_NA_NA', 'Black/African American_Asian_NA_NA_NA', 'Black/African American_Hispanic_NA_NA_NA', 'Asian_Hispanic_NA_NA_NA', 'Hispanic_Mixed_NA_NA_NA', 'American Indian/Alaska Native_Hispanic_NA_NA_NA', 'American Indian/Alaska Native_Black/African American_Hispanic_NA_NA', 'American Indian/Alaska Native_Native Hawaiian/Pacific Islander_NA_NA_NA', 'American Indian/Alaska Native_Black/African American_White/Caucasian_NA_NA', 'White/Caucasian_Asian_Hispanic_NA_NA', 'American Indian/Alaska Native_White/Caucasian_Asian_NA_NA', 'American Indian/Alaska Native_Black/African American_NA_NA_NA']\n"
     ]
    }
   ],
   "source": [
    "# create race dmy variables based on Race1 through Race5\n",
    "\n",
    "race_dict = {1: 'American Indian/Alaska Native',\n",
    "             2: 'Native Hawaiian/Pacific Islander',\n",
    "             3: 'Black/African American',\n",
    "             4: 'White/Caucasian',\n",
    "             5: 'Asian',\n",
    "             6: 'Hispanic',\n",
    "             7: 'Mixed',\n",
    "             8: 'Persian/Arab/North African/Middle Eastern',\n",
    "             0: 'Refused',\n",
    "             10: 'NA'}\n",
    "\n",
    "for i in ['race_1', 'race_2', 'race_3', 'race_4', 'race_5']:\n",
    "    df[i] = df[i].fillna(10)\n",
    "    df[i].replace(to_replace = ' ', value = 10, inplace=True)\n",
    "    df[i] = df[i].apply(lambda x: int(x))\n",
    "    df[i+'_temp'] = df[i].map(race_dict)\n",
    "    \n",
    "df['race_concat'] = df['race_1_temp'] + '_' + df['race_2_temp'] + '_' + df['race_3_temp'] + '_' + df['race_4_temp'] + '_' + df['race_5_temp']\n",
    "print(list(df['race_concat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hisp</th>\n",
       "      <th>hisp_from_race</th>\n",
       "      <th>race_1</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>303525.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>303526.0</td>\n",
       "      <td>0</td>\n",
       "      <td>hisp</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>303572.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hisp</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>313923.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hisp</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>313940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hisp</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>335500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>hisp</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  hisp hisp_from_race  race_1  race_2  race_3  race_4  race_5\n",
       "413  303525.0     1           hisp       4       6      10      10      10\n",
       "414  303526.0     0           hisp       6      10      10      10      10\n",
       "459  303572.0     1           hisp       3       6      10      10      10\n",
       "556  313923.0     1           hisp       1       6      10      10      10\n",
       "572  313940.0     1           hisp       3       6      10      10      10\n",
       "717  335500.0     0           hisp       6      10      10      10      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hisp</th>\n",
       "      <th>hisp_from_race</th>\n",
       "      <th>race_1</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>336161.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>336163.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>336166.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>336170.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>336171.0</td>\n",
       "      <td>2</td>\n",
       "      <td>non-hisp</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  hisp hisp_from_race  race_1  race_2  race_3  race_4  race_5\n",
       "0          3.0     2       non-hisp       4      10      10      10      10\n",
       "3          9.0     2       non-hisp       0      10      10      10      10\n",
       "7         25.0     2       non-hisp       4      10      10      10      10\n",
       "9         29.0     2       non-hisp       4      10      10      10      10\n",
       "10        30.0     2       non-hisp       0      10      10      10      10\n",
       "...        ...   ...            ...     ...     ...     ...     ...     ...\n",
       "1205  336161.0     2       non-hisp       0      10      10      10      10\n",
       "1207  336163.0     2       non-hisp       0      10      10      10      10\n",
       "1210  336166.0     2       non-hisp       4      10      10      10      10\n",
       "1214  336170.0     2       non-hisp       0      10      10      10      10\n",
       "1215  336171.0     2       non-hisp       0      10      10      10      10\n",
       "\n",
       "[334 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# estimate if hispanic based on race1 through race5\n",
    "df['hisp_from_race'] = 'non-hisp'\n",
    "df.loc[df.race_concat.str.contains('Hispanic',na=False), 'hisp_from_race'] = 'hisp'\n",
    "\n",
    "# check consistency between 'hisp' derived from race1 through race5 and the original 'hisp' variable and make corrections\n",
    "\n",
    "# records where race1 through race5 indicates 'hispanic' but 'hisp' is 1 (not hispanic)\n",
    "display(df.loc[(df.hisp_from_race == 'hisp') & (df.hisp != 2)][['ID','hisp','hisp_from_race',\n",
    "                                                                'race_1', 'race_2', 'race_3', 'race_4', 'race_5']])\n",
    "# make hisp=2 for records where hisp_from_ETH == 'hisp'\n",
    "df.loc[df.hisp_from_race == 'hisp', 'hisp'] = 2\n",
    "\n",
    "# records where race1-race5 doesn't indicate 'hispanic' but 'hisp' is 2 (is hispanic)\n",
    "# for these, keep the '2' value because the surveyed may leave 'race-hispanic' out when they feel\n",
    "# they have already provided the information in 'hisp'\n",
    "display(df.loc[(df.hisp_from_race != 'hisp') & (df.hisp == 2)][['ID','hisp','hisp_from_race',\n",
    "                                                                'race_1', 'race_2', 'race_3', 'race_4', 'race_5']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create race_dmy_xx\n",
    "\n",
    "df['race_dmy_ind'] = 0\n",
    "df.loc[df.race_concat.str.contains('American Indian/Alaska Native',na=False), 'race_dmy_ind'] = 1\n",
    "\n",
    "df['race_dmy_hwi'] = 0\n",
    "df.loc[df.race_concat.str.contains('Native Hawaiian/Pacific Islander',na=False), 'race_dmy_hwi'] = 1\n",
    "\n",
    "df['race_dmy_blk'] = 0\n",
    "df.loc[df.race_concat.str.contains('Black/African American',na=False), 'race_dmy_blk'] = 1\n",
    "\n",
    "df['race_dmy_wht'] = 0\n",
    "df.loc[df.race_concat.str.contains('White/Caucasian',na=False), 'race_dmy_wht'] = 1\n",
    "\n",
    "df['race_dmy_asn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Asian',na=False), 'race_dmy_asn'] = 1\n",
    "\n",
    "df['race_dmy_mdl_estn'] = 0\n",
    "df.loc[df.race_concat.str.contains('Persian/Arab/North African/Middle Eastern',na=False), 'race_dmy_mdl_estn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     711\n",
       "2     455\n",
       "4      10\n",
       "0       6\n",
       "5       6\n",
       "10      5\n",
       "6       4\n",
       "3       3\n",
       "8       3\n",
       "9       2\n",
       "14      2\n",
       "18      1\n",
       "11      1\n",
       "7       1\n",
       "12      1\n",
       "13      1\n",
       "15      1\n",
       "16      1\n",
       "17      1\n",
       "19      1\n",
       "Name: langhh, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ENGLISH ONLY    711\n",
       "OTHER           505\n",
       "Name: language_at_home_binary, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create 'language_at_home_binary' variable based on \"langhh\"（What language do you primarily speak in your household?）\n",
    "df['language_at_home_binary'] = 'OTHER'\n",
    "df.loc[df.langhh == 1, 'language_at_home_binary'] = 'ENGLISH ONLY'\n",
    "display(df.langhh.value_counts())\n",
    "display(df.language_at_home_binary.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sys_RespNum', 'sys_StartTime', 'sys_EndTime', 'sys_LastQuestion', 'CCGID', 'RUNID', 'ROUTE', 'DIR', 'DAY', 'DATE', 'STRATA', 'wcode', 'WEIGHT', 'TWEIGHT', 'LANG_1', 'FromTo_c1', 'FromTo_c2', 'k12hs1', 'uni1', 'STARTLAT', 'STARTLONG', 'k12hs2', 'uni2', 'ENDLAT', 'ENDLONG', 'morebus', 'Gettolotsbus_c1', 'Gettolotsbus_c2', 'Getto1bus_c1', 'Getto1bus_c2', 'Route1', 'ONBUS-LAT1', 'ONBUS-LONG1', 'OFFBUS-LAT1', 'OFFBUS-LONG1', 'Route2', 'ONBUS-LAT2', 'ONBUS-LONG2', 'OFFBUS-LAT2', 'OFFBUS-LONG2', 'Route3', 'ONBUS-LAT3', 'ONBUS-LONG3', 'OFFBUS-LAT3', 'OFFBUS-LONG3', 'Route4', 'ONBUS-LAT4', 'ONBUS-LONG4', 'OFFBUS-LAT4', 'OFFBUS-LONG4', 'totalbus', 'businfo1', 'businfo2', 'businfo3', 'businfo4', 'sys1', 'sys2', 'sys3', 'sys4', 'fare', 'farecat', 'RideFreq', 'Sat', 'IntAccess_1', 'IntAccess_2', 'IntAccess_3', 'IntAccess_4', 'cars', 'hh', 'hhwork', 'age', 'birthyear', 'hisp', 'race_1', 'race_2', 'race_3', 'race_4', 'race_5', 'income', 'langhh', 'engspk', 'livebay', 'HOMELAT', 'HOMELONG', 'sch', 'k12hs3', 'uni3', 'School_Name', 'School_Lat', 'School_Long', 'work', 'WORKLAT', 'WORKLONG', 'workafter', 'workbefore', 'schafter', 'schbefore', 'hometime_c1', 'hometime_c2', 'gender', 'COMMENTS', 'Mode', 'break', 'on17n', 'off17n', 'on17s', 'off17s', 'on22n', 'off22n', 'on22s', 'off22s', 'on23e', 'off23e', 'on23w', 'off23w', 'on23xe', 'off23xe', 'on23xw', 'off23xw', 'on29e', 'off29', 'on29w', 'off29w', 'on35n', 'off35n', 'on35s', 'off35s', 'on36n', 'off36n', 'on36s', 'off36s', 'on49n', 'off49n', 'on49s', 'off49s', 'on61e', 'off61', 'on61w', 'off61w', 'on68e', 'off68e', 'on68w', 'off68w', 'on71n', 'off71n', 'on71s', 'off71s', 'on219e', 'off219', 'on219w', 'off219w', 'on228e', 'off228e', 'on228w', 'off228w', 'on233n', 'off233n', 'on233s', 'off233s', 'on245n', 'off245n', 'on245s', 'off245s', 'on251n', 'off251n', 'on251s', 'off251s', 'on257n', 'off257n', 'on257s', 'off257s', 'ID', 'time_string', 'access_mode', 'egress_mode', 'survey_route', 'first_route_before_survey_board', 'second_route_before_survey_board', 'third_route_before_survey_board', 'first_route_after_survey_alight', 'second_route_after_survey_alight', 'third_route_after_survey_alight', 'first_board_lat', 'first_board_lon', 'last_alight_lat', 'last_alight_lon', 'race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_mdl_estn', 'language_at_home_binary']\n"
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns and export\n",
    "\n",
    "df.drop(columns = ['survey_route_temp',\n",
    "                   'sys1_temp', 'sys2_temp', 'sys3_temp', 'sys4_temp', \n",
    "                   'route1', 'route2', 'route3', 'route4',\n",
    "                   'first_route_idx', 'second_route_idx', 'third_route_idx', 'fourth_route_idx',\n",
    "                   'race_1_temp', 'race_2_temp','race_3_temp','race_4_temp','race_5_temp',\n",
    "                   'race_concat', 'hisp_from_race'], inplace=True)\n",
    "\n",
    "print(list(df))\n",
    "\n",
    "df.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Marin Transit\\Final Data\\marin transit_data file_final01222021_NO POUND OR SINGLE QUOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# gather all transfer routes\n",
    "routes = pd.DataFrame(columns = ['survey_name'])\n",
    "for i in ['first_route_before_survey_board', 'second_route_before_survey_board',\n",
    "          'third_route_before_survey_board', 'first_route_after_survey_alight', \n",
    "          'second_route_after_survey_alight', 'third_route_after_survey_alight']:\n",
    "    route_unique = df[[i]]\n",
    "    route_unique.columns = ['survey_name']\n",
    "    routes = pd.concat([routes, route_unique])\n",
    "\n",
    "routes_clean = routes.loc[(routes.survey_name.notnull()) & (routes.survey_name != '')]\n",
    "routes_clean.drop_duplicates(inplace=True)\n",
    "routes_clean['survey'] = 'Marin Transit'\n",
    "routes_clean['survey_year'] = 2017\n",
    "\n",
    "print(routes_clean.shape)\n",
    "routes_clean[['survey','survey_year','survey_name']].to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Marin Transit\\Final Data\\all_routes_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic_Variable that shouldn not exit:\n",
      "[]\n",
      "\n",
      "variables not in standard dictionary\n",
      "variables in df but not in the current Marin Transit dictionary\n",
      "sys_RespNum\n",
      "sys_StartTime\n",
      "sys_EndTime\n",
      "sys_LastQuestion\n",
      "CCGID\n",
      "RUNID\n",
      "ROUTE\n",
      "wcode\n",
      "k12hs1\n",
      "uni1\n",
      "k12hs2\n",
      "uni2\n",
      "morebus\n",
      "Gettolotsbus_c1\n",
      "Gettolotsbus_c2\n",
      "Getto1bus_c1\n",
      "Getto1bus_c2\n",
      "Route1\n",
      "ONBUS-LAT1\n",
      "ONBUS-LONG1\n",
      "OFFBUS-LAT1\n",
      "OFFBUS-LONG1\n",
      "Route2\n",
      "ONBUS-LAT2\n",
      "ONBUS-LONG2\n",
      "OFFBUS-LAT2\n",
      "OFFBUS-LONG2\n",
      "Route3\n",
      "ONBUS-LAT3\n",
      "ONBUS-LONG3\n",
      "OFFBUS-LAT3\n",
      "OFFBUS-LONG3\n",
      "Route4\n",
      "ONBUS-LAT4\n",
      "ONBUS-LONG4\n",
      "OFFBUS-LAT4\n",
      "OFFBUS-LONG4\n",
      "totalbus\n",
      "businfo1\n",
      "businfo2\n",
      "businfo3\n",
      "businfo4\n",
      "sys1\n",
      "sys2\n",
      "sys3\n",
      "sys4\n",
      "RideFreq\n",
      "Sat\n",
      "IntAccess_1\n",
      "IntAccess_2\n",
      "IntAccess_3\n",
      "IntAccess_4\n",
      "age\n",
      "race_1\n",
      "race_2\n",
      "race_3\n",
      "race_4\n",
      "race_5\n",
      "livebay\n",
      "k12hs3\n",
      "uni3\n",
      "School_Name\n",
      "COMMENTS\n",
      "break\n",
      "on17n\n",
      "off17n\n",
      "on17s\n",
      "off17s\n",
      "on22n\n",
      "off22n\n",
      "on22s\n",
      "off22s\n",
      "on23e\n",
      "off23e\n",
      "on23w\n",
      "off23w\n",
      "on23xe\n",
      "off23xe\n",
      "on23xw\n",
      "off23xw\n",
      "on29e\n",
      "off29\n",
      "on29w\n",
      "off29w\n",
      "on35n\n",
      "off35n\n",
      "on35s\n",
      "off35s\n",
      "on36n\n",
      "off36n\n",
      "on36s\n",
      "off36s\n",
      "on49n\n",
      "off49n\n",
      "on49s\n",
      "off49s\n",
      "on61e\n",
      "off61\n",
      "on61w\n",
      "off61w\n",
      "on68e\n",
      "off68e\n",
      "on68w\n",
      "off68w\n",
      "on71n\n",
      "off71n\n",
      "on71s\n",
      "off71s\n",
      "on219e\n",
      "off219\n",
      "on219w\n",
      "off219w\n",
      "on228e\n",
      "off228e\n",
      "on228w\n",
      "off228w\n",
      "on233n\n",
      "off233n\n",
      "on233s\n",
      "off233s\n",
      "on245n\n",
      "off245n\n",
      "on245s\n",
      "off245s\n",
      "on251n\n",
      "off251n\n",
      "on251s\n",
      "off251s\n",
      "on257n\n",
      "off257n\n",
      "on257s\n",
      "off257s\n"
     ]
    }
   ],
   "source": [
    "# bring in standard dictionary to check field consistency\n",
    "\n",
    "# dictionary for Marin Transit survey\n",
    "var = pd.read_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Marin Transit\\Final Data\\var_dict_raw.csv',\n",
    "                  encoding = \"ISO-8859-1\", engine='python')\n",
    "\n",
    "# standard dictionary\n",
    "var_standard = pd.read_csv(r'C:\\Users\\ywang\\Documents\\GitHub\\onboard-surveys\\make-uniform\\production\\Dictionary for Standard Database.csv')\n",
    "var_standard.columns = [x+'_s' for x in list(var_standard)]\n",
    "\n",
    "# merge\n",
    "var_merge = var.merge(var_standard, left_on='Generic_Variable', right_on='Generic_Variable_s', how='outer')\n",
    "\n",
    "# check if 'Generic_Variable' in Marin Transit dictionary matches the standard 'Generic_Variable'. chk1 should be empty\n",
    "chk1 = var_merge.loc[(var_merge.Generic_Variable.notnull()) & (var_merge.Generic_Variable_s.isnull())]\n",
    "print('Generic_Variable that shouldn not exit:')\n",
    "print(chk1.Generic_Variable.unique())\n",
    "print()\n",
    "\n",
    "# check if columns names in survey data matches 'Survey_Variable' in Marin Transit dictionary.\n",
    "# the following loops should not include variables that are needed for standardization\n",
    "\n",
    "print('variables not in standard dictionary')\n",
    "for i in var.loc[var.Generic_Variable.notnull()]['Survey_Variable']:\n",
    "    if i not in list(df):\n",
    "        print(i)\n",
    "\n",
    "print('variables in df but not in the current Marin Transit dictionary')\n",
    "for i in list(df):\n",
    "    if i not in list(var.Survey_Variable):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR\n",
      "DAY\n",
      "LANG_1\n",
      "FromTo_c1\n",
      "FromTo_c2\n",
      "access_mode\n",
      "egress_mode\n",
      "fare\n",
      "farecat\n",
      "cars\n",
      "hh\n",
      "hhwork\n",
      "hisp\n",
      "race_dmy_ind\n",
      "race_dmy_hwi\n",
      "race_dmy_blk\n",
      "race_dmy_wht\n",
      "race_dmy_asn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\ywang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "race_dmy_mdl_estn\n",
      "income\n",
      "langhh\n",
      "language_at_home_binary\n",
      "engspk\n",
      "[nan]\n",
      "sch\n",
      "[nan]\n",
      "work\n",
      "[nan]\n",
      "workafter\n",
      "[nan]\n",
      "workbefore\n",
      "[nan]\n",
      "schafter\n",
      "[nan]\n",
      "schbefore\n",
      "[nan]\n",
      "hometime_c1\n",
      "[nan]\n",
      "gender\n",
      "Mode\n"
     ]
    }
   ],
   "source": [
    "# check if all the values in the survey data are included in Napa Vine dictionary\n",
    "# look at non-categorical variables; \"diff\" should be empty or only contains nan\n",
    "\n",
    "var_clean = var[['operator', 'Survey_year', 'Survey_Variable', 'Survey_Response', \n",
    "                 'Generic_Variable', 'Generic_Response']].drop_duplicates()\n",
    "var_clean = var_clean.loc[var_clean.Generic_Variable.notnull()]\n",
    "\n",
    "for i in var_clean.loc[var_clean.Survey_Response != 'NONCATEGORICAL']['Survey_Variable'].unique():\n",
    "    print(i)\n",
    "    df_sub = df[['ID', i]]\n",
    "    var_sub = var_clean.loc[var_clean.Survey_Variable == i]\n",
    "\n",
    "    if i in ['LANG_1', 'FromTo_c1', 'FromTo_c2', 'access_mode', 'egress_mode', 'fare', 'farecat', \n",
    "             'engspk', 'langhh', 'sch', 'work', 'workafter', 'workbefore', 'schafter', 'schbefore',\n",
    "             'hometime_c1', 'gender', 'Mode',\n",
    "             'race_dmy_ind', 'race_dmy_hwi', 'race_dmy_blk', 'race_dmy_wht', 'race_dmy_asn', 'race_dmy_mdl_estn']:\n",
    "        var_sub.Survey_Response = var_sub.Survey_Response.apply(lambda x: int(x))\n",
    "\n",
    "    if i in ['hh', 'cars', 'hhwork', 'hisp', 'income']:\n",
    "        df_sub[i] = df_sub[i].apply(lambda x: str(x))    \n",
    "    \n",
    "    compare = df_sub.merge(var_sub, left_on=i, right_on='Survey_Response', how='left')\n",
    "    diff = compare.loc[compare.Generic_Response.isnull()]\n",
    "    if diff.shape[0] > 0:\n",
    "        print(diff[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID' 'time_string' 'direction' 'route' 'weekpart' 'date_string'\n",
      " 'time_period' 'weight' 'tweight' 'interview_language' 'orig_purp'\n",
      " 'dest_purp' 'orig_lat' 'orig_lon' 'dest_lat' 'dest_lon' 'access_mode'\n",
      " 'egress_mode' 'first_route_before_survey_board'\n",
      " 'second_route_before_survey_board' 'third_route_before_survey_board'\n",
      " 'first_route_after_survey_alight' 'second_route_after_survey_alight'\n",
      " 'third_route_after_survey_alight' 'first_board_lat' 'first_board_lon'\n",
      " 'last_alight_lat' 'last_alight_lon' 'fare_medium' 'fare_category'\n",
      " 'vehicles' 'persons' 'workers' 'year_born_four_digit' 'hispanic'\n",
      " 'race_dmy_ind' 'race_dmy_hwi' 'race_dmy_blk' 'race_dmy_wht'\n",
      " 'race_dmy_asn' 'race_dmy_mdl_estn' 'household_income'\n",
      " 'language_at_home_detail' 'language_at_home_binary' 'eng_proficient'\n",
      " 'home_lat' 'home_lon' 'student_status' 'school_lat' 'school_lon'\n",
      " 'work_status' 'workplace_lat' 'workplace_lon' 'at_work_after_dest_purp'\n",
      " 'at_work_prior_to_orig_purp' 'at_school_after_dest_purp'\n",
      " 'at_school_prior_to_orig_purp' 'depart_hour' 'gender' 'survey_type']\n"
     ]
    }
   ],
   "source": [
    "# finally, check all necessary fields are included, and export\n",
    "print(var_clean.Generic_Variable.unique())\n",
    "var_clean.to_csv(r'M:\\Data\\OnBoard\\Data and Reports\\Marin Transit\\Final Data\\vars_for_standard_dictionary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
