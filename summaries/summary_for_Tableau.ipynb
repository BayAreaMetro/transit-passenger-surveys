{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read 'survey_standard.csv' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0,7,9,22,23,26,27,28,29,30,32,40,41,42,52,55,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fname = 'survey_standard_2021-03-22.csv'\n",
    "\n",
    "df_raw = pd.read_csv(os.path.join('M:\\\\Data\\\\OnBoard\\\\Data and Reports\\\\_data Standardized', fname), encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create summary table of non-spatial variables for Tableau visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 146457 rows from the data including the following surveys: \n",
      "['AC Transit - 2018', 'ACE - 2019', 'BART - 2015', 'Caltrain - 2014', 'Capitol Corridor - 2019', 'City Coach - 2017', 'County Connection - 2019', 'Delta Breeze - 2017', 'FAST - 2017', 'Golden Gate Transit - 2018', 'LAVTA - 2018', 'Marin Transit - 2017', 'Napa Vine - 2014', 'Napa Vine - 2019', 'Petaluma Transit - 2018', 'Santa Rosa CityBus - 2018', 'SF Muni - 2017', 'Soltrans - 2017', 'Sonoma-Marin Area Rail Transit - 2018', 'Sonoma County Transit - 2018', 'TriDelta - 2019', 'Union City Transit - 2017', 'VTA - 2017', 'WestCAT - 2017', 'WETA - 2019']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>operator</th>\n",
       "      <th>survey_year</th>\n",
       "      <th>survey_tech</th>\n",
       "      <th>access_mode</th>\n",
       "      <th>alt_weight</th>\n",
       "      <th>depart_hour</th>\n",
       "      <th>depart_time</th>\n",
       "      <th>dest_purp</th>\n",
       "      <th>direction</th>\n",
       "      <th>...</th>\n",
       "      <th>home_maz</th>\n",
       "      <th>orig_maz</th>\n",
       "      <th>school_maz</th>\n",
       "      <th>workplace_maz</th>\n",
       "      <th>board_tap</th>\n",
       "      <th>alight_tap</th>\n",
       "      <th>trip_weight</th>\n",
       "      <th>field_language</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>operator_survey_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AC Transit</td>\n",
       "      <td>2018</td>\n",
       "      <td>local bus</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11514.0</td>\n",
       "      <td>11514.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>425106.0</td>\n",
       "      <td>90131.0</td>\n",
       "      <td>490370.0</td>\n",
       "      <td>1.855557</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>AC Transit - 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>AC Transit</td>\n",
       "      <td>2018</td>\n",
       "      <td>local bus</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>316876.0</td>\n",
       "      <td>316876.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324992.0</td>\n",
       "      <td>390602.0</td>\n",
       "      <td>390316.0</td>\n",
       "      <td>4.847912</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>AC Transit - 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>AC Transit</td>\n",
       "      <td>2018</td>\n",
       "      <td>local bus</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>318470.0</td>\n",
       "      <td>318567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318567.0</td>\n",
       "      <td>390526.0</td>\n",
       "      <td>390132.0</td>\n",
       "      <td>9.772444</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>AC Transit - 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>AC Transit</td>\n",
       "      <td>2018</td>\n",
       "      <td>local bus</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>327175.0</td>\n",
       "      <td>327175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325899.0</td>\n",
       "      <td>390316.0</td>\n",
       "      <td>390746.0</td>\n",
       "      <td>10.572424</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>AC Transit - 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>AC Transit</td>\n",
       "      <td>2018</td>\n",
       "      <td>local bus</td>\n",
       "      <td>walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work-related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>324492.0</td>\n",
       "      <td>323825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311933.0</td>\n",
       "      <td>390086.0</td>\n",
       "      <td>390449.0</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>AC Transit - 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID    operator  survey_year survey_tech access_mode  alt_weight  \\\n",
       "0      1  AC Transit         2018   local bus        walk         NaN   \n",
       "1     10  AC Transit         2018   local bus        walk         NaN   \n",
       "2    100  AC Transit         2018   local bus        walk         NaN   \n",
       "3   1000  AC Transit         2018   local bus        walk         NaN   \n",
       "4  10000  AC Transit         2018   local bus        walk         NaN   \n",
       "\n",
       "   depart_hour depart_time     dest_purp direction  ...  home_maz  orig_maz  \\\n",
       "0          NaN         NaN          work       NaN  ...   11514.0   11514.0   \n",
       "1          NaN         NaN          work       NaN  ...  316876.0  316876.0   \n",
       "2          NaN         NaN          home       NaN  ...  318470.0  318567.0   \n",
       "3          NaN         NaN          work       NaN  ...  327175.0  327175.0   \n",
       "4          7.0         NaN  work-related       NaN  ...  324492.0  323825.0   \n",
       "\n",
       "  school_maz workplace_maz  board_tap  alight_tap trip_weight field_language  \\\n",
       "0        NaN      425106.0    90131.0    490370.0    1.855557        ENGLISH   \n",
       "1        NaN      324992.0   390602.0    390316.0    4.847912        ENGLISH   \n",
       "2        NaN      318567.0   390526.0    390132.0    9.772444        ENGLISH   \n",
       "3        NaN      325899.0   390316.0    390746.0   10.572424        ENGLISH   \n",
       "4        NaN      311933.0   390086.0    390449.0    1.270000        ENGLISH   \n",
       "\n",
       "  survey_time operator_survey_year  \n",
       "0    17:30:00    AC Transit - 2018  \n",
       "1    07:30:00    AC Transit - 2018  \n",
       "2    17:30:00    AC Transit - 2018  \n",
       "3    08:30:00    AC Transit - 2018  \n",
       "4    11:30:00    AC Transit - 2018  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create field \"operator_survey_year\" which will be used as a Tableau filter\n",
    "\n",
    "df = df_raw.copy()\n",
    "df['operator_survey_year'] = df['operator'] + ' - ' + df['survey_year'].apply(lambda x: str(x))\n",
    "\n",
    "print('Read {} rows from the data including the following surveys: \\n{}'.format(df.shape[0],\n",
    "                                                                              list(df.operator_survey_year.unique())))\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race has missing value in 0 rows, 0.0% of total\n",
      "hispanic has missing value in 4615 rows, 3.2% of total\n",
      "household_income has missing value in 30497 rows, 20.8% of total\n",
      "approximate_age has missing value in 7659 rows, 5.2% of total\n"
     ]
    }
   ],
   "source": [
    "# consistently label 'missing' value for fields that should not have na\n",
    "missing_value_dict = {'missing': 'missing',\n",
    "                      'MISSING': 'missing',\n",
    "                      'Missing': 'missing'}\n",
    "\n",
    "for colname in ['race', 'hispanic', 'household_income', 'approximate_age', 'work_status', 'student_status', 'auto_suff',\n",
    "                'access_mode', 'egress_mode', 'boardings',  'depart_hour', 'return_hour',\n",
    "                'tour_purp', 'weekpart', 'day_part', \n",
    "                'fare_medium', 'fare_category', 'eng_proficient',\n",
    "                'persons', 'gender', 'worker_numeric_cat', 'vehicle_numeric_cat']:\n",
    "    df[colname+'_temp'] = df[colname].map(missing_value_dict)\n",
    "    df.loc[df[colname+'_temp'] == 'missing', colname] = 'missing'\n",
    "    df.loc[df[colname].isnull(), colname] = 'missing'\n",
    "\n",
    "    missing = df.loc[df[colname] == 'missing']\n",
    "    print('{} has missing value in {} rows, {:.1%} of total'.format(colname, missing.shape[0], missing.shape[0]/df.shape[0]))\n",
    "    \n",
    "    df.drop(columns = [colname+'_temp'], inplace=True)\n",
    "    \n",
    "\n",
    "# 'work_status' and 'student_status' fields can have na, so not 'missing'\n",
    "for i in ['work_status', 'student_status']:\n",
    "    df.loc[df[i] == 'missing', i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize access and egress modes\n",
    "df['access_egress_modes'] = df['access_mode'] + '-' + df['egress_mode']\n",
    "# display(df.access_egress_modes.value_counts())\n",
    "\n",
    "access_egress_mode_dict = {'walk-walk': 'walk at both ends',\n",
    "                           'pnr-walk': 'pnr at one end',\n",
    "                           'knr-walk': 'knr at one end',\n",
    "                           'walk-pnr': 'pnr at one end',\n",
    "                           'walk-knr': 'knr at one end',\n",
    "                           'bike-bike': 'bike at both ends',\n",
    "                           'missing-missing': 'missing at least one end',\n",
    "                           'pnr-pnr': 'pnr at both ends',\n",
    "                           'knr-knr': 'knr at both ends',\n",
    "                           'knr-pnr': 'pnr and knr',\n",
    "                           'pnr-knr': 'pnr and knr',\n",
    "                           'bike-walk': 'bike at one end',\n",
    "                           'walk-bike': 'bike at one end',\n",
    "                           'tnc-walk': 'tnc at one end',\n",
    "                           'walk-tnc': 'tnc at one end',\n",
    "                           'bike-pnr': 'pnr at one end',\n",
    "                           'pnr-bike': 'pnr at one end',\n",
    "                           'bike-knr': 'knr at one end',\n",
    "                           'knr-bike': 'knr at one end',\n",
    "                           'walk-missing': 'missing at least one end',\n",
    "                           'missing-walk': 'missing at least one end',\n",
    "                           'other-walk': 'other',\n",
    "                           'tnc-tnc': 'tnc at both ends',\n",
    "                           'pnr-tnc': 'pnr and tnc',\n",
    "                           'knr-tnc': 'pnr and tnc',\n",
    "                           'tnc-knr': 'pnr and tnc',\n",
    "                           'tnc-pnr': 'pnr and tnc',\n",
    "                           'walk-other': 'other',\n",
    "                           'missing-pnr': 'missing at least one end',\n",
    "                           'pnr-missing': 'missing at least one end',\n",
    "                           'missing-knr': 'missing at least one end',\n",
    "                           'bike-tnc': 'tnc at one end',\n",
    "                           'knr-missing': 'missing at least one end',\n",
    "                           'bike-missing': 'missing at least one end',\n",
    "                           'tnc-bike': 'tnc at one end',\n",
    "                           'knr-other': 'knr at one end',\n",
    "                           'other-other': 'other',\n",
    "                           'other-pnr': 'pnr at one end',\n",
    "                           'other-knr': 'knr at one end',\n",
    "                           'other-bike': 'bike at one end',\n",
    "                           'missing-tnc': 'missing at least one end',\n",
    "                           'missing-other':'missing at least one end',\n",
    "                           'tnc-missing': 'missing at least one end'}\n",
    "\n",
    "df['access_egress_modes'] = df['access_egress_modes'].map(access_egress_mode_dict)\n",
    "display(df.access_egress_modes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'age_group' field\n",
    "\n",
    "df.loc[df.approximate_age == 'missing', 'approximate_age'] = np.nan\n",
    "df['approximate_age'] = df['approximate_age'].fillna(0)\n",
    "df['approximate_age'] = df['approximate_age'].apply(lambda x: int(x))\n",
    "df['age_group'] = 'missing'\n",
    "df.loc[(df.approximate_age > 0) & (df.approximate_age < 16), 'age_group'] = 'below than 16'\n",
    "df.loc[(df.approximate_age > 15) & (df.approximate_age < 23), 'age_group'] = '16 to 22'\n",
    "df.loc[(df.approximate_age > 22) & (df.approximate_age < 30), 'age_group'] = '23 to 29'\n",
    "df.loc[(df.approximate_age > 29) & (df.approximate_age < 40), 'age_group'] = '30 to 39'\n",
    "df.loc[(df.approximate_age > 39) & (df.approximate_age < 50), 'age_group'] = '40 to 49'\n",
    "df.loc[(df.approximate_age > 49) & (df.approximate_age < 60), 'age_group'] = '50 to 59'\n",
    "df.loc[(df.approximate_age > 59) & (df.approximate_age < 70), 'age_group'] = '60 to 69'\n",
    "df.loc[df.approximate_age > 69, 'age_group'] = 'Above 69'\n",
    "display(df.age_group.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize fare medium and fare category\n",
    "\n",
    "# use standard value dictionary\n",
    "dict_df = pd.read_csv(r'C:\\Users\\ywang\\Documents\\GitHub\\onboard-surveys\\util\\standard_variable_dict.csv',\n",
    "                      usecols = ['generic_variable',\n",
    "                                 'valid_values_for_categoric_variables',\n",
    "                                 'standard_values_for_categoric_variables'])\n",
    "dict_df.columns = ['variable_name','value_details','value_summary']\n",
    "\n",
    "for colname in ['fare_medium', 'fare_category']:\n",
    "    df[colname] = df[colname].apply(lambda x: x.strip())\n",
    "    value_dict = dict_df.loc[dict_df.variable_name == colname]\n",
    "    df = df.merge(value_dict, left_on=colname, right_on='value_details', how='left')\n",
    "    df.rename(columns = {'value_summary': colname+'_summary'}, inplace=True)\n",
    "    display(df[colname+'_summary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select fields for visualization\n",
    "basic_info = ['operator_survey_year', 'weekpart', 'day_part', 'trip_weight', 'weight']\n",
    "\n",
    "trip_info = ['access_egress_modes', 'access_mode', 'egress_mode', 'tour_purp', 'boardings',\n",
    "             'fare_category_summary', 'fare_medium_summary',\n",
    "             'commuter_rail_present', 'heavy_rail_present', 'ferry_present', 'light_rail_present', 'express_bus_present']\n",
    "\n",
    "demo_info = ['persons', 'work_status', 'student_status', 'age_group', 'gender', 'race', 'hispanic', 'eng_proficient', \n",
    "             'household_income', 'worker_numeric_cat', 'vehicle_numeric_cat', 'auto_suff']\n",
    "\n",
    "spatial_info = ['orig_taz', 'dest_taz', 'home_taz', 'workplace_taz', 'school_taz',\n",
    "#                 'orig_maz', 'dest_maz', 'home_maz', 'workplace_maz', 'school_maz',\n",
    "                'first_board_lat', 'first_board_lon', 'last_alight_lat', 'last_alight_lon']\n",
    "\n",
    "\n",
    "df_summary = df[basic_info + trip_info + demo_info + spatial_info]\n",
    "\n",
    "# check NA in columns\n",
    "for i in list(df_summary):\n",
    "    if df_summary[i].isnull().values.any():\n",
    "        print('column with NA: {}'.format(i))\n",
    "    if 'missing' in (df_summary[i].unique()):\n",
    "        print('column with missing: {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "new_fname = fname.split('.')[0] + '_forTableau.csv'\n",
    "df_summary.to_csv(os.path.join('M:\\\\Data\\\\OnBoard\\\\Data and Reports\\\\_data Standardized', new_fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create TAZ-level spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_df = gpd.read_file(r'M:\\Data\\OnBoard\\Data and Reports\\_geocoding Standardized\\TM2_Zones\\tazs.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert taz data to integer\n",
    "for i in ['orig_taz', 'dest_taz', 'home_taz', 'workplace_taz', 'school_taz']:\n",
    "    df_summary[i] = df_summary[i].fillna(0)\n",
    "    df_summary[i] = df_summary[i].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_taz = df_summary.groupby(['operator_survey_year', 'weekpart', 'day_part', 'orig_taz'])['trip_weight'].sum().reset_index()\n",
    "orig_taz.rename(columns = {'trip_weight': 'trip_weight_by_orig_taz',\n",
    "                           'orig_taz': 'TM2_taz'}, inplace=True)\n",
    "# print(orig_taz.shape)\n",
    "# print(list(orig_taz))\n",
    "\n",
    "dest_taz = df_summary.groupby(['operator_survey_year', 'weekpart', 'day_part', 'dest_taz'])['trip_weight'].sum().reset_index()\n",
    "dest_taz.rename(columns = {'trip_weight': 'trip_weight_by_dest_taz',\n",
    "                           'dest_taz': 'TM2_taz'}, inplace=True)\n",
    "# print(dest_taz.shape)\n",
    "# print(list(dest_taz))\n",
    "\n",
    "home_taz = df_summary.groupby(['operator_survey_year', 'weekpart', 'day_part', 'home_taz'])['trip_weight'].sum().reset_index()\n",
    "home_taz.rename(columns = {'trip_weight': 'trip_weight_by_home_taz',\n",
    "                           'home_taz': 'TM2_taz'}, inplace=True)\n",
    "# print(home_taz.shape)\n",
    "# print(list(home_taz))\n",
    "\n",
    "workplace_taz = df_summary.groupby(['operator_survey_year', 'weekpart', 'day_part', 'workplace_taz'])['trip_weight'].sum().reset_index()\n",
    "workplace_taz.rename(columns = {'trip_weight': 'trip_weight_by_workplace_taz',\n",
    "                                'workplace_taz': 'TM2_taz'}, inplace=True)\n",
    "# print(workplace_taz.shape)\n",
    "# print(list(workplace_taz))\n",
    "\n",
    "school_taz = df_summary.groupby(['operator_survey_year', 'weekpart', 'day_part', 'school_taz'])['trip_weight'].sum().reset_index()\n",
    "school_taz.rename(columns = {'trip_weight': 'trip_weight_by_school_taz',\n",
    "                             'school_taz': 'TM2_taz'}, inplace=True)\n",
    "# print(school_taz.shape)\n",
    "# print(list(school_taz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "TM2_taz_summary = orig_taz.merge(dest_taz,\n",
    "                                 on=['operator_survey_year', 'weekpart', 'day_part', 'TM2_taz'],\n",
    "                                 how='outer').merge(home_taz,\n",
    "                                                    on=['operator_survey_year', 'weekpart', 'day_part', 'TM2_taz'],\n",
    "                                                    how='outer').merge(workplace_taz,\n",
    "                                                                       on=['operator_survey_year', 'weekpart', 'day_part', 'TM2_taz'],\n",
    "                                                                       how='outer').merge(school_taz,\n",
    "                                                                                          on=['operator_survey_year', 'weekpart', 'day_part', 'TM2_taz'],\n",
    "                                                                                          how='outer')\n",
    "# fill 'na' in trip_weights_sum with 0\n",
    "for i in ['trip_weight_by_orig_taz', 'trip_weight_by_dest_taz',\n",
    "          'trip_weight_by_home_taz', 'trip_weight_by_workplace_taz', 'trip_weight_by_school_taz']:\n",
    "#     print(TM2_taz_summary.loc[TM2_taz_summary[i].isnull()].shape[0])\n",
    "    TM2_taz_summary[i] = TM2_taz_summary[i].fillna(0)\n",
    "#     print(TM2_taz_summary.loc[TM2_taz_summary[i].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "taz_fname = fname.split('.')[0] + '_TM2_taz_summary.csv'\n",
    "TM2_taz_summary.to_csv((os.path.join('M:\\\\Data\\\\OnBoard\\\\Data and Reports\\\\_data Standardized', taz_fname)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
